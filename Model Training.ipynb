{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('combined_df.csv')\n",
    "flairs=[\"Politics\",\"Non-Political\",\"AskIndia\",\"Policy/Economy\",'Business/Finance','Science/Technology','Sports','Food',\n",
    "       'Photography','CAA-NRC-NPR','Coronavirus',\"[R]ediquette\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21489b2a0f0>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "strip_df=pd.read_csv('stripped_data.csv')\n",
    "strip_df.groupby('flair').count()['title'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1321cae6400>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJwAAAHjCAYAAABmYgVvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xu8bed8L/7PV+J+J5uSYIdf1Ak/gt3Q9tAURVRFlUp+LnE7wUFLL6dUT5ufNqf9FdWi+AUR0YpbpNKWRqTiUtcdIheiItKKpEnQg6JIPOeP8azsmZW11l5751lrrr3zfr9e67XGfOYYYz5zjvtnPGOMaq0FAAAAAEa5zrwrAAAAAMDuReAEAAAAwFACJwAAAACGEjgBAAAAMJTACQAAAIChBE4AAAAADCVwAgAAAGAogRMAAAAAQwmcAAAAABhqz3lXYK3stddebfPmzfOuBgAAAMBu4/TTT/96a23T9vrbbQOnzZs3Z+vWrfOuBgAAAMBuo6r+ZTX9uaQOAAAAgKEETgAAAAAMJXACAAAAYCiBEwAAAABDCZwAAAAAGErgBAAAAMBQAicAAAAAhhI4AQAAADCUwAkAAACAoQROAAAAAAwlcAIAAABgKIETAAAAAEMJnAAAAAAYSuAEAAAAwFACJwAAAACGEjgBAAAAMJTACQAAAIChBE4AAAAADCVwAgAAAGCoPeddAQB2zive+rB5V2GX94L/5+R5VwEAAHZLWjgBAAAAMJTACQAAAIChBE4AAAAADCVwAgAAAGAogRMAAAAAQwmcAAAAABhK4AQAAADAUAInAAAAAIYSOAEAAAAwlMAJAAAAgKEETgAAAAAMJXACAAAAYCiBEwAAAABDCZwAAAAAGErgBAAAAMBQAicAAAAAhhI4AQAAADCUwAkAAACAoQROAAAAAAy1ZoFTVR1TVZdW1dkzZW+vqjP63wVVdUYv31xV359573Uzw9y3qs6qqvOq6pVVVWtVZwAAAACuuT3XcNzHJnl1kuMWClprj1/orqqXJ/nWTP9fbq0dsMR4XpvkiCSfSPLeJA9P8r41qC8AAAAAA6xZC6fW2oeTfHOp93orpV9NcvxK46iq2yW5WWvt4621lim8evTougIAAAAwzrzu4fSAJJe01r40U7ZvVX22qj5UVQ/oZXsnuXCmnwt72ZKq6oiq2lpVWy+77LLxtQYAAABgu+YVOB2Wq7ZuujjJHVtr907yG0neWlU3S7LU/ZraciNtrR3dWtvSWtuyadOmoRUGAAAAYHXW8h5OS6qqPZM8Jsl9F8paaz9I8oPefXpVfTnJXTO1aNpnZvB9kly0frUFAAAAYEfNo4XTQ5Kc21q78lK5qtpUVXv07jsn2S/J+a21i5N8p6ru3+/79OQk75lDnQEAAABYpTULnKrq+CQfT/KTVXVhVT29v3Vorn6z8AcmObOqPpfkXUme1VpbuOH4s5O8Icl5Sb4cT6gDAAAA2NDW7JK61tphy5Q/ZYmyE5KcsEz/W5PcY2jlAAAAAFgz87ppOAAAAAC7KYETAAAAAEMJnAAAAAAYSuAEAAAAwFACJwAAAACGEjgBAAAAMJTACQAAAIChBE4AAAAADCVwAgAAAGAogRMAAAAAQwmcAAAAABhK4AQAAADAUAInAAAAAIYSOAEAAAAwlMAJAAAAgKEETgAAAAAMJXACAAAAYCiBEwAAAABDCZwAAAAAGErgBAAAAMBQAicAAAAAhhI4AQAAADCUwAkAAACAoQROAAAAAAwlcAIAAABgKIETAAAAAEMJnAAAAAAYSuAEAAAAwFACJwAAAACG2nPeFQB2DX93zMHzrsIu75FPe9+8qwAAALAutHACAAAAYCiBEwAAAABDCZwAAAAAGErgBAAAAMBQAicAAAAAhhI4AQAAADCUwAkAAACAoQROAAAAAAwlcAIAAABgKIETAAAAAEMJnAAAAAAYSuAEAAAAwFACJwAAAACGEjgBAAAAMJTACQAAAIChBE4AAAAADLVmgVNVHVNVl1bV2TNlR1bV16rqjP73iJn3XlRV51XVF6vqYTPlD+9l51XVC9eqvgAAAACMsZYtnI5N8vAlyl/RWjug/703Sapq/ySHJrl7H+Y1VbVHVe2R5C+THJxk/ySH9X4BAAAA2KD2XKsRt9Y+XFWbV9n7IUne1lr7QZKvVNV5SQ7s753XWjs/Sarqbb3fzw+uLgAAAACDzOMeTs+tqjP7JXe37GV7J/nqTD8X9rLlygEAAADYoNY7cHptkrskOSDJxUle3striX7bCuVLqqojqmprVW297LLLrmldAQAAANgJ6xo4tdYuaa1d0Vr7cZLXZ9tlcxcmucNMr/skuWiF8uXGf3RrbUtrbcumTZvGVh4AAACAVVnXwKmqbjfz8peTLDzB7qQkh1bV9atq3yT7JflUkk8n2a+q9q2q62W6sfhJ61lnAAAAAHbMmt00vKqOT3JQkr2q6sIkf5DkoKo6INNlcRckeWaStNbOqap3ZLoZ+OVJntNau6KP57lJTk6yR5JjWmvnrFWdAQAAALjm1vIpdYctUfzGFfo/KslRS5S/N8l7B1YNAAAAgDU0j6fUAQAAALAbEzgBAAAAMJTACQAAAIChBE4AAAAADCVwAgAAAGAogRMAAAAAQwmcAAAAABhK4AQAAADAUAInAAAAAIYSOAEAAAAwlMAJAAAAgKEETgAAAAAMJXACAAAAYCiBEwAAAABDCZwAAAAAGErgBAAAAMBQAicAAAAAhhI4AQAAADCUwAkAAACAoQROAAAAAAy157wrMG+Xvfav5l2FXd6mZz9x3lUAAAAANhAtnAAAAAAYSuAEAAAAwFACJwAAAACGEjgBAAAAMJTACQAAAIChBE4AAAAADCVwAgAAAGAogRMAAAAAQwmcAAAAABhK4AQAAADAUAInAAAAAIYSOAEAAAAwlMAJAAAAgKEETgAAAAAMJXACAAAAYCiBEwAAAABDCZwAAAAAGErgBAAAAMBQAicAAAAAhhI4AQAAADCUwAkAAACAoQROAAAAAAwlcAIAAABgKIETAAAAAEPtOe8KwGJfftUh867CLu8uz3vPvKsAAADAtZgWTgAAAAAMtWaBU1UdU1WXVtXZM2Uvrapzq+rMqjqxqm7RyzdX1fer6oz+97qZYe5bVWdV1XlV9cqqqrWqMwAAAADX3Fq2cDo2ycMXlZ2S5B6ttXsm+eckL5p578uttQP637Nmyl+b5Igk+/W/xeMEAAAAYANZs8CptfbhJN9cVPb+1trl/eUnkuyz0jiq6nZJbtZa+3hrrSU5Lsmj16K+AAAAAIwxz3s4PS3J+2Ze71tVn62qD1XVA3rZ3kkunOnnwl4GAAAAwAY1l6fUVdWLk1ye5K970cVJ7tha+0ZV3TfJ31TV3ZMsdb+mtsJ4j8h0+V3ueMc7jq00AAAAAKuy7i2cqurwJI9M8oR+mVxaaz9orX2jd5+e5MtJ7pqpRdPsZXf7JLlouXG31o5urW1prW3ZtGnTWn0FAAAAAFawroFTVT08ye8keVRr7Xsz5Zuqao/efedMNwc/v7V2cZLvVNX9+9PpnpzkPetZZwAAAAB2zJpdUldVxyc5KMleVXVhkj/I9FS66yc5ZcqP8on+RLoHJnlJVV2e5Iokz2qtLdxw/NmZnnh3w0z3fJq97xMAAAAAG8yaBU6ttcOWKH7jMv2ekOSEZd7bmuQeA6sGAAAAwBqa51PqAAAAANgNCZwAAAAAGErgBAAAAMBQAicAAAAAhhI4AQAAADCUwAkAAACAoQROAAAAAAwlcAIAAABgKIETAAAAAEMJnAAAAAAYSuAEAAAAwFACJwAAAACGEjgBAAAAMJTACQAAAIChBE4AAAAADCVwAgAAAGAogRMAAAAAQwmcAAAAABhK4AQAAADAUAInAAAAAIYSOAEAAAAwlMAJAAAAgKEETgAAAAAMJXACAAAAYCiBEwAAAABDCZwAAAAAGErgBAAAAMBQAicAAAAAhhI4AQAAADCUwAkAAACAoQROAAAAAAwlcAIAAABgKIETAAAAAEMJnAAAAAAYSuAEAAAAwFACJwAAAACGEjgBAAAAMJTACQAAAIChBE4AAAAADCVwAgAAAGAogRMAAAAAQwmcAAAAABhK4AQAAADAUAInAAAAAIYSOAEAAAAw1KoCp6o6dTVlAAAAALDnSm9W1Q2S3CjJXlV1yyTV37pZktuvcd0AAAAA2AVtr4XTM5OcnuRu/f/C33uS/OX2Rl5Vx1TVpVV19kzZrarqlKr6Uv9/y15eVfXKqjqvqs6sqvvMDHN47/9LVXX4jn9NAAAAANbLioFTa+0vWmv7Jvmt1tqdW2v79r97tdZevYrxH5vk4YvKXpjk1NbafklO7a+T5OAk+/W/I5K8NpkCqiR/kOR+SQ5M8gcLIRUAAAAAG8+Kl9QtaK29qqp+Jsnm2WFaa8dtZ7gPV9XmRcWHJDmod785yWlJfqeXH9daa0k+UVW3qKrb9X5Paa19M0mq6pRMIdbxq6k7AAAAAOtrVYFTVb0lyV2SnJHkil7ckqwYOC3jtq21i5OktXZxVd2ml++d5Ksz/V3Yy5YrX6qeR2RqHZU73vGOO1E1AAAAAK6pVQVOSbYk2b+3PlortURZW6H86oWtHZ3k6CTZsmXLWtYVAAAAgGVs76bhC85O8hODPvOSfqlc+v9Le/mFSe4w098+SS5aoRwAAACADWi1gdNeST5fVSdX1UkLfzv5mSclWXjS3OGZnni3UP7k/rS6+yf5Vr/07uQkD62qW/abhT+0lwEAAACwAa32krojd2bkVXV8ppt+71VVF2Z62tyfJHlHVT09yb8meVzv/b1JHpHkvCTfS/LUJGmtfbOq/jDJp3t/L1m4gTgAAAAAG89qn1L3oZ0ZeWvtsGXeevAS/bYkz1lmPMckOWZn6gAAAADA+lrtU+q+k2036r5ekusm+W5r7WZrVTEAAAAAdk2rbeF009nXVfXoJAeuSY0AAAAA2KWt9qbhV9Fa+5skDxpcFwAAAAB2A6u9pO4xMy+vk2RLtl1iBwAAAABXWu1T6n5ppvvyJBckOWR4bQAAAADY5a32Hk5PXeuKAAAAALB7WNU9nKpqn6o6saourapLquqEqtpnrSsHAAAAwK5ntTcNf1OSk5LcPsneSf62lwEAAADAVaw2cNrUWntTa+3y/ndskk1rWC8AAAAAdlGrDZy+XlVPrKo9+t8Tk3xjLSsGAAAAwK5ptYHT05L8apJ/S3JxkscmcSNxAAAAAK5mVU+pS/KHSQ5vrf17klTVrZK8LFMQBQAAAABXWm0Lp3suhE1J0lr7ZpJ7r02VAAAAANiVrTZwuk5V3XLhRW/htNrWUQAAAABci6w2NHp5ko9V1buStEz3czpqzWoFAAAAwC5rVYFTa+24qtqa5EFJKsljWmufX9OaAcAu6OD3PGveVdjlve+Q1827CgAAXEOrviyuB0xCJgAAAABWtNp7OAEAAADAqgicAAAAABhK4AQAAADAUAInAAAAAIYSOAEAAAAwlMAJAAAAgKEETgAAAAAMJXACAAAAYCiBEwAAAABDCZwAAAAAGErgBAAAAMBQAicAAAAAhhI4AQAAADCUwAkAAACAoQROAAAAAAwlcAIAAABgKIETAAAAAEMJnAAAAAAYSuAEAAAAwFACJwAAAACGEjgBAAAAMJTACQAAAIChBE4AAAAADCVwAgAAAGAogRMAAAAAQwmcAAAAABhK4AQAAADAUAInAAAAAIYSOAEAAAAwlMAJAAAAgKHWPXCqqp+sqjNm/r5dVc+vqiOr6msz5Y+YGeZFVXVeVX2xqh623nUGAAAAYPX2XO8PbK19MckBSVJVeyT5WpITkzw1yStaay+b7b+q9k9yaJK7J7l9kg9U1V1ba1esa8UBAAAAWJV5X1L34CRfbq39ywr9HJLkba21H7TWvpLkvCQHrkvtAAAAANhh8w6cDk1y/Mzr51bVmVV1TFXdspftneSrM/1c2MuupqqOqKqtVbX1sssuW5saAwAAALCiuQVOVXW9JI9K8s5e9Nokd8l0ud3FSV6+0OsSg7elxtlaO7q1tqW1tmXTpk2DawwAAADAasyzhdPBST7TWrskSVprl7TWrmit/TjJ67PtsrkLk9xhZrh9kly0rjUFAAAAYNXmGTgdlpnL6arqdjPv/XKSs3v3SUkOrarrV9W+SfZL8ql1qyUAAAAAO2Tdn1KXJFV1oyS/kOSZM8V/WlUHZLpc7oKF91pr51TVO5J8PsnlSZ7jCXUAAAAAG9dcAqfW2veS3HpR2ZNW6P+oJEetdb0AAAAAuObm/ZQ6AAAAAHYzc2nhBACwXn7xhP9/3lXY5f39rzxz+z0BAMzQwgkAAACAoQROAAAAAAwlcAIAAABgKIETAAAAAEMJnAAAAAAYSuAEAAAAwFACJwAAAACGEjgBAAAAMJTACQAAAIChBE4AAAAADCVwAgAAAGAogRMAAAAAQwmcAAAAABhK4AQAAADAUAInAAAAAIYSOAEAAAAwlMAJAAAAgKEETgAAAAAMJXACAAAAYCiBEwAAAABDCZwAAAAAGErgBAAAAMBQAicAAAAAhhI4AQAAADCUwAkAAACAoQROAAAAAAwlcAIAAABgKIETAAAAAEMJnAAAAAAYSuAEAAAAwFACJwAAAACGEjgBAAAAMJTACQAAAIChBE4AAAAADCVwAgAAAGAogRMAAAAAQwmcAAAAABhK4AQAAADAUAInAAAAAIYSOAEAAAAwlMAJAAAAgKEETgAAAAAMJXACAAAAYCiBEwAAAABDCZwAAAAAGGpugVNVXVBVZ1XVGVW1tZfdqqpOqaov9f+37OVVVa+sqvOq6syqus+86g0AAADAyubdwunnW2sHtNa29NcvTHJqa22/JKf210lycJL9+t8RSV677jUFAAAAYFXmHTgtdkiSN/fuNyd59Ez5cW3yiSS3qKrbzaOCAAAAAKxsnoFTS/L+qjq9qo7oZbdtrV2cJP3/bXr53km+OjPshb3sKqrqiKraWlVbL7vssjWsOgAAAADL2XOOn/2zrbWLquo2SU6pqnNX6LeWKGtXK2jt6CRHJ8mWLVuu9j4AAAAAa29uLZxaaxf1/5cmOTHJgUkuWbhUrv+/tPd+YZI7zAy+T5KL1q+2AAAAAKzWXAKnqrpxVd10oTvJQ5OcneSkJIf33g5P8p7efVKSJ/en1d0/ybcWLr0DAAAAYGOZ1yV1t01yYlUt1OGtrbV/qKpPJ3lHVT09yb8meVzv/71JHpHkvCTfS/LU9a8yAAAAAKsxl8CptXZ+knstUf6NJA9eorwlec46VA0AAACAa2ieT6kDAAAAYDc0z6fUAQBwLfSod71n+z2xXSc99pB5VwEAlqWFEwAAAABDCZwAAAAAGErgBAAAAMBQAicAAAAAhhI4AQAAADCUwAkAAACAoQROAAAAAAwlcAIAAABgKIETAAAAAEMJnAAAAAAYSuAEAAAAwFACJwAAAACGEjgBAAAAMJTACQAAAIChBE4AAAAADCVwAgAAAGAogRMAAAAAQwmcAAAAABhK4AQAAADAUAInAAAAAIYSOAEAAAAwlMAJAAAAgKEETgAAAAAMJXACAAAAYCiBEwAAAABDCZwAAAAAGErgBAAAAMBQAicAAAAAhhI4AQAAADCUwAkAAACAoQROAAAAAAwlcAIAAABgqD3nXQEAAGD+HnfC2fOuwi7vnb9yj3lXAWDD0MIJAAAAgKEETgAAAAAM5ZI6AACADegdJ3x93lXYLfzqr+w17yrAtZIWTgAAAAAMJXACAAAAYCiBEwAAAABDCZwAAAAAGErgBAAAAMBQAicAAAAAhhI4AQAAADCUwAkAAACAoQROAAAAAAy17oFTVd2hqj5YVV+oqnOq6td7+ZFV9bWqOqP/PWJmmBdV1XlV9cWqeth61xkAAACA1dtzDp95eZLfbK19pqpumuT0qjqlv/eK1trLZnuuqv2THJrk7klun+QDVXXX1toV61prAAAAAFZl3Vs4tdYubq19pnd/J8kXkuy9wiCHJHlba+0HrbWvJDkvyYFrX1MAAAAAdsZc7+FUVZuT3DvJJ3vRc6vqzKo6pqpu2cv2TvLVmcEuzDIBVVUdUVVbq2rrZZddtka1BgAAAGAlcwucquomSU5I8vzW2reTvDbJXZIckOTiJC9f6HWJwdtS42ytHd1a29Ja27Jp06Y1qDUAAAAA2zOXwKmqrpspbPrr1tq7k6S1dklr7YrW2o+TvD7bLpu7MMkdZgbfJ8lF61lfAAAAAFZvHk+pqyRvTPKF1tqfzZTfbqa3X05ydu8+KcmhVXX9qto3yX5JPrVe9QUAAABgx8zjKXU/m+RJSc6qqjN62e8mOayqDsh0udwFSZ6ZJK21c6rqHUk+n+kJd8/xhDoAAACAjWvdA6fW2kez9H2Z3rvCMEclOWrNKgUAAADAMHN9Sh0AAAAAux+BEwAAAABDCZwAAAAAGErgBAAAAMBQAicAAAAAhhI4AQAAADDUnvOuAAAAAOwqzn3NJfOuwi7vbv/9tvOuAutACycAAAAAhhI4AQAAADCUwAkAAACAoQROAAAAAAwlcAIAAABgKIETAAAAAEMJnAAAAAAYSuAEAAAAwFACJwAAAACGEjgBAAAAMJTACQAAAIChBE4AAAAADCVwAgAAAGAogRMAAAAAQ+057woAAAAA7KxL/vxT867CLu+2zz9w+Di1cAIAAABgKIETAAAAAEMJnAAAAAAYSuAEAAAAwFACJwAAAACGEjgBAAAAMJTACQAAAIChBE4AAAAADCVwAgAAAGAogRMAAAAAQwmcAAAAABhK4AQAAADAUAInAAAAAIYSOAEAAAAwlMAJAAAAgKEETgAAAAAMJXACAAAAYCiBEwAAAABDCZwAAAAAGErgBAAAAMBQAicAAAAAhhI4AQAAADCUwAkAAACAoQROAAAAAAwlcAIAAABgqF0mcKqqh1fVF6vqvKp64bzrAwAAAMDSdonAqar2SPKXSQ5Osn+Sw6pq//nWCgAAAICl7BKBU5IDk5zXWju/tfbDJG9Lcsic6wQAAADAEqq1Nu86bFdVPTbJw1trz+ivn5Tkfq215y7q74gkR/SXP5nki+ta0bWxV5Kvz7sSXI3psvGYJhuT6bLxmCYbk+my8ZgmG49psjGZLhuPabIx7U7T5U6ttU3b62nP9ajJALVE2dWSstba0UmOXvvqrJ+q2tpa2zLvenBVpsvGY5psTKbLxmOabEymy8Zjmmw8psnGZLpsPKbJxnRtnC67yiV1Fya5w8zrfZJcNKe6AAAAALCCXSVw+nSS/apq36q6XpJDk5w05zoBAAAAsIRd4pK61trlVfXcJCcn2SPJMa21c+ZcrfWyW10iuBsxXTYe02RjMl02HtNkYzJdNh7TZOMxTTYm02XjMU02pmvddNklbhoOAAAAwK5jV7mkDgAAAIBdhMAJAAAAgKEETmusqq6oqjOq6uyqemdV3Wg7/f9H/3/7qnpX7z6gqh4x08+jquqFa1vzXUNVtap6+czr36qqIweN+8iq+trM9HvUKvr/rd79kqp6SO9+/ux0r6r3VtUtdqI+T6mqV+/ocBtZVf1yn4Z3205//7FE2eaqOnsHP+/K37CqnlVVT96xGm9cI9Y1O/m5L6qqJyxaXhb+dng+35XNTIPPVdVnqupndnI86zZvVtVPV9Xrq+qgqvrWzLT7wHrX5ZqoqhdX1TlVdWav//2W6W9LVb1ynet2elV9ttfrX6vqspnfefMOjusZVfXng+r1R1X1/BHj2uhWO3/s4DgP2tllnKuaWXfu1HKxzDhPq6pr1aPHl9oPuAb7Srdfq3qusg5X2+/blVTVT1TV26rqy1X1+b7vf9f+3guq6j+r6uZLDPcXfV9q2WP0Pm9vnXm9papO690L2/LPVtW5VfWyRcMeXFVbq+oLS70/098FVXXCzOvHVtWxvfspM9uxz1fVf1ui/NyqesGO/GbzsNJ02ghq5nhyVyZwWnvfb60d0Fq7R5IfJnnWagZqrV3UWntsf3lAkkfMvHdSa+1Pxld1l/SDJI+pqr3WaPyvaK0dkORxSY5ZaQMwq7X2+621D/SXz09yo5n3HtFa+9/jq7pLOizJRzM9eXJdtdZe11o7br0/dw2NWNfsjIcmeX/vfkWvw8LftW0+X5gG90ryoiR/vDMjWed58+FJ/qF3f2Rm2j1kDnXZKVX100kemeQ+rbV7JnlIkq8u1W9rbWtr7dfWsW6bk3yttXbvvi35/SRvn/mdL1ivulxb7cj8sQPj3DPJQUkETmN8f9G244J5V2gXtVP7AUt4SpIhgVNfVq5VqqqSnJjktNbaXVpr+yf53SS37b0clukJ7L+8aLjr9LKvJnngdj7mNlV18DLvfaS1du8k907yyKr62T7+eyR5dZInttb+S5J7JDl/hc/YUlV3X+a9t/dt2kFJ/ldV3XZR+c8meXFV3WE732NuVjGdVhp2j7WuX3K148l1//xRBE7r6yNJ/q8kqarf6Gcgzl7qDOPCGYmqul6SlyR5fE+MH19XbaVx26o6saYz6p+rqp+pqhtX1d/312dX1ePX9Vuur8sz3e3/ail6Vd2pqk7tZzRPrao79vJjq+qVVfWxqjq/qrZ7sN1a+0L/rL2WG++izz62nw34tUwb7Q9W1Qf7excsBGRV9eQ+ns9V1Vt62S9V1Sf72YkPzKzEdytVdZNMG6SnpwdOVXW7qvpwbTtD94BFw+xVVR+vql9cVP6Uqnp3Vf1DVX2pqv505r2nVtU/V9WH+uctlM+2SPtvVfXpPh1OqO20DtoF7PC6pnfvUVUvq6qz+nz5vKp6cFWdONP/L1TVu3v3zZJcr7V22XIVWWqcvfzBfR4/q6qOqarr9/ILqur/ramF0FnVW79V1a2q6m/6OD5RVffs5UdW1Zur6v192MdU1Z/2Yf+hqq670ndYQzdL8u/98w6qqr+b+fxXV9VTevef1HRW7czqZxoXzZunVdX/V1Wf6vPxA2Z+15f2+fbMqnpmL7/aMtT7Pba/PquuetbxwUmutjMzU9fV1GVzVX2kT7MrW3b1731aVb2rprOdf11V1d/7qZrWwZ/r47vpct/TOw5zAAAUC0lEQVRpFW6X5OuttR8kSWvt6621i5b5jCunRU3bymP65322qg7p5SutTx7ev+PnqurUlcbTHZxtgd5yv/HBNa3XPlNVb6+qG/fy+/Xyz9W0TVhYL+1TVSf3uv1x73fPqvrffX76XB/uNv29favqg/03PaWq9lmiDvfpn3FmTevAm/fy+/eyj/Vpc0Yv/1hNBy8Lw3+ylj8wmbfl5o8LZubnT1XVwjpzpX2HP6tpW/72TAfzL+jL2gOq6nF9GftcVX14Xl92d1FVN6iqN/V11mer6ue3U37DmloqnFlVb09yw7l+gfm7cj8gyR41tWQ9p6Zt5Q2TK6+g+ET/zU6sqlvWtE+8Jclf93n7hrX89voRNa3bP1rTfvXCuvXIqjq6qt6f5LhaeRvx4f7Zn6+q19XMid2qOqovT5+o6XjnplX1laq6bn//Zn05vu66/aqr8/NJftRae91CQWvtjNbaR6rqLklukuT3MgVPi4c7O8lrl3hvsZf2cSyrtfb9JGck2bsX/Y8kR7XWzu3vX95ae80Ko3hZpgBmpc+4NMmXk9xpUfk3kpyXaf27US05nZJ8tG/vFvaZHp9cOb9+sKremuSsXna1few+v39hmWXuascbVXXzPh9fp/dzo6r6ak37r8f2ZXJh//j3q+qjSR5XM604azo+uqB3371v087oy/Z+6/R7Lq+15m8N/5L8R/+/Z5L3JHl2kvtmmlFvnGmlc06Sey/qf3OSs3v3U5K8emacV77OtNPz/N69R5KbJ/mVJK+f6f/m8/4d1vL3zXRgd0H/7r+V5Mj+3t8mObx3Py3J3/TuY5O8M1Pgun+S85YZ95FJfqt33y/JRUlqhfHO9n9sksf27guS7DUz3guS7JXk7km+uPBeklv1/7dMrnyC5DOSvHyp+WBX/0vyxCRv7N0fS3KfJL+Z5MVt2/x805npfNskn0zyC71s8TJyfp8HbpDkX5LcIdOG7l+TbEpyvST/NLPszE6vW8/U64+SPG/ev8/OLAv9/zVZ1zw7yQlJ9lyYJ/s8f26STb3srUl+qXc/JslLZn7Pr2XauTkjyQdXGOcNMp3Bu2svOy7b1mMXLPz+Sf57kjf07lcl+YPe/aAkZ8x87keTXDfJvZJ8L8nB/b0Tkzx6pe8weBpc0b/7uUm+leS+vfygJH8309+r+zx7q0zrgIXl/RZLzJunZds64BFJPtC7j0jye737+km2Jtk3SyxDfT44ZebzFz5nr5npdFCv88L0e/EO1OVGSW7Qu/dLsnXROPfJtL79eJL/mmlZPD/JT/X+bpZpvl3yO63id79Jr/M/J3lNkp9b4TOunBZJ/lemM71Jcos+/I2z/PpkU6b5dt+FeXml8fTX70ly55m6PiVX3Z7fJsmHktyov35xph38GyT5SqZWOel12SPTNuFLfbresNfn9v27tWyb9/8syQt79/uSPGFmvnlX7/6jbFvuPp/kv858n5f17i8kObB3vyzblrunz/Szf5JPznsduCPzx8y6ZmE+f/LMfLHSvsPfJdlj8bLRX5+VZO/ZZczfDq87z0hyYi/7zSRv6t13y7Qtv8EK5b+R5Jhefs9MJwm3zPu7rfPvuNR+wOb+WxzQ33tHtq2vzpxZHl6S5M9792kLv12W2V7PlC+sD4+fWYaOTHJ6khv21yttI/4zyZ0zrd9OybZ955Zt+xp/mm3bhjcleXTvPiJ9m7SR/pL8WqYW30u993tJ/membeIFSW4z894bkjwp0/bqa0muu8w4TssUCv5jptBkS6ZWOgu/6cJ0uGWfDj/RX38myb1W+R0uyLTf/YVMweVjkxzb33tKtu1L3znJpZn2Z2bL75hpeb7BvKfHjk6nTMfRp/R58raZ1jG367/td2fm+SX3sbPyMrfk8Uam5fXne/fjs23f99hc9XjyfyyeD3r3Xkku6N2vyrZt/vXSl8N5/mnhtPZu2M8Ibs00w74x0w73ia2177bW/iPJu5M8YIVxrORBmZLwtNauaK19K9PM/5B+5u4BvWy31Vr7dqYN4OLLJH4604Flkrwl0+++4G9aaz9urX0+KzedfEGffi9L8vg2Lb0rjXdHPCjTjv/X+/f4Zi/fJ8nJVXVWkt/OFEztjg5L8rbe/bZsa2L81Jruw/V/t9a+09+/bpJTM61oT1lmfKe21r7VWvvPTAdPd8oUFJ7WWrustfbDTAHtUu7Rz76dleQJ2TV/8xHrmockeV1r7fJkmif7PP+WJE+s6Z5MP53pADaZLsd638zws5fU/fxy40zyk0m+0lr7597Pm3PV5uMLrY9Oz7ThTv8ub+nj+Mckt65t9z94X2vtR5nWfXtkW4uSs5Js3s53GGnhcoa7ZfptjquaWvQs49uZdrbfUFWPyRSWLWWp3+OhSZ7cp/knk9w60478UsvQ+UnuXFWvqqqH989dGMfC5ZDJVS+pO2oH6nLdJK/vy887MwUQCz7VWruwtfbjTDufmzNN/4tba59OpnV4nz+W+04r6vP2fTMdfFyWaTl/5jKfMeuhSV7YP++0TAdQCy1Wl1qf3D/Jh1trX+nj/OZK46mphfI+rbWVLln4mf57fawP/4T+G/2XJP/aWvtM/6xvtdau6MN8oLX2nTadvT53ps7fb60tzNez0+d+2bauPS6L1gFVdetMBwUf7UVvTvLAmlriXq+19qle/taZwd6W5JCaLpd5WqaDwA1pqfmjegvDTAfJC/9/unevtI1/58x0WOyfkhxb0/1MdqnLHTaA2UvqFi4zml3nn5sp+L3rCuUPTPJXvfzMTGHKtc1S+wHJtL09o3efnmRz337eorX2oV6+eDu8YLnt9d2SnL+wPsy2ZWnBSX0dlWx/G3F+X66Oz7bl7YeZAt4r69y735Dkqb37qdnA655lHJrkbX2b+O5Mt+xI3148ItPxybczbQMfup1x/VGWbuX0gKo6M8m/ZQqf/m0n63pFppZUL1rivcf3ee34JM+c2R4+vqrOybTf8Rd9G7qr+a9Jju/H1ZdkOin0U/29T83M8yvtY19tmevdyx1vvD1T0JRM88hyxyvLlc/6eJLfrarfSXKnmeVwbq5119XOwffbdC3rlbZzAHKNtdb+uarum2nF9cdV9f7W2kvW8jM3gD/PlNyvtOFpM90/mOleuMTjqCS/mCQz0+wVrbUlb6i3zHh3RC0z7KuS/Flr7aSqOijTmaLdSj/AeVCmFW/LtHPeMjX3fWCm6fCWqnppm+4fc3mmFfbDMq34lzI7Ta/ItvXbaqbPsZnOmH2uH4gctCPfZ4MYsa5Zbp58U6az/v+Z6YBr4cD9wExnUHd0nNur18K0nJ2OSw2zMN6FS2V+XFU/6gFTkvx4ZvjlvsOaaK19vB+wb8o0/86e4LlB7+fyqjow02VthyZ5bqblYrHlfo/ntdZOXtxzVV1tGaqqe2Vafp6T5FczhQQHZ2oJsyOWqssLklySqYXZdTL9xov7nx1mufls2e+0Pf1g5bQkp/Uduecs8xmLP+9XWmtfvErhdEPpHa33UuN5cKbWd9urwz+01p60aNj7rFD/5dZ1P1ymfHuWWx6XXU5ba9+t6Sa1j8p0NviA5frdCJaYPw5feGu2t+UGn+n+7gqf8aw+7/xikjOq6oA2XVbCztnh+TI7vz+2u1hqPyC5+jpjRy433JnpkFx1WVlpG7F4mi28nt2WX7k+a639U79k6ecytTbcoRuir5NzMrUIuoqabgWwX5JT+nRZaIn7l5lOUt08yVn9vRtlOgn191V1cqaT41tba89YGF9r7R+r6g8znQyZ9ZHW2iNruvn1R6vqxB5+nJMpfP/conrtkWkfO5mCwt+fefstmQKncxZ9xttba89d4ru/vbX23Jrunff3VfW+axB4rbUlp1NWnrdn5+uV+ltumTs2Sx9vnJTpmP1WmabRP67i82f3LW+wUNhae2tVfTLTtujkqnpGP1E7N1o4zceHkzy6X6N540w3iPvICv1/J1Pz+aWcmn7AV9P9L25W05Mlvtda+6tMLXPuM67qG1NP1t+RqZn/go9l282on5Dt7Pi31l68cIZtOx+3Q+PN8tPv1CS/2sOX9JVMMm1wvta7D19iuN3BY5Mc11q7U2ttc2vtDpkuH3lgkktba6/PdGZuYd5tmQ6Q71Y79oTGTyY5qKpuXdM1/o9bpr+bJrm49/OEnfg+G9WOrmven+RZvdXClfNka+2iTJeU/l6mjWVqul/LuSuc7V9pnOdmOsO6cH+JJ2X5IHH2uzyhj+OgTPdk+faKQ8xY6juspZruPbVHkm9kOgO/f1Vdv59VfnDv5yaZLnl+b6ZLFHbkoP3kJM+ubfeyuGtN9xK6UxYtQz34uk5r7YRMTfnv08PIe2ZqdXRN3TxTa6IfZ5qW22vdcW6S21fVT/W637TPH0t+p+19eFX95KJ7FByQ6TKApT5j1slJnrcQzFbVvbfzUR9P8nNVtW/vf2Gdvdx4FrcAXMrH+jjv3Ie9cf8u5yS5Uw+eFu5VsrOtZj6RKWRMpkuZr3J/oTa1sv1+bXvi2pOSfKhN92b7UW170tfihzu8IdPloR9rG7gl9TLzx7/07sfP/P94717tNv4q2/aquktr7ZP9YO3rmS7DZOfNrvPvmqkl3xdXWX6PTOs3ltGX2X+vbffKnN0Oz87by22vz83UcnZzL1/pfrErbSMOrOk+c9fp49jePnUytdQ8Phu3ddM/Jrl+b+2YZLpvYZK/yHTbj8397/ZJ9u7b7cOSPGPhvUyXyD+0qm7UWntYPz55xhKfdVSmk7VX01ul/XGS3+lFL83U8mXhaXnXqarf6C15FloY/v6icfwoySsy7aOsWmvt45nCql/fkeHW2XLT6d8ztdTao6o2ZTo2+dQSw+/oPnayzPFGbyH1qUzzyN+tYt86mS6xu2/vvjI46/sT57fWXpkpyJr7ulALpzlorX2mpkdLLsy8b2itfXaFQT6Ybc31Fz/16NeTHF1VT8+UoD4707W/L62qHyf5UbbfAmF38fJMLQQW/FqmJ8v9dqZm9E9dcqgdt6PjPTrJ+6rq4rbtMqO01s6pqVXVh6rqiiSfzXT985FJ3llVX8t0oLDvoHpvJIclWfykxRMyBQHfraofZbpv05WPY2+tXVFVhyb526r6dpL3bu9DWmsX13Rp0ceTXJypFdxSB23/M1M49S+ZLsNaLuDdpezEuuYNmS5NOLNPg9dnOqBMkr/OdA+kz/fXS90M+QVV9cSZ149eapyttVdX1VMzzed7ZroM7HVZ2ZFJ3lRTM/HvZefC2MXfYbSFyxmS6czX4X2n4atV9Y5Ml3h8KdOynkzz2Xuq6ga9/x15hPAbMjXR/kwPOi7L9HsflOS3Fy1De2f67RZOMr0o007KZ2fOIF8Tr0lyQlU9LtP2atlWIEnSWvthTTfhfFVNN9L8fqZLL5f7Tttzkz6uW2Q643depsun3rTEZ8z6w0ytY8/sn3dBpqeZLVfvy6rqiCTv7r/lpUl+YYXxHJTpqXQr/RaX9O3322u6pCJJfre19qWqOizJa/v88f0s3fptNZ6b5I1V9aJMrQyW2mY9qX/WDTP9fgv9PC3TvPOdTDvXVwZLrbVPVtX3snEP+hYsN388MtPBxicznYBduEnvarfxf5vkXTXdJP55mdZ/+2Valk/NolYE7LDXJHldTS3SLk/ylNbaD6pqufLXZts24oz/094dg8hRRnEA/z8QERHESgQttBAsUggp7IygCEIigmClsRFFRIVIGi1ERAiIClFQJJBGTEwREBRBwUJBLCRoo2ChhVGLgFVQUHkW3x5ecreXXJi9zSW/X3U7OzP7ZvbY+ebN970v698gcqa9Gefy6oyeNiv/64dny//MGGK65no9O+dPJvmkqk5l4/O90TXiq4z24I6M35jjazdf472M4WRnD+O7KHR3V9UDSd6o8ZD0r4zrwq6svSc7ntH2vzdjKPjKPk7XKA69OxsMo+ruj6tq7sQtGW2r56rq5u7+rkZh6/dn33kn+eg8DulQzlGgfI4DGdfzV/r/EhkXjQ2+p2czrhvfZjb6ort/r9kkNqu2X7eNvSoJu56N7jeOZgw53XWeh/Bqkg+q6uGc2SPqoYwSEn9nDKtc+iinmqatCcClrMbMmCe6+9Ds9adJHunu35Yb2fk7+xguZ1X1QsaECUfOuTKbVmMmuHe7e9601dtCVV0ze/Kaqno+o1D6vtnrmzIKq942UeJyS9WY0WfnrIcXsEkrvw+zRPtbSX7s7tc3sf2ujML7cxP9c7Z7MMn9Zw9FBi5OejgBsKGq+ibjieS+lWXdfc/yItq89Y7hctbdLy87hktZd/+S0Qtwu9tTVfsz2os/ZzyJz6yH4ktJntmOySZgEo9V1d6MWkQnkryz6A+sqoMZv633LfqzgGno4QQAAADApBQNBwAAAGBSEk4AAAAATErCCQAAAIBJSTgBACxQVT1dVd9X1cnZbIkbrbtnNkUzAMC2pmg4AMACVdUPGTMr3ZlkZ3c/dQH7uKK7/5k8OACABdHDCQBgQarq7SS3JPkwyXWrlu+uqq+r6kRVfVZV18+WP7rSC6qqDlfVa1X1eZIDy4gfAOBCSTgBACxIdz+R5NckdyX5Y9VbXya5o7tvT3Ikyf45u7g1yd3dvW+hgQIATOyKZQcAAHAZujHJ0aq6IcmVSX6as96x7v5368ICAJiGHk4AAFvvYJI3u3tHkseTXDVnvdNbFxIAwHQknAAAtt61SU7O/t67zEAAABZBwgkAYOu9mORYVX2R5NSSYwEAmFx197JjAAAAAOASoocTAAAAAJOScAIAAABgUhJOAAAAAExKwgkAAACASUk4AQAAADApCScAAAAAJiXhBAAAAMCk/gPStt7tpL5B4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "sns.countplot(x='flair',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an unequal distribution of datapoints for each dataset. We will first try to train on this original dataset and then see if further data trimming is required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>comment_length</th>\n",
       "      <th>comments</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>flair</th>\n",
       "      <th>id</th>\n",
       "      <th>numerical_flair</th>\n",
       "      <th>score</th>\n",
       "      <th>stem_comments</th>\n",
       "      <th>stemmed_titles</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>title_length</th>\n",
       "      <th>url</th>\n",
       "      <th>processed_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>chillinvillain122</td>\n",
       "      <td>2115</td>\n",
       "      <td>If there is anything positive in the fight ag...</td>\n",
       "      <td>73</td>\n",
       "      <td>Politics</td>\n",
       "      <td>futac9</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>anyth posit fight covid giv credit institut li...</td>\n",
       "      <td>pit commun polit party fuck stupid</td>\n",
       "      <td>2020-04-05 02:28:28</td>\n",
       "      <td>Pitting a community against a political party ...</td>\n",
       "      <td>64</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/futac9...</td>\n",
       "      <td>www reddit com r india comments futac9 pitting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>chillinvillain122</td>\n",
       "      <td>4631</td>\n",
       "      <td>What an incredibly narrow minded person. Our ...</td>\n",
       "      <td>73</td>\n",
       "      <td>Politics</td>\n",
       "      <td>futac9</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>incred narrow mind person gre grandfath nat pe...</td>\n",
       "      <td>pit commun polit party fuck stupid</td>\n",
       "      <td>2020-04-05 02:28:28</td>\n",
       "      <td>Pitting a community against a political party ...</td>\n",
       "      <td>64</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/futac9...</td>\n",
       "      <td>www reddit com r india comments futac9 pitting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>hipporama</td>\n",
       "      <td>5391</td>\n",
       "      <td>So the argument is that the DMs could have co...</td>\n",
       "      <td>67</td>\n",
       "      <td>Politics</td>\n",
       "      <td>fpaj1w</td>\n",
       "      <td>0</td>\n",
       "      <td>404</td>\n",
       "      <td>argu dms could command pol arm forc didnt dms ...</td>\n",
       "      <td>hit backlash post lack med gear doct go sil so...</td>\n",
       "      <td>2020-03-27 01:47:25</td>\n",
       "      <td>Hit by backlash over posts on lack of medical ...</td>\n",
       "      <td>242</td>\n",
       "      <td>https://theprint.in/india/hit-by-backlash-over...</td>\n",
       "      <td>theprint india hit backlash posts lack medical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>aaluinsonaout</td>\n",
       "      <td>3828</td>\n",
       "      <td>I tend to agree with her. After the first Del...</td>\n",
       "      <td>146</td>\n",
       "      <td>Politics</td>\n",
       "      <td>ff8sth</td>\n",
       "      <td>0</td>\n",
       "      <td>731</td>\n",
       "      <td>tend agr first delh shoot arnab goswam republ ...</td>\n",
       "      <td>new polit party gav ful front pag ad popul new...</td>\n",
       "      <td>2020-03-08 20:06:11</td>\n",
       "      <td>A new political party gave a full front page a...</td>\n",
       "      <td>85</td>\n",
       "      <td>https://i.redd.it/yjo9wpy38el41.jpg</td>\n",
       "      <td>redd yjo9wpy38el41 jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>I_can_believe_that</td>\n",
       "      <td>2148</td>\n",
       "      <td>Except Indira all of them loved dissent. They...</td>\n",
       "      <td>51</td>\n",
       "      <td>Politics</td>\n",
       "      <td>fs887w</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>exceiv indir lov diss spin back didn’t sold go...</td>\n",
       "      <td>i’ve cury ind polit think good job polit</td>\n",
       "      <td>2020-03-31 20:29:29</td>\n",
       "      <td>I’ve been curious, which Indian politicians do...</td>\n",
       "      <td>98</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fs887w...</td>\n",
       "      <td>www reddit com r india comments fs887w ive cur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author  comment_length  \\\n",
       "0   chillinvillain122            2115   \n",
       "1   chillinvillain122            4631   \n",
       "2           hipporama            5391   \n",
       "3       aaluinsonaout            3828   \n",
       "4  I_can_believe_that            2148   \n",
       "\n",
       "                                            comments  comms_num     flair  \\\n",
       "0   If there is anything positive in the fight ag...         73  Politics   \n",
       "1   What an incredibly narrow minded person. Our ...         73  Politics   \n",
       "2   So the argument is that the DMs could have co...         67  Politics   \n",
       "3   I tend to agree with her. After the first Del...        146  Politics   \n",
       "4   Except Indira all of them loved dissent. They...         51  Politics   \n",
       "\n",
       "       id  numerical_flair  score  \\\n",
       "0  futac9                0    196   \n",
       "1  futac9                0    198   \n",
       "2  fpaj1w                0    404   \n",
       "3  ff8sth                0    731   \n",
       "4  fs887w                0     43   \n",
       "\n",
       "                                       stem_comments  \\\n",
       "0  anyth posit fight covid giv credit institut li...   \n",
       "1  incred narrow mind person gre grandfath nat pe...   \n",
       "2  argu dms could command pol arm forc didnt dms ...   \n",
       "3  tend agr first delh shoot arnab goswam republ ...   \n",
       "4  exceiv indir lov diss spin back didn’t sold go...   \n",
       "\n",
       "                                      stemmed_titles            timestamp  \\\n",
       "0                 pit commun polit party fuck stupid  2020-04-05 02:28:28   \n",
       "1                 pit commun polit party fuck stupid  2020-04-05 02:28:28   \n",
       "2  hit backlash post lack med gear doct go sil so...  2020-03-27 01:47:25   \n",
       "3  new polit party gav ful front pag ad popul new...  2020-03-08 20:06:11   \n",
       "4           i’ve cury ind polit think good job polit  2020-03-31 20:29:29   \n",
       "\n",
       "                                               title  title_length  \\\n",
       "0  Pitting a community against a political party ...            64   \n",
       "1  Pitting a community against a political party ...            64   \n",
       "2  Hit by backlash over posts on lack of medical ...           242   \n",
       "3  A new political party gave a full front page a...            85   \n",
       "4  I’ve been curious, which Indian politicians do...            98   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.reddit.com/r/india/comments/futac9...   \n",
       "1  https://www.reddit.com/r/india/comments/futac9...   \n",
       "2  https://theprint.in/india/hit-by-backlash-over...   \n",
       "3                https://i.redd.it/yjo9wpy38el41.jpg   \n",
       "4  https://www.reddit.com/r/india/comments/fs887w...   \n",
       "\n",
       "                                       processed_url  \n",
       "0  www reddit com r india comments futac9 pitting...  \n",
       "1  www reddit com r india comments futac9 pitting...  \n",
       "2  theprint india hit backlash posts lack medical...  \n",
       "3                             redd yjo9wpy38el41 jpg  \n",
       "4  www reddit com r india comments fs887w ive cur...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sec Stripped Data\n",
    "\n",
    "This dataset containts approximately similar number of datapoints for each flair, with the relatively unpopular posts from the flairs removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_strip=pd.read_csv('sec_strip_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x214d7a268d0>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sec_strip.groupby('flair').count()['title'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval=dict()\n",
    "model_eval['Classifier']=[]\n",
    "model_eval['Features']=[]\n",
    "model_eval['macro_precision']=[]\n",
    "model_eval['weighted_precision']=[]\n",
    "model_eval['macro_recall']=[]\n",
    "model_eval['weighted_recall']=[]\n",
    "model_eval['macro_F1']=[]\n",
    "model_eval['weighted_F1']=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logregclassifier(X,y):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=101)\n",
    "    logreg=Pipeline([('vect',CountVectorizer()),\n",
    "                     ('tfidf',TfidfTransformer()),\n",
    "                      ('clf',LogisticRegression(C=50,penalty='l2')) # l1 performed comparatively worse \n",
    "                     ])\n",
    "    logreg.fit(X_train,y_train)\n",
    "    predictions=logreg.predict(X_test)\n",
    "    print(\"confusion matrix\")\n",
    "    print(confusion_matrix(y_test,predictions))\n",
    "    print('\\n')\n",
    "    print(\"Classification report \")\n",
    "    print(classification_report(y_test,predictions))\n",
    "    c_report=classification_report(y_test,predictions,output_dict=True)\n",
    "    model_eval['Classifier'].append('Logistic Regression')\n",
    "    model_eval['macro_precision'].append(c_report['macro avg']['precision'])\n",
    "    model_eval['weighted_precision'].append(c_report['weighted avg']['precision'])\n",
    "    model_eval['macro_recall'].append(c_report['macro avg']['recall'])\n",
    "    model_eval['weighted_recall'].append(c_report['weighted avg']['recall'])\n",
    "    model_eval['macro_F1'].append(c_report['macro avg']['f1-score'])\n",
    "    model_eval['weighted_F1'].append(c_report['weighted avg']['f1-score'])\n",
    "\n",
    "    '''#Using GridSearch CV\n",
    "    param_grid = {'clf__C': [1,10,50,100,1000],\n",
    "                  'clf__penalty': ['l1','l2']}\n",
    "    print(\"using the grid search cv\")\n",
    "    grid = GridSearchCV(logreg, param_grid, cv=5)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"Best cross-validation score:\",grid.best_score_)\n",
    "    print(\"Best parameters: \", grid.best_params_)\n",
    "    print(\"Best estimator: \", grid.best_estimator_)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['title_comments_stem']+df['processed_url']\n",
    "y=df['flair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[393  18   1   0   7  28   3  18  16   9   1]\n",
      " [ 21 155   0   0   0  10   0  55   5  11   0]\n",
      " [  4   0  48   0   0   0   1   9   4   0   0]\n",
      " [  1   0   0  29   1   2   0   0   1   0   0]\n",
      " [ 13   2   0   1  44  25   3   5   3   0   2]\n",
      " [ 23   4   0   0   2 285   9  11  36   4   4]\n",
      " [ 14   1   0   0   1  28  46   0   0   1   0]\n",
      " [ 12  43   0   0   1  14   3 413  32  13   1]\n",
      " [ 10   4   1   0   2  56   0  38 313   4   1]\n",
      " [ 25  18   0   0   0  22   3  48  10 101   2]\n",
      " [ 16   0   0   0   1   9   2   7   4   3  98]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.74      0.80      0.77       494\n",
      "  Business/Finance       0.63      0.60      0.62       257\n",
      "       CAA-NRC-NPR       0.96      0.73      0.83        66\n",
      "       Coronavirus       0.97      0.85      0.91        34\n",
      "              Food       0.75      0.45      0.56        98\n",
      "     Non-Political       0.59      0.75      0.67       378\n",
      "       Photography       0.66      0.51      0.57        91\n",
      "    Policy/Economy       0.68      0.78      0.73       532\n",
      "          Politics       0.74      0.73      0.73       429\n",
      "Science/Technology       0.69      0.44      0.54       229\n",
      "            Sports       0.90      0.70      0.79       140\n",
      "\n",
      "          accuracy                           0.70      2748\n",
      "         macro avg       0.76      0.67      0.70      2748\n",
      "      weighted avg       0.71      0.70      0.70      2748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logregclassifier(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfclassifier(X,y):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=101)\n",
    "    rf_reg=Pipeline([('vect',CountVectorizer()),\n",
    "                     ('tfidf',TfidfTransformer()),\n",
    "                      ('clf',RandomForestClassifier(max_depth=75,max_features='auto',n_estimators=500))#{'clf__max_depth': 75, 'clf__max_features': 'auto', 'clf__n_estimators': 500} \n",
    "                     ])\n",
    "    rf_reg.fit(X_train,y_train)\n",
    "    predictions=rf_reg.predict(X_test)\n",
    "    print(\"confusion matrix\")\n",
    "    print(confusion_matrix(y_test,predictions))\n",
    "    print('\\n')\n",
    "    print(\"Classification report \")\n",
    "    print(classification_report(y_test,predictions))\n",
    "    c_report=classification_report(y_test,predictions,output_dict=True)\n",
    "    model_eval['Classifier'].append('Random Forests')\n",
    "    model_eval['macro_precision'].append(c_report['macro avg']['precision'])\n",
    "    model_eval['weighted_precision'].append(c_report['weighted avg']['precision'])\n",
    "    model_eval['macro_recall'].append(c_report['macro avg']['recall'])\n",
    "    model_eval['weighted_recall'].append(c_report['weighted avg']['recall'])\n",
    "    model_eval['macro_F1'].append(c_report['macro avg']['f1-score'])\n",
    "    model_eval['weighted_F1'].append(c_report['weighted avg']['f1-score'])\n",
    "\n",
    "    #Using GridSearch CV\n",
    "    '''param_grid = {'clf__n_estimators': [500,100,50],\n",
    "                  'clf__max_features': ['auto','sqrt','log2'],\n",
    "                 'clf__max_depth':[5,15,50,75]\n",
    "                 }\n",
    "    print(\"using the grid search cv\")\n",
    "    grid = GridSearchCV(rf_reg, param_grid, cv=5)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"Best cross-validation score:\",grid.best_score_)\n",
    "    print(\"Best parameters: \", grid.best_params_)\n",
    "    print(\"Best estimator: \", grid.best_estimator_)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[457   0   0   0   0  13   0  10  12   1   1]\n",
      " [ 37  61   0   0   0  17   0 137   3   2   0]\n",
      " [ 15   0  41   0   0   0   1   4   5   0   0]\n",
      " [  3   0   0  18   0   4   0   5   4   0   0]\n",
      " [ 26   1   0   0   9  34   0  20   6   0   2]\n",
      " [ 28   0   0   0   0 279   4  29  37   0   1]\n",
      " [ 17   0   0   0   0  27  34  13   0   0   0]\n",
      " [ 35   7   0   0   0  14   0 446  28   1   1]\n",
      " [ 13   0   1   0   0  56   0  60 297   1   1]\n",
      " [ 37   0   0   0   0  21   1 109   9  51   1]\n",
      " [ 22   0   0   0   1  20   2  27   6   0  62]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.66      0.93      0.77       494\n",
      "  Business/Finance       0.88      0.24      0.37       257\n",
      "       CAA-NRC-NPR       0.98      0.62      0.76        66\n",
      "       Coronavirus       1.00      0.53      0.69        34\n",
      "              Food       0.90      0.09      0.17        98\n",
      "     Non-Political       0.58      0.74      0.65       378\n",
      "       Photography       0.81      0.37      0.51        91\n",
      "    Policy/Economy       0.52      0.84      0.64       532\n",
      "          Politics       0.73      0.69      0.71       429\n",
      "Science/Technology       0.91      0.22      0.36       229\n",
      "            Sports       0.90      0.44      0.59       140\n",
      "\n",
      "          accuracy                           0.64      2748\n",
      "         macro avg       0.81      0.52      0.57      2748\n",
      "      weighted avg       0.71      0.64      0.61      2748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=df['title_comments_stem']+df['processed_url']\n",
    "y=df['flair']\n",
    "rfclassifier(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlpclassifier(X,y):\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=101)\n",
    "    mlp_reg=Pipeline([('vect',CountVectorizer()),\n",
    "                     ('tfidf',TfidfTransformer()),\n",
    "                      ('clf',MLPClassifier(early_stopping=True,hidden_layer_sizes=(30,30,30),solver='lbfgs')) \n",
    "                     ])\n",
    "    mlp_reg.fit(X_train,y_train)\n",
    "    predictions=mlp_reg.predict(X_test)\n",
    "    print(\"confusion matrix\")\n",
    "    print(confusion_matrix(y_test,predictions))\n",
    "    print('\\n')\n",
    "    print(\"Classification report \")\n",
    "    print(classification_report(y_test,predictions))\n",
    "    c_report=classification_report(y_test,predictions,output_dict=True)\n",
    "    model_eval['Classifier'].append('Multi Layer Perceptron')\n",
    "    model_eval['macro_precision'].append(c_report['macro avg']['precision'])\n",
    "    model_eval['weighted_precision'].append(c_report['weighted avg']['precision'])\n",
    "    model_eval['macro_recall'].append(c_report['macro avg']['recall'])\n",
    "    model_eval['weighted_recall'].append(c_report['weighted avg']['recall'])\n",
    "    model_eval['macro_F1'].append(c_report['macro avg']['f1-score'])\n",
    "    model_eval['weighted_F1'].append(c_report['weighted avg']['f1-score'])\n",
    "\n",
    "    #Using GridSearch CV\n",
    "    \"\"\"param_grid = {'clf__hidden_layer_sizes': [15,20,30],\n",
    "                  'clf__solver': ['lbfgs','adam'],\n",
    "                 'clf__learning_rate':['constant','adaptive']\n",
    "                 }\n",
    "    print(\"using the grid search cv\")\n",
    "    grid = GridSearchCV(mlp_reg, param_grid, cv=5)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"Best cross-validation score:\",grid.best_score_)\n",
    "    print(\"Best parameters: \", grid.best_params_)\n",
    "    print(\"Best estimator: \", grid.best_estimator_)\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[332  25   1   0   8  32  20  27  18  18  13]\n",
      " [ 23 142   0   0   3  11   2  59   9   8   0]\n",
      " [  0   0  56   1   0   2   0   3   4   0   0]\n",
      " [  1   0   0  28   3   0   0   1   0   1   0]\n",
      " [  9   2   0   4  38  17   4  10   6   3   5]\n",
      " [ 29   9   0   0   8 190  21  34  40  21  26]\n",
      " [ 11   3   1   0   9  10  42   2   7   1   5]\n",
      " [ 25  59   2   0   7  21   3 337  51  25   2]\n",
      " [ 25  15   2   0   7  63   2  44 249  16   6]\n",
      " [ 21  14   0   0   1  27   7  57  13  88   1]\n",
      " [ 13   2   0   0   8  24   5   6   7   4  71]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.68      0.67      0.68       494\n",
      "  Business/Finance       0.52      0.55      0.54       257\n",
      "       CAA-NRC-NPR       0.90      0.85      0.88        66\n",
      "       Coronavirus       0.85      0.82      0.84        34\n",
      "              Food       0.41      0.39      0.40        98\n",
      "     Non-Political       0.48      0.50      0.49       378\n",
      "       Photography       0.40      0.46      0.43        91\n",
      "    Policy/Economy       0.58      0.63      0.61       532\n",
      "          Politics       0.62      0.58      0.60       429\n",
      "Science/Technology       0.48      0.38      0.43       229\n",
      "            Sports       0.55      0.51      0.53       140\n",
      "\n",
      "          accuracy                           0.57      2748\n",
      "         macro avg       0.59      0.58      0.58      2748\n",
      "      weighted avg       0.57      0.57      0.57      2748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=df['title']\n",
    "y=df['flair']\n",
    "mlpclassifier(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on stripped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x214d7720780>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "strip_df.groupby('flair').count()['title'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[236  11   0   0   0   5   1   1   3  10   1]\n",
      " [ 16 198   0   0   1  12   0  13   7  18   0]\n",
      " [  3   0  52   0   0   3   0   0   2   0   0]\n",
      " [  1   0   0  31   1   0   0   0   4   0   0]\n",
      " [ 18   4   0   1  48  12   1   0   2   5   2]\n",
      " [ 17  13   0   0   2 167   5   7  27   8   7]\n",
      " [ 12   0   0   0   1  27  41   0   1   0   1]\n",
      " [ 10  33   3   0   1   9   0 107  14  16   1]\n",
      " [  9   9   0   0   1  53   0  17 156  12   2]\n",
      " [ 29  24   0   0   5  15   0  21  10 117   4]\n",
      " [ 18   1   0   0   2   7   1   4   8   6 103]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.64      0.88      0.74       268\n",
      "  Business/Finance       0.68      0.75      0.71       265\n",
      "       CAA-NRC-NPR       0.95      0.87      0.90        60\n",
      "       Coronavirus       0.97      0.84      0.90        37\n",
      "              Food       0.77      0.52      0.62        93\n",
      "     Non-Political       0.54      0.66      0.59       253\n",
      "       Photography       0.84      0.49      0.62        83\n",
      "    Policy/Economy       0.63      0.55      0.59       194\n",
      "          Politics       0.67      0.60      0.63       259\n",
      "Science/Technology       0.61      0.52      0.56       225\n",
      "            Sports       0.85      0.69      0.76       150\n",
      "\n",
      "          accuracy                           0.67      1887\n",
      "         macro avg       0.74      0.67      0.69      1887\n",
      "      weighted avg       0.68      0.67      0.66      1887\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=strip_df['stemmed_titles']+strip_df['processed_url']\n",
    "y=strip_df['flair']\n",
    "logregclassifier(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive - Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbclassifier(X,y):\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=101)\n",
    "    nb_pipeline=Pipeline([('vect',CountVectorizer()),\n",
    "                     ('tfidf',TfidfTransformer()),\n",
    "                      ('clf',MultinomialNB(alpha=1))\n",
    "                     ])\n",
    "    nb_pipeline.fit(X_train,y_train)\n",
    "    predictions=nb_pipeline.predict(X_test)\n",
    "    print(\"confusion matrix\")\n",
    "    print(confusion_matrix(y_test,predictions))\n",
    "    print('\\n')\n",
    "    print(\"Classification report \")\n",
    "    print(classification_report(y_test,predictions))\n",
    "    c_report=classification_report(y_test,predictions,output_dict=True)\n",
    "    model_eval['Classifier'].append('Naive Bayes')\n",
    "    model_eval['macro_precision'].append(c_report['macro avg']['precision'])\n",
    "    model_eval['weighted_precision'].append(c_report['weighted avg']['precision'])\n",
    "    model_eval['macro_recall'].append(c_report['macro avg']['recall'])\n",
    "    model_eval['weighted_recall'].append(c_report['weighted avg']['recall'])\n",
    "    model_eval['macro_F1'].append(c_report['macro avg']['f1-score'])\n",
    "    model_eval['weighted_F1'].append(c_report['weighted avg']['f1-score'])\n",
    "\n",
    "    #Using GridSearch CV\n",
    "    '''param_grid = {'clf__alpha': [1,2,10,5]}\n",
    "    grid = GridSearchCV(nb_pipeline, param_grid, cv=5)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    print(\"using the grid search cv\")\n",
    "    grid = GridSearchCV(nb_pipeline, param_grid, cv=5)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"Best cross-validation score:\",grid.best_score_)\n",
    "    print(\"Best parameters: \", grid.best_params_)\n",
    "    print(\"Best estimator: \", grid.best_estimator_)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[237  16   0   0   0   7   0   0   4   4   0]\n",
      " [ 30 213   0   0   0   7   0   2   6   7   0]\n",
      " [ 12   4  16   0   0   4   0   1  23   0   0]\n",
      " [  2   9   0   0   0   2   0   1  21   2   0]\n",
      " [ 41  15   0   0   5  21   0   0   8   3   0]\n",
      " [ 31  26   0   0   0 142   0   2  43   6   3]\n",
      " [ 22   3   0   0   0  39  12   0   7   0   0]\n",
      " [ 17  68   3   0   0   8   0  59  32   7   0]\n",
      " [ 14  24   0   0   0  38   0   5 172   6   0]\n",
      " [ 54  55   0   0   0   5   0   3  17  91   0]\n",
      " [ 37  17   0   0   0   7   0   1  16   3  69]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.48      0.88      0.62       268\n",
      "  Business/Finance       0.47      0.80      0.60       265\n",
      "       CAA-NRC-NPR       0.84      0.27      0.41        60\n",
      "       Coronavirus       0.00      0.00      0.00        37\n",
      "              Food       1.00      0.05      0.10        93\n",
      "     Non-Political       0.51      0.56      0.53       253\n",
      "       Photography       1.00      0.14      0.25        83\n",
      "    Policy/Economy       0.80      0.30      0.44       194\n",
      "          Politics       0.49      0.66      0.57       259\n",
      "Science/Technology       0.71      0.40      0.51       225\n",
      "            Sports       0.96      0.46      0.62       150\n",
      "\n",
      "          accuracy                           0.54      1887\n",
      "         macro avg       0.66      0.41      0.42      1887\n",
      "      weighted avg       0.63      0.54      0.51      1887\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X=strip_df['stemmed_titles']+strip_df['processed_url']\n",
    "y=strip_df['flair']\n",
    "nbclassifier(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmclassifier(X,y):    \n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=101)\n",
    "    svm_pipeline=Pipeline([('vect',CountVectorizer()),\n",
    "                     ('tfidf',TfidfTransformer()),\n",
    "                      ('clf',SGDClassifier(alpha=0.001,penalty='elasticnet'))\n",
    "                     ])\n",
    "    svm_pipeline.fit(X_train,y_train)\n",
    "    predictions=svm_pipeline.predict(X_test)\n",
    "    print(\"confusion matrix\")\n",
    "    print(confusion_matrix(y_test,predictions))\n",
    "    print('\\n')\n",
    "    print(\"Classification report \")\n",
    "    print(classification_report(y_test,predictions))\n",
    "    c_report=classification_report(y_test,predictions,output_dict=True)\n",
    "    model_eval['Classifier'].append('SVM')\n",
    "    model_eval['macro_precision'].append(c_report['macro avg']['precision'])\n",
    "    model_eval['weighted_precision'].append(c_report['weighted avg']['precision'])\n",
    "    model_eval['macro_recall'].append(c_report['macro avg']['recall'])\n",
    "    model_eval['weighted_recall'].append(c_report['weighted avg']['recall'])\n",
    "    model_eval['macro_F1'].append(c_report['macro avg']['f1-score'])\n",
    "    model_eval['weighted_F1'].append(c_report['weighted avg']['f1-score'])\n",
    "\n",
    "    #Using GridSearch CV\n",
    "    \"\"\"param_grid = {'clf__alpha': [0.001,0.01,0.1,1]}\n",
    "    grid = GridSearchCV(svm_pipeline, param_grid, cv=5)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    print(\"using the grid search cv\")\n",
    "    grid = GridSearchCV(svm_pipeline, param_grid, cv=5)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"Best cross-validation score:\",grid.best_score_)\n",
    "    print(\"Best parameters: \", grid.best_params_)\n",
    "    print(\"Best estimator: \", grid.best_estimator_)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[453   2   0   0   6   6   3  17   6   1   0]\n",
      " [ 65  71   0   0   0  10   0  96  10   4   1]\n",
      " [ 13   0  37   0   0   3   0   5   8   0   0]\n",
      " [  2   0   0  28   1   1   0   0   2   0   0]\n",
      " [ 25   2   0   0  47  19   0   5   0   0   0]\n",
      " [ 61   6   2   0   1 228   1  44  29   0   6]\n",
      " [ 15   1   1   0   1  37  33   1   2   0   0]\n",
      " [ 54  28   0   0   1  12   2 397  30   6   2]\n",
      " [ 37  10   4   2   2  65   0  73 228   3   5]\n",
      " [ 47  12   0   2   0  21   0  76  12  58   1]\n",
      " [ 23   1   0   0   0   6   0   9   6   0  95]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.57      0.92      0.70       494\n",
      "  Business/Finance       0.53      0.28      0.36       257\n",
      "       CAA-NRC-NPR       0.84      0.56      0.67        66\n",
      "       Coronavirus       0.88      0.82      0.85        34\n",
      "              Food       0.80      0.48      0.60        98\n",
      "     Non-Political       0.56      0.60      0.58       378\n",
      "       Photography       0.85      0.36      0.51        91\n",
      "    Policy/Economy       0.55      0.75      0.63       532\n",
      "          Politics       0.68      0.53      0.60       429\n",
      "Science/Technology       0.81      0.25      0.39       229\n",
      "            Sports       0.86      0.68      0.76       140\n",
      "\n",
      "          accuracy                           0.61      2748\n",
      "         macro avg       0.72      0.57      0.60      2748\n",
      "      weighted avg       0.64      0.61      0.59      2748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=df['stemmed_titles']+df['processed_url']\n",
    "y=df['flair']\n",
    "svmclassifier(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the various models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MLP model took lot of time to train and had low output scores, hence it was removed from further testing after initial runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(X,y,features):\n",
    "    print(\"TESTING THE  LOGISTIC REGRESSION MODEL \")\n",
    "    model_eval['Features'].append(features)\n",
    "    logregclassifier(X,y) #1\n",
    "    print(\"\\n TESTING THE RANDOM FORESTS MODEL \\n\")\n",
    "    model_eval['Features'].append(features)\n",
    "    rfclassifier(X,y) #2\n",
    "    #print(\"\\n TESTING THE MLP MODEL\")\n",
    "    #model_eval['Features'].append(features)\n",
    "    #mlpclassifier(X,y) #3\n",
    "    print(\"\\n TESTING THE SVM MODEL \")\n",
    "    model_eval['Features'].append(features)\n",
    "    svmclassifier(X,y) #4\n",
    "    print(\"\\n TESTING THE NAIVE BAYES MODEL\")\n",
    "    model_eval['Features'].append(features)\n",
    "    nbclassifier(X,y) #5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING ON COMBINED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_df.isna().sum()\n",
    "strip_df=strip_df.drop(strip_df[strip_df['stemmed_titles'].isna()].index)\n",
    "strip_df=strip_df.drop(strip_df[strip_df['title_comments_stem'].isna()].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING THE  LOGISTIC REGRESSION MODEL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[112  14   0   0   3   6   1   7   8  10   0]\n",
      " [ 15 131   0   0   4   6   1  21   6  20   1]\n",
      " [  2   0  57   0   0   1   1   2   3   1   1]\n",
      " [  1   0   1  23   2   0   0   0   1   0   0]\n",
      " [ 10   0   1   1  50  10   1   1   6   4   1]\n",
      " [  4   6   0   0   4 115   3   5  22   5   5]\n",
      " [  8   0   0   0   2  25  53   0   1   2   1]\n",
      " [  8  32   0   0   2   7   0 105  20  24   0]\n",
      " [  1   3   0   2   3  27   2  20 126   3   3]\n",
      " [ 20  14   0   0   2   9   2  15   5 140   2]\n",
      " [  9   0   0   0   3   8   2   0   3   2 112]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.59      0.70      0.64       161\n",
      "  Business/Finance       0.66      0.64      0.65       205\n",
      "       CAA-NRC-NPR       0.97      0.84      0.90        68\n",
      "       Coronavirus       0.88      0.82      0.85        28\n",
      "              Food       0.67      0.59      0.62        85\n",
      "     Non-Political       0.54      0.68      0.60       169\n",
      "       Photography       0.80      0.58      0.67        92\n",
      "    Policy/Economy       0.60      0.53      0.56       198\n",
      "          Politics       0.63      0.66      0.64       190\n",
      "Science/Technology       0.66      0.67      0.67       209\n",
      "            Sports       0.89      0.81      0.85       139\n",
      "\n",
      "          accuracy                           0.66      1544\n",
      "         macro avg       0.72      0.68      0.70      1544\n",
      "      weighted avg       0.67      0.66      0.67      1544\n",
      "\n",
      "\n",
      " TESTING THE RANDOM FORESTS MODEL \n",
      "\n",
      "confusion matrix\n",
      "[[139   3   0   0   0   3   0   2   8   6   0]\n",
      " [ 26 112   0   0   0  15   1  10   3  38   0]\n",
      " [  5   0  52   0   0   1   1   0   6   3   0]\n",
      " [  1   0   1  16   1   1   0   0   5   3   0]\n",
      " [ 17   0   0   2  27  18   5   0   4  10   2]\n",
      " [  4   0   0   0   1 133   3   4  16   5   3]\n",
      " [ 10   0   0   0   0  17  59   0   0   6   0]\n",
      " [ 11  30   0   0   0  12   0  89  28  28   0]\n",
      " [  2   1   0   0   0  34   3  10 127  11   2]\n",
      " [ 24  13   0   0   0  17   5   3   4 139   4]\n",
      " [ 13   5   0   0   3   8   2   1   7  10  90]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.55      0.86      0.67       161\n",
      "  Business/Finance       0.68      0.55      0.61       205\n",
      "       CAA-NRC-NPR       0.98      0.76      0.86        68\n",
      "       Coronavirus       0.89      0.57      0.70        28\n",
      "              Food       0.84      0.32      0.46        85\n",
      "     Non-Political       0.51      0.79      0.62       169\n",
      "       Photography       0.75      0.64      0.69        92\n",
      "    Policy/Economy       0.75      0.45      0.56       198\n",
      "          Politics       0.61      0.67      0.64       190\n",
      "Science/Technology       0.54      0.67      0.59       209\n",
      "            Sports       0.89      0.65      0.75       139\n",
      "\n",
      "          accuracy                           0.64      1544\n",
      "         macro avg       0.73      0.63      0.65      1544\n",
      "      weighted avg       0.68      0.64      0.63      1544\n",
      "\n",
      "\n",
      " TESTING THE SVM MODEL \n",
      "confusion matrix\n",
      "[[ 80  25   0   0   9   4   4  10  11  15   3]\n",
      " [ 10 133   0   0   5   1   1  21   8  19   7]\n",
      " [  2   0  57   0   1   0   0   1   3   2   2]\n",
      " [  1   0   0  24   2   0   0   0   1   0   0]\n",
      " [  4   1   1   1  66   3   0   1   6   2   0]\n",
      " [  3   6   0   0  14  99   4   6  20   3  14]\n",
      " [  3   1   0   0   4  28  48   1   2   1   4]\n",
      " [  6  34   3   2   1  11   1 102  19  13   6]\n",
      " [  1   7   4   3   3  14   5  16 126   5   6]\n",
      " [ 19  15   0   3   4  14   1  21   7 119   6]\n",
      " [  5   0   0   0   1   3   2   2   5   1 120]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.60      0.50      0.54       161\n",
      "  Business/Finance       0.60      0.65      0.62       205\n",
      "       CAA-NRC-NPR       0.88      0.84      0.86        68\n",
      "       Coronavirus       0.73      0.86      0.79        28\n",
      "              Food       0.60      0.78      0.68        85\n",
      "     Non-Political       0.56      0.59      0.57       169\n",
      "       Photography       0.73      0.52      0.61        92\n",
      "    Policy/Economy       0.56      0.52      0.54       198\n",
      "          Politics       0.61      0.66      0.63       190\n",
      "Science/Technology       0.66      0.57      0.61       209\n",
      "            Sports       0.71      0.86      0.78       139\n",
      "\n",
      "          accuracy                           0.63      1544\n",
      "         macro avg       0.66      0.67      0.66      1544\n",
      "      weighted avg       0.63      0.63      0.63      1544\n",
      "\n",
      "\n",
      " TESTING THE NAIVE BAYES MODEL\n",
      "confusion matrix\n",
      "[[ 45  17   0   0   0  56   0   6  31   6   0]\n",
      " [  6 112   0   0   0  15   0  27  29  16   0]\n",
      " [  1   0  11   0   0   1   0   4  49   2   0]\n",
      " [  2   0   0   0   0   4   0   2  14   6   0]\n",
      " [  2   0   0   0   7  52   0   1  18   5   0]\n",
      " [  0   0   0   0   0 132   0   2  34   0   1]\n",
      " [  3   0   0   0   0  74  10   1   3   1   0]\n",
      " [  0  14   0   0   0  17   0  98  64   5   0]\n",
      " [  0   1   0   0   0  18   0   8 159   3   1]\n",
      " [ 11   8   0   0   0  34   0  21  34 101   0]\n",
      " [  4   2   0   0   0  40   0   1  25   8  59]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.61      0.28      0.38       161\n",
      "  Business/Finance       0.73      0.55      0.62       205\n",
      "       CAA-NRC-NPR       1.00      0.16      0.28        68\n",
      "       Coronavirus       0.00      0.00      0.00        28\n",
      "              Food       1.00      0.08      0.15        85\n",
      "     Non-Political       0.30      0.78      0.43       169\n",
      "       Photography       1.00      0.11      0.20        92\n",
      "    Policy/Economy       0.57      0.49      0.53       198\n",
      "          Politics       0.35      0.84      0.49       190\n",
      "Science/Technology       0.66      0.48      0.56       209\n",
      "            Sports       0.97      0.42      0.59       139\n",
      "\n",
      "          accuracy                           0.48      1544\n",
      "         macro avg       0.65      0.38      0.38      1544\n",
      "      weighted avg       0.64      0.48      0.46      1544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X=strip_df['stemmed_titles']+strip_df['stem_comments']+strip_df['author']+strip_df['processed_url']\n",
    "y=strip_df['flair']\n",
    "test_models(X,y,'stemmed titles,stemmed comments,author,processed_url')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING ON TITLES + URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING THE  LOGISTIC REGRESSION MODEL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[437  15   0   0   3  15   1  11   8   4   1]\n",
      " [ 21 149   0   0   0  13   0  59   5   7   0]\n",
      " [  8   0  49   0   0   2   0   4   3   0   0]\n",
      " [  1   0   0  26   1   1   0   2   2   0   1]\n",
      " [ 19   2   0   1  47  12   1  10   1   4   1]\n",
      " [ 20   3   0   0   3 255  12  24  46   4   7]\n",
      " [ 14   5   0   0   1  35  36   1   3   0   0]\n",
      " [ 24  33   0   0   1  23   0 393  43  12   0]\n",
      " [ 20   8   0   0   0  68   4  52 272   5   1]\n",
      " [ 26  17   0   0   0  22   0  42  14 116   0]\n",
      " [ 16   1   0   0   0  13   2   4   2   6  91]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.72      0.88      0.79       495\n",
      "  Business/Finance       0.64      0.59      0.61       254\n",
      "       CAA-NRC-NPR       1.00      0.74      0.85        66\n",
      "       Coronavirus       0.96      0.76      0.85        34\n",
      "              Food       0.84      0.48      0.61        98\n",
      "     Non-Political       0.56      0.68      0.61       374\n",
      "       Photography       0.64      0.38      0.48        95\n",
      "    Policy/Economy       0.65      0.74      0.69       529\n",
      "          Politics       0.68      0.63      0.66       430\n",
      "Science/Technology       0.73      0.49      0.59       237\n",
      "            Sports       0.89      0.67      0.77       135\n",
      "\n",
      "          accuracy                           0.68      2747\n",
      "         macro avg       0.76      0.64      0.68      2747\n",
      "      weighted avg       0.69      0.68      0.68      2747\n",
      "\n",
      "\n",
      " TESTING THE RANDOM FORESTS MODEL \n",
      "\n",
      "confusion matrix\n",
      "[[465   0   0   0   3  17   0   7   1   1   1]\n",
      " [ 52  73   0   0   1  20   0 105   1   2   0]\n",
      " [ 11   0  46   0   0   4   0   2   3   0   0]\n",
      " [  4   0   0  26   1   2   0   1   0   0   0]\n",
      " [ 24   2   0   3  37  20   0  12   0   0   0]\n",
      " [ 30   1   0   0   1 278   1  43  15   0   5]\n",
      " [ 18   0   0   0   1  48  25   3   0   0   0]\n",
      " [ 64  11   0   0   0  23   0 407  22   2   0]\n",
      " [ 37   2   1   0   0  88   0  87 213   2   0]\n",
      " [ 47   4   0   0   0  39   0  78   5  64   0]\n",
      " [ 32   1   0   0   0  23   0  12   2   0  65]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.59      0.94      0.73       495\n",
      "  Business/Finance       0.78      0.29      0.42       254\n",
      "       CAA-NRC-NPR       0.98      0.70      0.81        66\n",
      "       Coronavirus       0.90      0.76      0.83        34\n",
      "              Food       0.84      0.38      0.52        98\n",
      "     Non-Political       0.49      0.74      0.59       374\n",
      "       Photography       0.96      0.26      0.41        95\n",
      "    Policy/Economy       0.54      0.77      0.63       529\n",
      "          Politics       0.81      0.50      0.62       430\n",
      "Science/Technology       0.90      0.27      0.42       237\n",
      "            Sports       0.92      0.48      0.63       135\n",
      "\n",
      "          accuracy                           0.62      2747\n",
      "         macro avg       0.79      0.55      0.60      2747\n",
      "      weighted avg       0.70      0.62      0.60      2747\n",
      "\n",
      "\n",
      " TESTING THE SVM MODEL \n",
      "confusion matrix\n",
      "[[444   4   0   0   8   9   2  17   9   1   1]\n",
      " [ 66  69   1   0   2   9   1  92   8   3   3]\n",
      " [ 13   0  37   0   0   3   0   5   8   0   0]\n",
      " [  2   0   0  28   1   2   0   0   1   0   0]\n",
      " [ 24   0   0   0  50  14   0   9   0   0   1]\n",
      " [ 57   5   0   0   3 228   5  44  25   1   6]\n",
      " [ 15   1   0   0   1  42  34   1   1   0   0]\n",
      " [ 66  18   0   0   1  19   1 382  35   5   2]\n",
      " [ 28   8   2   3   1  64   0  85 235   3   1]\n",
      " [ 53   7   1   2   0  20   3  64  19  66   2]\n",
      " [ 26   0   0   0   0   7   0   6   2   0  94]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.56      0.90      0.69       495\n",
      "  Business/Finance       0.62      0.27      0.38       254\n",
      "       CAA-NRC-NPR       0.90      0.56      0.69        66\n",
      "       Coronavirus       0.85      0.82      0.84        34\n",
      "              Food       0.75      0.51      0.61        98\n",
      "     Non-Political       0.55      0.61      0.58       374\n",
      "       Photography       0.74      0.36      0.48        95\n",
      "    Policy/Economy       0.54      0.72      0.62       529\n",
      "          Politics       0.69      0.55      0.61       430\n",
      "Science/Technology       0.84      0.28      0.42       237\n",
      "            Sports       0.85      0.70      0.77       135\n",
      "\n",
      "          accuracy                           0.61      2747\n",
      "         macro avg       0.72      0.57      0.61      2747\n",
      "      weighted avg       0.64      0.61      0.59      2747\n",
      "\n",
      "\n",
      " TESTING THE NAIVE BAYES MODEL\n",
      "confusion matrix\n",
      "[[424   2   0   0   0   6   0  58   5   0   0]\n",
      " [ 40  35   0   0   0   3   0 174   2   0   0]\n",
      " [ 14   0   4   0   0   2   0  35  11   0   0]\n",
      " [  1   0   0   0   0   1   0  25   7   0   0]\n",
      " [ 29   2   0   0   0  11   0  47   9   0   0]\n",
      " [ 55   2   0   0   0 187   0  83  44   0   3]\n",
      " [ 19   1   0   0   0  43  15  11   6   0   0]\n",
      " [ 18   4   0   0   0   5   0 493   9   0   0]\n",
      " [ 22   1   0   0   0  34   0 145 227   1   0]\n",
      " [ 45   4   0   0   0   7   0 146   7  28   0]\n",
      " [ 26   0   0   0   0  13   0  51   8   0  37]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.61      0.86      0.71       495\n",
      "  Business/Finance       0.69      0.14      0.23       254\n",
      "       CAA-NRC-NPR       1.00      0.06      0.11        66\n",
      "       Coronavirus       0.00      0.00      0.00        34\n",
      "              Food       0.00      0.00      0.00        98\n",
      "     Non-Political       0.60      0.50      0.55       374\n",
      "       Photography       1.00      0.16      0.27        95\n",
      "    Policy/Economy       0.39      0.93      0.55       529\n",
      "          Politics       0.68      0.53      0.59       430\n",
      "Science/Technology       0.97      0.12      0.21       237\n",
      "            Sports       0.93      0.27      0.42       135\n",
      "\n",
      "          accuracy                           0.53      2747\n",
      "         macro avg       0.62      0.32      0.33      2747\n",
      "      weighted avg       0.62      0.53      0.47      2747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X=df['stemmed_titles']+df['processed_url']\n",
    "y=df['flair']\n",
    "test_models(X,y,'stemmed_titles,processed_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING THE  LOGISTIC REGRESSION MODEL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[442  12   0   0   3  15   0  12   5   4   2]\n",
      " [ 25 146   0   0   0  11   0  61   4   7   0]\n",
      " [  8   0  51   0   0   2   0   2   1   2   0]\n",
      " [  1   0   0  27   1   0   0   2   1   0   2]\n",
      " [ 18   3   0   3  46  13   0   8   2   4   1]\n",
      " [ 20   7   0   0   5 258  10  22  40   6   6]\n",
      " [ 13   3   0   0   2  32  40   2   3   0   0]\n",
      " [ 25  38   0   0   1  18   0 403  34  10   0]\n",
      " [ 18   7   0   0   0  61   3  49 287   5   0]\n",
      " [ 25  15   0   0   0  18   1  41  15 120   2]\n",
      " [ 18   3   0   0   0  14   1   7   4   2  86]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.72      0.89      0.80       495\n",
      "  Business/Finance       0.62      0.57      0.60       254\n",
      "       CAA-NRC-NPR       1.00      0.77      0.87        66\n",
      "       Coronavirus       0.90      0.79      0.84        34\n",
      "              Food       0.79      0.47      0.59        98\n",
      "     Non-Political       0.58      0.69      0.63       374\n",
      "       Photography       0.73      0.42      0.53        95\n",
      "    Policy/Economy       0.66      0.76      0.71       529\n",
      "          Politics       0.72      0.67      0.69       430\n",
      "Science/Technology       0.75      0.51      0.60       237\n",
      "            Sports       0.87      0.64      0.74       135\n",
      "\n",
      "          accuracy                           0.69      2747\n",
      "         macro avg       0.76      0.65      0.69      2747\n",
      "      weighted avg       0.70      0.69      0.69      2747\n",
      "\n",
      "\n",
      " TESTING THE RANDOM FORESTS MODEL \n",
      "\n",
      "confusion matrix\n",
      "[[468   1   0   0   1  15   0   9   1   0   0]\n",
      " [ 39  85   0   0   0  16   0 113   1   0   0]\n",
      " [ 13   0  50   0   0   1   0   2   0   0   0]\n",
      " [  5   0   0  20   1   1   0   5   2   0   0]\n",
      " [ 26   0   0   3  35  15   0  18   1   0   0]\n",
      " [ 29   1   0   0   1 278   0  50  13   1   1]\n",
      " [ 22   0   0   0   1  46  24   2   0   0   0]\n",
      " [ 47  12   0   0   0  21   0 428  20   1   0]\n",
      " [ 36   2   0   0   0  85   0  97 207   3   0]\n",
      " [ 47   4   0   0   0  32   0  96   3  55   0]\n",
      " [ 36   1   0   0   0  19   0  16   4   0  59]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.61      0.95      0.74       495\n",
      "  Business/Finance       0.80      0.33      0.47       254\n",
      "       CAA-NRC-NPR       1.00      0.76      0.86        66\n",
      "       Coronavirus       0.87      0.59      0.70        34\n",
      "              Food       0.90      0.36      0.51        98\n",
      "     Non-Political       0.53      0.74      0.62       374\n",
      "       Photography       1.00      0.25      0.40        95\n",
      "    Policy/Economy       0.51      0.81      0.63       529\n",
      "          Politics       0.82      0.48      0.61       430\n",
      "Science/Technology       0.92      0.23      0.37       237\n",
      "            Sports       0.98      0.44      0.61       135\n",
      "\n",
      "          accuracy                           0.62      2747\n",
      "         macro avg       0.81      0.54      0.59      2747\n",
      "      weighted avg       0.71      0.62      0.60      2747\n",
      "\n",
      "\n",
      " TESTING THE SVM MODEL \n",
      "confusion matrix\n",
      "[[451   2   1   0   6  10   2  17   2   1   3]\n",
      " [ 75  65   4   0   2  11   4  79   6   4   4]\n",
      " [  6   0  50   0   0   0   1   3   6   0   0]\n",
      " [  1   0   0  30   0   0   1   1   1   0   0]\n",
      " [ 25   0   0   6  47   9   2   8   1   0   0]\n",
      " [ 36   4   2   0   4 249   9  39  21   3   7]\n",
      " [ 16   0   1   0   1  36  38   2   1   0   0]\n",
      " [ 52  26   3   0   0  13   5 387  35   4   4]\n",
      " [ 32   7   3   3   3  74   3  77 221   4   3]\n",
      " [ 51  10   3   2   0  16  14  56   9  71   5]\n",
      " [ 19   1   0   0   0  12   0   2   3   0  98]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.59      0.91      0.72       495\n",
      "  Business/Finance       0.57      0.26      0.35       254\n",
      "       CAA-NRC-NPR       0.75      0.76      0.75        66\n",
      "       Coronavirus       0.73      0.88      0.80        34\n",
      "              Food       0.75      0.48      0.58        98\n",
      "     Non-Political       0.58      0.67      0.62       374\n",
      "       Photography       0.48      0.40      0.44        95\n",
      "    Policy/Economy       0.58      0.73      0.65       529\n",
      "          Politics       0.72      0.51      0.60       430\n",
      "Science/Technology       0.82      0.30      0.44       237\n",
      "            Sports       0.79      0.73      0.76       135\n",
      "\n",
      "          accuracy                           0.62      2747\n",
      "         macro avg       0.67      0.60      0.61      2747\n",
      "      weighted avg       0.64      0.62      0.60      2747\n",
      "\n",
      "\n",
      " TESTING THE NAIVE BAYES MODEL\n",
      "confusion matrix\n",
      "[[445   0   0   0   0   2   0  46   2   0   0]\n",
      " [ 47  28   0   0   0   5   0 172   2   0   0]\n",
      " [ 13   0   1   0   0   1   0  38  13   0   0]\n",
      " [  3   0   0   0   0   1   0  23   7   0   0]\n",
      " [ 35   2   0   0   0  12   0  36  13   0   0]\n",
      " [ 60   2   0   0   0 216   0  68  28   0   0]\n",
      " [ 22   0   0   0   0  44  15   9   5   0   0]\n",
      " [ 26   1   0   0   0   3   0 492   7   0   0]\n",
      " [ 34   1   0   0   0  37   0 141 217   0   0]\n",
      " [ 57   3   0   0   0   9   0 137  10  21   0]\n",
      " [ 27   0   0   0   0  19   0  48   8   0  33]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.58      0.90      0.70       495\n",
      "  Business/Finance       0.76      0.11      0.19       254\n",
      "       CAA-NRC-NPR       1.00      0.02      0.03        66\n",
      "       Coronavirus       0.00      0.00      0.00        34\n",
      "              Food       0.00      0.00      0.00        98\n",
      "     Non-Political       0.62      0.58      0.60       374\n",
      "       Photography       1.00      0.16      0.27        95\n",
      "    Policy/Economy       0.41      0.93      0.57       529\n",
      "          Politics       0.70      0.50      0.58       430\n",
      "Science/Technology       1.00      0.09      0.16       237\n",
      "            Sports       1.00      0.24      0.39       135\n",
      "\n",
      "          accuracy                           0.53      2747\n",
      "         macro avg       0.64      0.32      0.32      2747\n",
      "      weighted avg       0.64      0.53      0.47      2747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X=df['title']+df['processed_url']\n",
    "y=df['flair']\n",
    "test_models(X,y,'title,processed_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING THE  LOGISTIC REGRESSION MODEL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[127   7   1   0   2   5   3   5   2   7   2]\n",
      " [ 17 142   0   0   2  10   0  15   4  15   0]\n",
      " [  3   0  59   0   0   0   0   3   3   0   0]\n",
      " [  1   0   0  25   0   0   0   0   1   0   1]\n",
      " [ 14   1   0   2  45  13   2   3   1   3   1]\n",
      " [  8   7   0   0   5 102   5   7  22   9   4]\n",
      " [  6   0   0   0   2  32  46   0   3   3   0]\n",
      " [  3  29   0   0   1   7   0 119  15  22   2]\n",
      " [  6   7   0   0   0  31   2  19 105  16   4]\n",
      " [ 20  16   0   0   2  15   0  22   6 124   4]\n",
      " [ 19   2   0   1   1  14   0   2   2   2  96]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.57      0.79      0.66       161\n",
      "  Business/Finance       0.67      0.69      0.68       205\n",
      "       CAA-NRC-NPR       0.98      0.87      0.92        68\n",
      "       Coronavirus       0.89      0.89      0.89        28\n",
      "              Food       0.75      0.53      0.62        85\n",
      "     Non-Political       0.45      0.60      0.51       169\n",
      "       Photography       0.79      0.50      0.61        92\n",
      "    Policy/Economy       0.61      0.60      0.61       198\n",
      "          Politics       0.64      0.55      0.59       190\n",
      "Science/Technology       0.62      0.59      0.60       209\n",
      "            Sports       0.84      0.69      0.76       139\n",
      "\n",
      "          accuracy                           0.64      1544\n",
      "         macro avg       0.71      0.66      0.68      1544\n",
      "      weighted avg       0.66      0.64      0.64      1544\n",
      "\n",
      "\n",
      " TESTING THE RANDOM FORESTS MODEL \n",
      "\n",
      "confusion matrix\n",
      "[[151   3   0   0   0   3   0   2   0   2   0]\n",
      " [ 23 123   0   0   1  16   0   4   4  34   0]\n",
      " [  4   1  58   0   0   0   0   3   2   0   0]\n",
      " [  2   0   0  23   0   0   0   0   2   1   0]\n",
      " [ 21   0   0   2  35  21   1   0   1   3   1]\n",
      " [ 20   1   0   0   2 112   1   4  17   9   3]\n",
      " [  9   0   0   0   1  49  29   0   2   2   0]\n",
      " [ 10  35   0   0   0  13   0  92  11  37   0]\n",
      " [ 17   4   1   0   0  53   0   8  76  28   3]\n",
      " [ 28  11   0   0   0  19   0  16   8 127   0]\n",
      " [ 29   1   0   1   1  13   0   1   2  10  81]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.48      0.94      0.64       161\n",
      "  Business/Finance       0.69      0.60      0.64       205\n",
      "       CAA-NRC-NPR       0.98      0.85      0.91        68\n",
      "       Coronavirus       0.88      0.82      0.85        28\n",
      "              Food       0.88      0.41      0.56        85\n",
      "     Non-Political       0.37      0.66      0.48       169\n",
      "       Photography       0.94      0.32      0.47        92\n",
      "    Policy/Economy       0.71      0.46      0.56       198\n",
      "          Politics       0.61      0.40      0.48       190\n",
      "Science/Technology       0.50      0.61      0.55       209\n",
      "            Sports       0.92      0.58      0.71       139\n",
      "\n",
      "          accuracy                           0.59      1544\n",
      "         macro avg       0.72      0.61      0.62      1544\n",
      "      weighted avg       0.66      0.59      0.59      1544\n",
      "\n",
      "\n",
      " TESTING THE SVM MODEL \n",
      "confusion matrix\n",
      "[[130  14   0   0   1   3   2   3   0   3   5]\n",
      " [ 17 139   0   0   4   6   2  10   1  15  11]\n",
      " [  3   0  57   0   0   0   0   0   5   1   2]\n",
      " [  1   0   0  25   1   0   0   0   1   0   0]\n",
      " [ 16   1   1   0  48   8   3   4   1   1   2]\n",
      " [ 15   9   0   1   7  82   6   7  18   9  15]\n",
      " [  5   0   0   0   4  29  44   2   3   4   1]\n",
      " [  7  38   3   0   3   4   2 108  11  15   7]\n",
      " [  3  11   4   2   2  32   3  23  82  15  13]\n",
      " [ 25  18   0   3   8  13   2  18   7  99  16]\n",
      " [ 18   1   0   1   1   8   0   2   1   1 106]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.54      0.81      0.65       161\n",
      "  Business/Finance       0.60      0.68      0.64       205\n",
      "       CAA-NRC-NPR       0.88      0.84      0.86        68\n",
      "       Coronavirus       0.78      0.89      0.83        28\n",
      "              Food       0.61      0.56      0.59        85\n",
      "     Non-Political       0.44      0.49      0.46       169\n",
      "       Photography       0.69      0.48      0.56        92\n",
      "    Policy/Economy       0.61      0.55      0.58       198\n",
      "          Politics       0.63      0.43      0.51       190\n",
      "Science/Technology       0.61      0.47      0.53       209\n",
      "            Sports       0.60      0.76      0.67       139\n",
      "\n",
      "          accuracy                           0.60      1544\n",
      "         macro avg       0.63      0.63      0.63      1544\n",
      "      weighted avg       0.60      0.60      0.59      1544\n",
      "\n",
      "\n",
      " TESTING THE NAIVE BAYES MODEL\n",
      "confusion matrix\n",
      "[[129   6   0   0   0   3   0   5   1  17   0]\n",
      " [ 14 139   0   0   0   7   0   9   2  33   1]\n",
      " [  9   0  34   0   0   1   0   1  13  10   0]\n",
      " [  1   0   0   1   1   0   0   2   7  16   0]\n",
      " [ 21   0   0   0  14  27   0   7   1  15   0]\n",
      " [ 10   4   0   0   0 109   0   6  18  19   3]\n",
      " [ 13   0   0   0   0  48  17   0   4  10   0]\n",
      " [  6  26   1   0   0   7   0 106  13  39   0]\n",
      " [  3   6   0   0   0  33   0  21  95  29   3]\n",
      " [ 18   7   0   0   0  14   0  11   7 152   0]\n",
      " [ 21   3   0   1   0  11   0   5   4  16  78]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.53      0.80      0.64       161\n",
      "  Business/Finance       0.73      0.68      0.70       205\n",
      "       CAA-NRC-NPR       0.97      0.50      0.66        68\n",
      "       Coronavirus       0.50      0.04      0.07        28\n",
      "              Food       0.93      0.16      0.28        85\n",
      "     Non-Political       0.42      0.64      0.51       169\n",
      "       Photography       1.00      0.18      0.31        92\n",
      "    Policy/Economy       0.61      0.54      0.57       198\n",
      "          Politics       0.58      0.50      0.54       190\n",
      "Science/Technology       0.43      0.73      0.54       209\n",
      "            Sports       0.92      0.56      0.70       139\n",
      "\n",
      "          accuracy                           0.57      1544\n",
      "         macro avg       0.69      0.48      0.50      1544\n",
      "      weighted avg       0.65      0.57      0.55      1544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=strip_df['title']+strip_df['processed_url']\n",
    "y=strip_df['flair']\n",
    "test_models(X,y,'title,processed_url(reduced_data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING THE  LOGISTIC REGRESSION MODEL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[134  24   1  16   2   3   4   3   3   0   0]\n",
      " [ 22 118   3   4   4   6   5   5   2   0   0]\n",
      " [  9   6 110   6  16  10   0   3   1   0   0]\n",
      " [ 22   6   5 109  35  17   1   3   0   0   0]\n",
      " [  5   7  11  19 137  21   1   4   0   0   0]\n",
      " [  5   9  20  19  13 138   2   1   2   0   0]\n",
      " [  3   8  10   0   1   4 109   3   1   0   0]\n",
      " [  5   9  12   1   2   3   1  50   1   1   0]\n",
      " [  2  23   7   0   0   9   0   2  49   0   0]\n",
      " [  2   0   1   3   0   1   1   0   1  59   0]\n",
      " [  1   0   0   1   0   0   0   2   1   1  22]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.71      0.67       190\n",
      "           1       0.56      0.70      0.62       169\n",
      "           2       0.61      0.68      0.65       161\n",
      "           3       0.61      0.55      0.58       198\n",
      "           4       0.65      0.67      0.66       205\n",
      "           5       0.65      0.66      0.66       209\n",
      "           6       0.88      0.78      0.83       139\n",
      "           7       0.66      0.59      0.62        85\n",
      "           8       0.80      0.53      0.64        92\n",
      "           9       0.97      0.87      0.91        68\n",
      "          10       1.00      0.79      0.88        28\n",
      "\n",
      "    accuracy                           0.67      1544\n",
      "   macro avg       0.73      0.68      0.70      1544\n",
      "weighted avg       0.68      0.67      0.67      1544\n",
      "\n",
      "\n",
      " TESTING THE RANDOM FORESTS MODEL \n",
      "\n",
      "confusion matrix\n",
      "[[132  28   2  11   3   9   2   0   2   0   1]\n",
      " [ 17 129   4   3   1   8   2   2   3   0   0]\n",
      " [  8   4 137   3   2   7   0   0   0   0   0]\n",
      " [ 32  10  11  77  27  39   0   2   0   0   0]\n",
      " [  4  15  21  11 108  45   0   1   0   0   0]\n",
      " [  6  15  24   7  14 136   3   0   4   0   0]\n",
      " [  7   8  11   0   5  12  92   3   1   0   0]\n",
      " [  4  20  14   1   0  14   1  27   3   0   1]\n",
      " [  0  17   8   0   0  19   0   0  48   0   0]\n",
      " [  5   0   0   0   0   3   0   0   1  59   0]\n",
      " [  6   1   1   0   0   4   0   1   0   1  14]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.69      0.64       190\n",
      "           1       0.52      0.76      0.62       169\n",
      "           2       0.59      0.85      0.70       161\n",
      "           3       0.68      0.39      0.50       198\n",
      "           4       0.68      0.53      0.59       205\n",
      "           5       0.46      0.65      0.54       209\n",
      "           6       0.92      0.66      0.77       139\n",
      "           7       0.75      0.32      0.45        85\n",
      "           8       0.77      0.52      0.62        92\n",
      "           9       0.98      0.87      0.92        68\n",
      "          10       0.88      0.50      0.64        28\n",
      "\n",
      "    accuracy                           0.62      1544\n",
      "   macro avg       0.71      0.61      0.63      1544\n",
      "weighted avg       0.66      0.62      0.62      1544\n",
      "\n",
      "\n",
      " TESTING THE SVM MODEL \n",
      "confusion matrix\n",
      "[[130  16   1  14   4   6   7   3   3   4   2]\n",
      " [ 25  96   4   7   5   2  13  14   3   0   0]\n",
      " [ 10   3  97   7  21   7   4   7   3   1   1]\n",
      " [ 25   9   5  97  37  11   6   2   4   1   1]\n",
      " [  9   3  11  21 129  17   7   5   3   0   0]\n",
      " [  5  13  26  20  14 113   9   3   4   0   2]\n",
      " [  4   4   7   1   1   2 119   1   0   0   0]\n",
      " [  6   3   5   2   0   2   0  62   2   1   2]\n",
      " [  1  31   7   1   1   5   4   4  37   1   0]\n",
      " [  3   0   3   0   0   0   1   1   0  60   0]\n",
      " [  1   0   1   0   0   0   0   2   0   0  24]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.68      0.64       190\n",
      "           1       0.54      0.57      0.55       169\n",
      "           2       0.58      0.60      0.59       161\n",
      "           3       0.57      0.49      0.53       198\n",
      "           4       0.61      0.63      0.62       205\n",
      "           5       0.68      0.54      0.60       209\n",
      "           6       0.70      0.86      0.77       139\n",
      "           7       0.60      0.73      0.66        85\n",
      "           8       0.63      0.40      0.49        92\n",
      "           9       0.88      0.88      0.88        68\n",
      "          10       0.75      0.86      0.80        28\n",
      "\n",
      "    accuracy                           0.62      1544\n",
      "   macro avg       0.65      0.66      0.65      1544\n",
      "weighted avg       0.62      0.62      0.62      1544\n",
      "\n",
      "\n",
      " TESTING THE NAIVE BAYES MODEL\n",
      "confusion matrix\n",
      "[[160  19   0   8   0   2   1   0   0   0   0]\n",
      " [ 35 132   0   1   0   0   1   0   0   0   0]\n",
      " [ 29  54  48   5  18   7   0   0   0   0   0]\n",
      " [ 62  16   1  97  13   9   0   0   0   0   0]\n",
      " [ 26  14   6  24 111  24   0   0   0   0   0]\n",
      " [ 33  39  10  17   5 105   0   0   0   0   0]\n",
      " [ 28  43   4   1   2  11  50   0   0   0   0]\n",
      " [ 18  49   7   1   0   6   0   4   0   0   0]\n",
      " [  3  65   7   0   0   8   0   0   9   0   0]\n",
      " [ 40   2   1   3   0   9   0   0   0  13   0]\n",
      " [ 16   3   1   1   0   7   0   0   0   0   0]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.84      0.50       190\n",
      "           1       0.30      0.78      0.44       169\n",
      "           2       0.56      0.30      0.39       161\n",
      "           3       0.61      0.49      0.54       198\n",
      "           4       0.74      0.54      0.63       205\n",
      "           5       0.56      0.50      0.53       209\n",
      "           6       0.96      0.36      0.52       139\n",
      "           7       1.00      0.05      0.09        85\n",
      "           8       1.00      0.10      0.18        92\n",
      "           9       1.00      0.19      0.32        68\n",
      "          10       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.47      1544\n",
      "   macro avg       0.65      0.38      0.38      1544\n",
      "weighted avg       0.63      0.47      0.45      1544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X=strip_df['title']+strip_df['processed_url']+strip_df['author']+strip_df['stem_comments']\n",
    "y=strip_df['numerical_flair']\n",
    "test_models(X,y,'title,processed_url,author,stemmed_comments(reduced data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_strip=pd.read_csv('sec_strip_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21480ec5940>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAFjCAYAAAAzecDDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcnWV9/vHPRUDABTeCIiBBlipaFg0WS60sFgFlcWFTFJGKVFSw1orYKvZXrFZBrXsUEVwQECi4IRg2kTVgZKcioLJIgrIJKgau3x/3c5KTySQzk5n7OZlnrvfrNa8555kz870nmfnO/dzL95ZtIiKiu1YadAMiIqKuJPqIiI5Loo+I6Lgk+oiIjkuij4jouCT6iIiOS6KPiOi4JPqIiI5Loo+I6LiVB90AgDXXXNMzZswYdDMiIiaVK6+88h7b00d63QqR6GfMmMGcOXMG3YyIiElF0q9G87oM3UREdFwSfURExyXRR0R0XBJ9RETHJdFHRHRcEn1ERMcl0UdEdFwSfUREx60QG6ZGMuPw7y/359720VdOYEsiIiaf9OgjIjouiT4iouMmxdBNTA0ZoouoIz36iIiOS6KPiOi4DN1ExJQwlYcG06OPiOi4JPqIiI5Loo+I6Lgk+oiIjkuij4jouKy6iRiQ8awCgcm/EiTaM2KPXtJqki6X9HNJ10n6cHN9A0mXSfqFpJMkPa65vmrz/Obm4zPqfgsREbEsoxm6+TOwve3NgS2AnSRtDXwM+KTtjYF7gQOb1x8I3Gt7I+CTzesiImJARkz0Lv7QPF2leTOwPfCd5vrxwB7N492b5zQf30GSJqzFERExJqOajJU0TdJcYB5wDvBL4D7bC5qX3A6s0zxeB/gNQPPx+4GnD/M1D5I0R9Kc+fPnj++7iIiIpRpVorf9qO0tgHWBFwPPG+5lzfvheu9e4oI9y/ZM2zOnT58+2vZGRMQYjWl5pe37gPOBrYGnSOqt2lkXuLN5fDuwHkDz8ScDv5+IxkZExNiNZtXNdElPaR6vDrwcuAE4D3hd87L9gTOax2c2z2k+fq7tJXr0ERHRjtGso18bOF7SNMofhpNtf0/S9cC3Jf0n8DPg2Ob1xwJfl3QzpSe/T4V2R0TEKI2Y6G1fDWw5zPVbKOP1Q6//CdhzQloXERHjlhIIEREdl0QfEdFxqXUTEa1JfZ/BSI8+IqLjkugjIjouiT4iouOS6CMiOi6TscswnomjTBpFxIoiPfqIiI5Loo+I6Lgk+oiIjkuij4jouCT6iIiOS6KPiOi4JPqIiI5Loo+I6Lgk+oiIjkuij4jouCT6iIiOS6KPiOi4JPqIiI5Loo+I6Lgk+oiIjhsx0UtaT9J5km6QdJ2kQ5vrR0q6Q9Lc5m2Xvs95v6SbJd0k6RU1v4GIiFi20Rw8sgB4j+2rJD0JuFLSOc3HPmn7E/0vlrQpsA/wfOBZwI8lbWL70YlseEREjM6Iid72XcBdzeMHJd0ArLOMT9kd+LbtPwO3SroZeDFwyQS0NyImQE5Pm1rGNEYvaQawJXBZc+kdkq6W9FVJT22urQP8pu/TbmeYPwySDpI0R9Kc+fPnj7nhERExOqNO9JKeCJwKHGb7AeALwIbAFpQe/9G9lw7z6V7igj3L9kzbM6dPnz7mhkdExOiM6nBwSatQkvw3bZ8GYPvuvo9/Gfhe8/R2YL2+T18XuHNCWhsRMcmsCMNko1l1I+BY4Abbx/RdX7vvZa8Grm0enwnsI2lVSRsAGwOXT0hrIyJizEbTo98GeCNwjaS5zbUjgH0lbUEZlrkNeBuA7esknQxcT1mxc0hW3EREDM5oVt1cxPDj7j9YxuccBRw1jnZFRMQEyc7YiIiOS6KPiOi4JPqIiI5Loo+I6Lgk+oiIjkuij4jouCT6iIiOS6KPiOi4JPqIiI5Loo+I6Lgk+oiIjkuij4jouCT6iIiOS6KPiOi4JPqIiI5Loo+I6Lgk+oiIjkuij4jouCT6iIiOS6KPiOi4JPqIiI5Loo+I6Lgk+oiIjlt5pBdIWg84AXgm8Bgwy/anJT0NOAmYAdwG7GX7XkkCPg3sAjwMvNn2VXWaHzF+Mw7//nJ/7m0ffeUEtiSijtH06BcA77H9PGBr4BBJmwKHA7NtbwzMbp4D7Axs3LwdBHxhwlsdERGjNmKit31Xr0du+0HgBmAdYHfg+OZlxwN7NI93B05wcSnwFElrT3jLIyJiVMY0Ri9pBrAlcBnwDNt3QfljAKzVvGwd4Dd9n3Z7c23o1zpI0hxJc+bPnz/2lkdExKiMOtFLeiJwKnCY7QeW9dJhrnmJC/Ys2zNtz5w+ffpomxEREWM04mQsgKRVKEn+m7ZPay7fLWlt23c1QzPzmuu3A+v1ffq6wJ0T1eCpIhOEETFRRuzRN6tojgVusH1M34fOBPZvHu8PnNF3/U0qtgbu7w3xRERE+0bTo98GeCNwjaS5zbUjgI8CJ0s6EPg1sGfzsR9QllbeTFleecCEtjgiIsZkxERv+yKGH3cH2GGY1xs4ZJztioiICZKdsRERHZdEHxHRcUn0EREdl0QfEdFxSfQRER2XRB8R0XFJ9BERHZdEHxHRcUn0EREdl0QfEdFxSfQRER2XRB8R0XFJ9BERHZdEHxHRcUn0EREdl0QfEdFxSfQRER2XRB8R0XFJ9BERHZdEHxHRcUn0EREdl0QfEdFxSfQRER03YqKX9FVJ8yRd23ftSEl3SJrbvO3S97H3S7pZ0k2SXlGr4RERMTqj6dF/DdhpmOuftL1F8/YDAEmbAvsAz28+5/OSpk1UYyMiYuxGTPS2LwR+P8qvtzvwbdt/tn0rcDPw4nG0LyIixmk8Y/TvkHR1M7Tz1ObaOsBv+l5ze3NtCZIOkjRH0pz58+ePoxkREbEsy5vovwBsCGwB3AUc3VzXMK/1cF/A9izbM23PnD59+nI2IyIiRrJcid723bYftf0Y8GUWDc/cDqzX99J1gTvH18SIiBiP5Ur0ktbue/pqoLci50xgH0mrStoA2Bi4fHxNjIiI8Vh5pBdIOhHYFlhT0u3Ah4BtJW1BGZa5DXgbgO3rJJ0MXA8sAA6x/WidpkdExGiMmOht7zvM5WOX8fqjgKPG06iIiJg42RkbEdFxSfQRER2XRB8R0XFJ9BERHZdEHxHRcUn0EREdl0QfEdFxI66jj6llxuHfX+7Pve2jr5zAlkTEREmPPiKi45LoIyI6Lok+IqLjkugjIjouiT4iouOS6CMiOi6JPiKi45LoIyI6Lok+IqLjkugjIjouiT4iouOS6CMiOi6JPiKi45LoIyI6bsREL+mrkuZJurbv2tMknSPpF837pzbXJel/JN0s6WpJL6zZ+IiIGNloevRfA3Yacu1wYLbtjYHZzXOAnYGNm7eDgC9MTDMjImJ5jZjobV8I/H7I5d2B45vHxwN79F0/wcWlwFMkrT1RjY2IiLFb3jH6Z9i+C6B5v1ZzfR3gN32vu725tgRJB0maI2nO/Pnzl7MZERExkomejNUw1zzcC23Psj3T9szp06dPcDMiIqJneRP93b0hmeb9vOb67cB6fa9bF7hz+ZsXERHjtbyJ/kxg/+bx/sAZfdff1Ky+2Rq4vzfEExERg7HySC+QdCKwLbCmpNuBDwEfBU6WdCDwa2DP5uU/AHYBbgYeBg6o0OaIiBiDERO97X2X8qEdhnmtgUPG26iIiJg42RkbEdFxSfQRER2XRB8R0XFJ9BERHZdEHxHRcUn0EREdl0QfEdFxSfQRER2XRB8R0XFJ9BERHZdEHxHRcUn0EREdl0QfEdFxSfQRER2XRB8R0XFJ9BERHZdEHxHRcUn0EREdl0QfEdFxSfQRER2XRB8R0XFJ9BERHZdEHxHRcSuP55Ml3QY8CDwKLLA9U9LTgJOAGcBtwF627x1fMyMiYnlNRI9+O9tb2J7ZPD8cmG17Y2B28zwiIgakxtDN7sDxzePjgT0qxIiIiFEab6I3cLakKyUd1Fx7hu27AJr3aw33iZIOkjRH0pz58+ePsxkREbE04xqjB7axfaektYBzJN042k+0PQuYBTBz5kyPsx0REbEU4+rR276zeT8POB14MXC3pLUBmvfzxtvIiIhYfsud6CU9QdKTeo+BHYFrgTOB/ZuX7Q+cMd5GRkTE8hvP0M0zgNMl9b7Ot2yfJekK4GRJBwK/BvYcfzMjImJ5LXeit30LsPkw138H7DCeRkVExMTJztiIiI5Loo+I6Lgk+oiIjkuij4jouCT6iIiOS6KPiOi4JPqIiI5Loo+I6Lgk+oiIjkuij4jouCT6iIiOS6KPiOi4JPqIiI5Loo+I6Lgk+oiIjkuij4jouCT6iIiOS6KPiOi4JPqIiI5Loo+I6Lgk+oiIjkuij4jouCT6iIiOq5boJe0k6SZJN0s6vFaciIhYtiqJXtI04HPAzsCmwL6SNq0RKyIilq1Wj/7FwM22b7H9CPBtYPdKsSIiYhlke+K/qPQ6YCfb/9g8fyPwN7bf0feag4CDmqd/Bdy0nOHWBO4ZR3PHY1Cx8z1PjdhTLe4gY0/W73l929NHetHKy/nFR6Jhri32F8X2LGDWuANJc2zPHO/XmUyx8z1PjdhTLe4gY3f9e641dHM7sF7f83WBOyvFioiIZaiV6K8ANpa0gaTHAfsAZ1aKFRERy1Bl6Mb2AknvAH4ETAO+avu6GrGYgOGfSRg73/PUiD3V4g4ydqe/5yqTsRERseLIztiIiI5Loo+I6Lgk+oiIjkuij4jouCT65SBpfUkvbx6vLulJA2rHE1qIsaGkVZvH20p6l6SnVI75wmW91Yw9aE2dqEHEPVXSKyW1nhMk7dn7HZL0b5JOa+P/WdLzascYRRueKmmz6nEm26obSasBBwLPB1brXbf9lpbiv5VSuuFptjeUtDHwRds7VIy5DrA2cLXtRyStBRwGvNn2s2rFbWLPBWYCMyjLZc8E/sr2LhVjntc8XK2J/XPKbuvNgMts/13F2J9hyC7ufrbfVSt2E/9W4DvAcbavrxlrSNyXAwcAWwOnAF+zfWNLsa+2vZmkvwP+C/gEcITtv6kc91LK//VxwIm2H6wZry/u+cBulOXtc4H5wAW2/7lWzMnYo/868EzgFcAFlF23rfwHNQ4BtgEeALD9C2CtWsEkHUb5YfgMcKmk/YEbgNWBF9WK2+cx2wuAVwOfsv1uyh+damxvZ3s74FfAC23PtP0iYEvg5pqxgTnAlct4q20z4P+Ar0i6VNJBktaoHdT2j22/AXghcBtwjqSLJR0gaZXK4R9t3r8S+ILtM4DHVY6J7a2BtwAbA3MlnSBpu9pxgSfbfgB4DeUP+ouAl1eNaHtSvQE/a95f3bxfBTi3xfiXDWnHyr22VIp3PeXuAeDZwCPA1m1+v8C+wLXABs21a1uKPXc017r6Bvw9cAfwEHA8sFHleE8HDqX8sTsT2JvSwTi/ctzvAV8Cfgk8BVgV+HmL/84rUToydwC/aH7ndq8Y7xpKZ+lsYKvmWrUcYrtaUbOa/tK8v0/SC4DfUoYV2nKBpCOA1SX9A/B24LsV4/3J9u8BbP9a0v/ZvrRivKEOAA4GjrJ9q6QNgG+0FPsGSV9p4hnYj3I3U52k6cD7KOcp9A8Rbl857jRKz/YAys/10cA3gZcCPwA2qRT3NOC5lDvmXW3f1XzoJElzasTssxewE/AJ2/dJWht4b+WYNGdkHEAZRjkfeLXtyyWtB1wEnFEp9Icpw6AX2b5C0nMof2CqmYxj9P8InEq5xT0OeCLwQdtfbCn+SpQ5gh0p48Y/Ar7iSv+QkuZR6vn37NP/3JXHjAepmY/5J0rPFuBCyq39n1qIfTZwEvAvlD90+wPzbb+vctxbgPOAY21fPORj/1Pr/1vS9rbPrfG1RxF7a+A6N2PkzcTsprYvqxz3p8BXgJNsPzzkY2+2/bVKcbex/dORrk1ozMmW6AetWenyJ9uPNs+nAasO/UGZwHj7L+vjto+vEbcv/q0MMzlp+zk14/bFfxzlvAIDN9n+ywifMlFxr7T9ot5EYXPtAtsvqxz3ibb/UDPGUuL27iRm0FcDy/YxLcT+GWUuxs3zlYA5tju5wkrSVUO/t+GuTaRJM3QjaT/b35A07Mx0Gz+QjdmUiZPeL+PqlLG2v60RzPbxzTDC+pRTu+6rEWcZ+utkrwbsCTytjcCStqWMTd9GuXtaT9L+ti9sIXzvD8pdkl5JKbO9bgtxV5f0LpZMuLVXlX0X+BNl/PixyrGGUv8dse3HJFXPTc0fmKGdmPspcxT/1RsyncB4L6HkielD8tgalOKP1UyaRA/01owPZM16n9X6e1y2/yDp8bWCNUNVH6FMVG0g6SDbrZV8tv27IZc+Jeki4IMthD8a2NH2TQCSNgFOpJ3VRv8p6cnAeygTkmsA724h7hnAT4Afs2g1ShvW7d25DMAtzR+3LzTP3w7c0kLccygdiG81z/eh/Jv/AfgaZex+Ij2OMtS8MovnsQeA101wrMVk6GaMmnG9d9q+qnn+IuCztl9SKd61wHa25zeTNt+sFWsp8ftvJ1ei9PD/yfbmLcS+emjyGe5al0iaa3uLAcT9GDDb9tkDiL0W8D/A9pQe9mzgMNvzKse9yEP2ZPSuSbrG9l9XiDmNMidQNbEPNWl69JL+Z1kfb3FS8jDgFEm9E7PWpixDq+UR2/MBbN+iZpdqi47ue7wAuJWySqINcyQdS1kJAvAG2lnLjqTjgUN7Q2WSngoc3cIQyvck7WL7B5XjDHUpcHozPv4XSk/XtttYwz+P0ptu25Mkvcj2lbCwU9P7fhfUCGj7UUmtDH32mzQ9+r5JyW0oS95Oap7vCVzpspGnrbasQpkgFHBjzQnCQa66aX7p97R90ogvrhN/VcoGtb+j/FtfCHze9p9biP0z21uOdG0C4z1I6c2KMkz5CIvmCaon3Ga1zx7ANbVWkA0T819t//fSdiPX7rw1q32+StmLI8q/+Vso8xS72T6xUtyjKZu0TqHskQDA9mk14sEkSvQ9zfb4HXvJtUm6Z7vspGyrDX/LkpNlJ1SKNehVNxfa/vuRX1kt/qBW3fwc2Nb2vc3zp1G2qU/47fyKQNKPgJ1ttzYRK2lX299d2s947Z/tvnY8nZIL72kp3nHDXHbNu8VJM3TT51mUiYzejPgTm2utkPR1YENKWYLeZJmBKom+rR/2ZThH0r9Q7qD6ex8TuiJhOANedXM0cLGk7zTP9wSOaiEukl5DuYsx8BPb/9tC2LuA8yX9EFh4x1RzNZvt3kbDh22f0v8xSXvWitsX40nAv9Ps01CpQXOUK9e8sX1Aza8/nMnYoz8AOJKyqQTgZcCRLf71v4GymaOt29vjWHqRLds+sHL8W5cSt/o6eklXAq8fuurGpTZIdc3Oye0pf2Rmu4UiY5I+D2xEWV0EZf7nl7YPqRz3Q8Ndt/3hmnGb2K2vK29inEKpK9TLHW8Enld7olTSupSVXNtQfrcvoswH3V4t5mRL9ACSngn0KttdZvu3LcY+BXiXF20Rrx3vtcNcfjZlUnia7TbWdg/EIFbdSFrD9gNLmzCrfScj6TrgBUM2D11j+/k14/bFfxLlD3n1TVuSdgZ2oUzu988DrUHpTL24cvwlVji1sepJ0jmUJZ29RQb7AW+w/Q+1Yk7GoRsomwvmU9q/iaRNWrqdB1gTuF7S5Sx+izvRa257X/fU3uNmeeURlFvNjwLH1ojZxNre9rnNMMJw7ao2cdRnEKtuvgW8qonT3wtS87z2ncxNlD/kv2qerwdcXTkmKnWjvk6zGU7SPcCbbF9XMeydlM1Ju7H4/+uDtLNn4U+SXmL7Elg4OVu9vAYw3Xb/OP3XVKrUVjPpevTNet+9getYtIPPtRLtMPGH3QJv+4KKMZ8HfIBSpvfjwDdcSgdXI+nDtj80iImjvjYMbNXNoEi6ANgKuLy5tBVwCfAw1OtQSLoY+IDt85rn2wIfsV1lx/eQ2CvX/nleStwXUv64rUr5+XqY8sftZ5Xj/piyIas3PLcvcIBrnmkxCRP9TcBmXf5l79cMFc2kHMZwMkN2S7YwlDDNTV2ftkh6tu1ftxlzmDbMHvqLN9y1CnGXWUunVodC0s+HboIb7toExzzZ9l6SrmH45ZWtbIxrhunkJXeB14r3bOCzQG/j408pY/S/WvpnjTPmJEz0P6Ss7W698FMTf2vKRMrzKFuapwEP1VrnLOk2Fv0S9N6r97z2pKikXwNnUcZQz21jErp/Ik7SqbaHm6eoFXs14PGUyf5tWfRvvQbwQ9sDP36uBkmnA1ex+LjxTNt7VIy5tu27JK0/3MdrJT6VcgtLZXuZmzMno8k4Rv8w5TSY2Sw+Rt7WztjPUjYt9Xrab6JsfqjC9oxaX3uU/grYlTKEcqyk7wHftn1RxZjqe9xKlcw+b6NMdD+Lkvh6HgA+Vzt42x2JPm+h1Ek/jUXDZFWXAfYWNNTsyS7F9JbjLaaZa/s05dhGU4bm3m27Wn2fydijH/Tmijm2Z2rx8rUXtzGW2deGI20f2Va8vrhPpfyAvsF2tWp7Q3r01ZfZLaUN77T9mQHEncMwHQnbR7Tdltr6dgMvvMSi3cFu4Y/bQKicVfs5Fo3R70Opn1XtjNxJ16NfATYQPdzs1pwr6b8pG02eMMLnTLTdKHsJWtGMG+8N7AxcQf1aN5tLeoDyC7968xhaSABadADHHcOtOGpjtZHtm/vmRo5rJkqravYo/AtL7viudqKW7YFWopX0LErHpVfY7EJKz/rOpX/WxIS2/fW+59+Q9I6aASdNol/ahE1PWxM3lE0VKwHvoCwBWw9obQy5oZFfMkGByoapuZSJ4PfafmiETxm3mncLo/Ay4FzKcNVQpgxt1DSojsQpwBcpJy61OvkOIGlzynGJABfarr6klHJC3Xco8xFQfrePA15ROe55kg6n1KwypRP1/d7ejRoLLCbN0M3SJmx6BjDONzCSVnJLNUl6G4jaiBULf87vpozPvxt4MmVJ6c2V417Z1o7jYWIfCryVRX9EXw3Mqj10NsANU73d5kMXV0ClBRaTJtH3SNrZ9g+HXDvY7Z0Zuw1l2GR9Fr/FrTJp2PTqbhn6/Ul6N/BM1z/DdDXKGbnPZ/FDsquvox8ELeUEsx5XrP2iUqv8eNv7jfjiiY99JDAPOJ3FFzm0UdPoauAlvbtFleM6L6l9ly7pXGAWi3bl7gW8rdZwlaStgN/0dvI3842vpdRyOrLmv/VKtb5wRf8uaeF/hKT3Abu3GP9Y4BjKuN5WfW+1vIrywzjUpylnfNb2deCZlNvZCyjH6VUt+jRgTxrhrZpmTH56M3TTtv2B9wIXU3apXknZtdoGsfhw0aO0Mzz5Fspk9z2UnfZvpHRqavkSpRQykv4e+C9KnZ37Gf53fMJMmjH6PrtRDmd4L7AT8Fwm/sivZbl/6B1FZR5umMblXM02fhk2sr2npN1dzq/9FvCjFuIOhFso4jWC24CfSjqTxauFVj0T2fYGNb/+CI4DLmvW8kOpi1+tvEeP7dsotXbaMq2v1743ZXjqVOBUSXNrBp50id72PZJ2o5ypeSXwujY28fQ5T9LHKeOJ/be4Vy39U8blYUkb2/5F/0VJGwN/rBSzX6/++31NPZTfUlZmdJoGUGGwcWfzthItno+scq7DP9GU7AXOB77kFur/2z5GpURwr9TFAbXLEABIWpPSq5/B4sOwB1UKOa2v3MMOQH+cqrl40iR6LX4CjymTVc8BXiepzTW3vbWuM/uumVLOtoYPAj+U9J8sKvw0E3g/ZWNPbbOa9fP/DpxJqf/fxsHgg3YcpcBZry76fs21ahUGYaB3FF+gnLT0+eb5G5tr/1grYDP/czClLPM1lEnnNmvenEE5QvEi2llpdCJwQVMw7o+UQ+CRtBFl+KaaSTcZOxU1Pen3Ai9oLl0LfML2NYNrVbcNcEXGd1lyGfH9lPHyL9muUl1xQLVuTqLcMf6EskfjNtttdF568Vs/iL3Z+bw25VS83uTzJsATK44KTJ4efU+z6mWu7Yck7Qe8EPhU7SJYkvaz/Y2lrcqoOYZq+1rKZNnQNq1fe1mpSgXJ17Lk7e1/1Iy7Arin+fnqrzDYRtGrWyhb9PsPHrkb2AT4MqWnXcOjkja0/UtYuE2/di93UzdHM6qUo758hNdPtB9K2tH22W0FtH3pMNf+r3bcSZfoKbeTmzcbLP6VMmnzdcpGl5p6m1Za380n6SXAOpSNJPMkbQYcTtlgsl7l8GdQepRX0jcnMQW8hVLX6JOUHvbFzbXatvTiZ/R+V825vSqHktTyXsr80y2U4dH1qVzrhkXzP9he0M7agsUcDLxP0sOU1TC9ndfDHjozmU26oZte7RNJHwTusH3soOqhtKGZ+H0VZXfqRsD3gLcDH6HirXxf/Gttv2DkV3aLpDXd0mHRQ+LeALyid4eqUtL2LNubSvqZ7S0rxl6VUsROwI2uXApc0qMsWlkkYHVK0cJWat00+xaW4JbLcrdhMvboH5T0fsot7Eub/6zq34eks23v2Dx+v+3/qh2z8UpKL+9PzaTonZR6/L8Y4fMmysWS/nqqzAdI2hX4KrCgSUR72a5ea6bPe4CLJP2SkvA2AN7ebCKqVudJ0iHAN3ulByQ9VdKBtj8/wqcutwGXusD2oyrHkj6bxXNIm//frZiMPfpnAq8HLrd9UbPx4DjbG1aOu7A31eYdxNCt6W1PIEm6nnIncStl6KbX22qrtlCrml2ae9m+UdLfAP9tu/aw4NA2rErZH9LrWVc/3m4pk89V7yAGTdJHKKupbmTRfIRtt7m2vhWTrkdv+7fN1uXXS/oGJQF9qo3QLcQYzobN5pmeGf3PXf8IxZ0rf/0VzQLbNwLYvkzlsOzWNOvZ30bfenZJbaxnX0nNOuWmHdMoS5i77LXAJm38IR20SZPomyVI+7Bo9cNJlDuS7VpqwnOaBKu+xwtVTLhDyzscXSnOsGz/SotXFvyJ7Z+32YaWrTVkZdViz2vvUGUA69kbPwJOlvRFSqfmYMrJYl12K5OzDMyYTZqhG0mPUdbbHuimkp+kW2oVExsm/kDO8hw0Daiy4KBI+tCyPl57Q9Mg1rM3MVai3EnsQOnMnA18pYsTk5J6K6nWAzaj7LLbXZGqAAAOI0lEQVTv3+W+zMJ2k9FkSvSvpvTo/5bS0/g25QexlRodkmYBPwR+bLu1ol6SzmPpw0Z2/cOqB1JZcKqSdBXlTOT+9ezfqTUnpGWUodYKcEh7DZKWWbjMdvU6O22bNIm+p0k0e1CGcLanrEQ4vfamh2ZH206UHs8jlB7PWbWHMSQNVyN8a8oegnm2a1bO7B34slVvHLPZtn5Fb6PLVNDy5PsOlFIL/evZ3+Jy6lWNeP3HNs7u7zh0edkyLPxZfsRN0cDmruZxXRyzn3SJvp/KiSx7Anu74pFnw8R9OrAjZaJyM8oh0mfZPrly3JdRas6sCnzELVTRbMan96fUKYfyR/ZrttuYAF8htLn6pFlxA33r2QFqrWkfsppsse9zCqy6uQTYsXeH3ky8/8gtnv/clkkzGTscl5KfX2re2oz7O8oW9RNhYa97p1rxJL2CkuD/BBxl+7xasYbygCoLrmC+32KsS5pe9MKj9JrhnFo9ay/l8XDPu2b1/mFY2w9KevwgG1TLpE70g9BMTh5HOXzjy5RfwPfbPqpSvCsotU8+DlzSXFv4S++KhZCaW9mrm52x1eKs6Gz/W+0Yzf6QdSiHoW/JooM31gBqJp/eqiKx+AojUX7uuuxhSZv3hl8lbUHpTHXOpB66GYTeCoiml30Ipad9XMXJsvNZ1LPqlWnuce0hK0nfpPwh69yk3LJIeg3wMWAtyr951W35KsfKvZlSgrr/ZKcHKUNlVQ4lH/Qqo0FqNsSdCPQKAz4b2Nd228XVqkuiHyNJV9veTNKngfNtn97lscxmc9pWlMqC/ScetXmqV+sk3QzsavuGluO+1uXUobbi7UspmdtGZc4VTjMn8jzKH/LrbD8y4CZVkaGbsbtS0tmUGiTvbyZwljjqryZJs1zvFJyhOtujG8HdbSf5xmxJx7BoZ+wFwH/YrnUwxfrAKc2O3NmUJcSXewr0ACWtDhwKzLB9sKSNVE5za/Oo0FakRz9Gzbj1FsAttu9rVv6s2ysG1VIbWl32JukZLDoA/XLb89qKPSjNHdszgf9l8c00VYZQ+uKeSjlYplfA7I3A5rZfUznuk4CXUxYVvBi4gbJf5Ue2764Ze1AknUg52er1tl/QTMT+tIt350n0Y6ThDz75tCsfADKkDWfZrrbKZ0isvSgTwedTbm9fCrzX9nfaiD8oko4b5rJtV61Jv5TiYoM4CWlTyvLhHW2/os3YbZE0x/bMIUtMW/+3bkOGbsZuuINPTqD+wScL2d6p2eyxq+1TKof7AGXD1DwASdMpW8Y7neht1z50Y2n+KOnvbF8ECzsW1Q+Bb+4kjqXsB3nM9vXA9bRcW6lljzS/R71CbhtQNkN2zpQo6DPBFjTjl7tTevKfpqVTpyRNk7SzpBMoKwX2biHsSkOGan7HFPi5kbSupNMlzZN0t6RTJa3bQuiDgc9Juk3SryinXB3cQtwvAG8AfiHpo5Ke20LMQfsPyvDUupKOB84D3j/YJtWRoZsxknQB5YfjLZRhjPmUoZxqJQFUau6/nnIIyeXANsBzbD9cK2Zf7I9Tdv/2n2F6te331Y49SJLOAb5FOaYSSt3yN9j+h5birwGwtDo0FeM+mVJe5APAbyh7Rb7h+mWSW9Nfw6e5Q/1byrDkxV2df0qiHyMtOvjkCts/UTnqbVvbJ1SKdzvwa0qP63+b3Xu31i7mJmkj4Bm2f9qsKe/tjL2XchLRL2vGH7RBjZVrgIexN6U99qNMAN8JfJPy//7XtretHb8tXa/hM5zO34JPNNu/BU6l1JsBuIdFdWBqOJWyY3JvYNemqFsbf50/Rdmsg+3TbP+z7XcDP6Cdg14G7R5J+zXDZdOaifc21pqfQRkWXEDZt9B7q0rSaZQy4I+nzP3sZvsk2+8Enlg7fstaP4V80NKjHyNJbwUOAp5me0NJGwNfdMVywZIEbEe5pd6Fsi3+QOAHtv9QKeZSDwWXdE3NoaoVQXOn9lngJZQ/rBcDh9ZeXbWsf/fKcbd3pQqZKxpJ8yhlzodl+10tNqcVWXUzdodQ1hlfBmD7F5LWqhmwmfw9Fzi32diyM6U2/+eBNSuFXW0ZH1u9UswVRjOGO4jdv4M6jP15zZDGfQAqB9Hv64qHgw/QH4ErB92INiXRj92fbT9SOtkgaWVarPLXTIqdKWkuTQnbSq6Q9FbbX+6/qHJoQ2d/SSR9cBkftu3/VynuNZSfo5WBAyTdQruHsb/V9ud6T2zf29y9djHR/9728SO/rDuS6MfuAklHUKoM/gPwduC7bQSWtCal/v6+lHH7mnMDhwGnS3oDixL7TMqB0a+uGHfQhhsPfwJlqOzpQJVED7yq0tcdral0OHirJUtWBBmjH6OmBMKBlINHRDlU+Su1aoM0W9NfTVnpswklue9tu4013UjaDuiNGV83VcZxYeG//aGU/++TgaNrLb9rNu4cDGxE2ZZ/rO0FNWItJf7HKSt9+g8H/43t97TVhrZImgPcTlkmfZbt2wbbovqS6Fdwkv5IWTv/b8BFtq0WD0Wfipr6Rf9M2UB0PGVj3L2VY54E/IWy8mVn4Fe2D60Zc0j8KXM4OICk9Sn/zjtR7o4vohR0u8CVTvMapCT6MWq2pB9Jqfq3MovGUKskXknvpky8PoGygeck4Jwk+jqanu1rgFnA52qtahom7sKVTM28z+VTba33oDQLHF5KSfrbAvNtv3KgjZpgSfRjJOlG4N2UceuFvZ3a9bwlPYcyNr8PsDHwQcoGqv+rGXeqkfQYZRJ0AYtPstc+eGSxTTxtbeqRdLLtvfomgxfTwiTwQKmUKn627Zv6rq1j+44BNmvCJdGPkaTLbP9Ni/EW7lDtu7YZZdPSy2xPa6stUY+kR1k0ESzKEtaHqf8HZm3bdzVDGUtosypr2yTtRqnM+jjbG6gcJfgf7uChOkn0YyTpo8A04DQWr1Ne5UxVSd8DjvCQeveStgI+ZHvQqzUiJiVJVwLbU06K65Up7uRmwCyvHLteb35m3zVTfmBqmDE0yQPYvmJpvbCI0ZL0IMMMUVH5TmIFscD2/b09MY1O9nyT6MfI9nYth5zSO1SjLtutlNheQV0r6fXAtKaUybsopS46J4l+lCTtZ/sbkv55uI/bPqZS6Cm5QzXap3KYzkubpxcOdyfZMe+klGP+M2VF24+A/xxoiypJoh+9JzTv2+4BTdUdqtEiSYcCb6XMPQF8U+UQ+s8MsFlVNec5fKB567RMxk4SU3mHatQn6WrgJbYfap4/Abiky8srm8Nl9hxSyO3b7uAZualHP0aS/lvSGpJWkTRb0j1NrfKqbJ9n+zPNW5J8TDTRty+kedz1uu1r9pI8lEJuQNVKtIOSRD92O7oc7/YqSr2MTYD3DrZJEeN2HHCZpCMlHQlcSjksvMsea84dABaWRejkEEfG6Mduleb9LsCJtn8/ZHlWxKRj+xhJ57PoyMgDbP9ssK2q7gPARSrnQAP8PeVQoc7JGP0YNRum9qAcXvBi4CnA99rcLRsxUQZdNXPQmtLfW1P+uF1i+54BN6mKJPrl0EzaPGD7UUmPB9ZozpKNmFSGqZp5m+3DBtuq9khah0UFCgGwfeHgWlRHEv0YSXrTcNdtn9B2WyLGaypXzZT0MWBv4DoWHUbiLta6yRj92G3V93g1Sv3uq4Ak+piM/tJ7YHvBFJtv2gP4qy7Wnx8qiX6MbL+z/7mkJwNfH1BzIsZrc0kPNI9FOSLzAaZGrZtbKIsrkuhjRA9T6sNHTDpTvMz1w8BcSbNZvBLtuwbXpDqS6MdI0ndZtNZ2JWBTynmiETG5nNm8dV4mY8dI0sv6ni6gnO15+6DaExHLb7gTprooiX4cmjW4v3P+ESMmHUm7Ap9gCpwwlRIIoyRpa0nnSzpN0paSrgWuBe6WtNOg2xcRY3YkZdPjfQC25wIbDLJBtWSMfvQ+CxwBPBk4F9jZ9qWSngucCJw1yMZFxJhNmROm0qMfvZVtn237FOC3ti8FsH3jgNsVEctnsROmJH2Gjp4wlUQ/eo/1Pf7jkI91shcQ0XHvBJ5PWVp5IvAA5aCfzslk7ChJehR4iGZTCWUNLs3z1WyvsrTPjYgYpCT6iJhSJH3K9mFD9sQs1MVVN5mMjYippley5BMDbUWL0qOPiCmpORf3j7Yfa55PA1ZtDg3vlEzGRsRUNRt4fN/z1YEfD6gtVSXRR8RUtZrtP/SeNI8fv4zXT1pJ9BExVT0kaeEhK5JmsuTS6U7IZGxETFWHAadIupOy+uZZlBOnOic9+oiYUiRtJemZtq8AngucRKlEexZw60AbV0kSfURMNV8CHmkev4RSw+pzwL3ArEE1qqYM3UTEVDPN9u+bx3sDs2yfCpwqae4A21VNevQRMdVMk9Tr5O5AqUbb08nObye/qYiIZTgRuEDSPZRVNj8BkLQRcP8gG1ZLdsZGxJQjaWtgbeBs2w811zYBnmj7qoE2roIk+oiIjssYfURExyXRR0R0XBJ9TGmS3iXpBkl3SPrsCK/dTdLhbbUtYqJkjD6mNEk3AjsDLwNm2n7HcnyNlW0vmPDGRUyQ9OhjypL0ReA5wJnAU/uu7yrpMkk/k/RjSc9orr+51+uX9DVJx0g6D/jYINofMVpJ9DFl2T4YuBPYjrL9veciYGvbWwLfBv51KV9iE+Dltt9TtaER45QNUxFLWhc4SdLawONYeqGrU2w/2l6zIpZPevQRS/oM8Fnbfw28DVhtKa97qL0mRSy/JPqIJT0ZuKN5vP8gGxIxEZLoI5Z0JOVAip8A9wy4LRHjluWVEREdlx59RETHJdFHRHRcEn1ERMcl0UdEdFwSfURExyXRR0R0XBJ9RETH/X8hgiie8AgcWQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sec_strip.groupby('flair').count()['title'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING THE  LOGISTIC REGRESSION MODEL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[78  5  0  0  2  0  1  3  5  6  0]\n",
      " [ 8 54  0  0  2  2  2  5  1  8  0]\n",
      " [ 4  0 49  0  0  0  0  0  2  1  1]\n",
      " [ 0  0  0 27  3  0  0  0  2  0  1]\n",
      " [ 6  1  1  5 72  4  2  3  4  1  2]\n",
      " [ 1  2  0  0  1 35  7  0  8  6  2]\n",
      " [12  1  0  0  4  8 59  0  1  8  1]\n",
      " [ 6  9  0  0  2  2  1 50 14  7  1]\n",
      " [ 0  1  0  0  5  8  1  9 50  3  1]\n",
      " [ 5  8  0  0  0  1  3  5  1 65  0]\n",
      " [ 8  0  0  0  1  2  1  2  3  1 55]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.61      0.78      0.68       100\n",
      "  Business/Finance       0.67      0.66      0.66        82\n",
      "       CAA-NRC-NPR       0.98      0.86      0.92        57\n",
      "       Coronavirus       0.84      0.82      0.83        33\n",
      "              Food       0.78      0.71      0.75       101\n",
      "     Non-Political       0.56      0.56      0.56        62\n",
      "       Photography       0.77      0.63      0.69        94\n",
      "    Policy/Economy       0.65      0.54      0.59        92\n",
      "          Politics       0.55      0.64      0.59        78\n",
      "Science/Technology       0.61      0.74      0.67        88\n",
      "            Sports       0.86      0.75      0.80        73\n",
      "\n",
      "          accuracy                           0.69       860\n",
      "         macro avg       0.72      0.70      0.70       860\n",
      "      weighted avg       0.70      0.69      0.69       860\n",
      "\n",
      "\n",
      " TESTING THE RANDOM FORESTS MODEL \n",
      "\n",
      "confusion matrix\n",
      "[[92  1  0  0  1  0  0  0  5  1  0]\n",
      " [16 36  1  0  1  1  8  3  1 15  0]\n",
      " [ 5  0 49  1  0  0  0  0  2  0  0]\n",
      " [ 2  0  0 22  2  0  0  0  6  0  1]\n",
      " [10  1  0  0 63  2  9  1 10  4  1]\n",
      " [ 1  2  0  0  2 27 11  0 16  2  1]\n",
      " [10  0  0  0  3  2 74  0  2  2  1]\n",
      " [11 14  1  1  3  2  0 21 21 17  1]\n",
      " [ 4  1  0  0  1  4  4  4 53  7  0]\n",
      " [17  8  0  0  1  0 10  2  4 46  0]\n",
      " [ 6  2  1  0  2  1  4  0  6  1 50]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.53      0.92      0.67       100\n",
      "  Business/Finance       0.55      0.44      0.49        82\n",
      "       CAA-NRC-NPR       0.94      0.86      0.90        57\n",
      "       Coronavirus       0.92      0.67      0.77        33\n",
      "              Food       0.80      0.62      0.70       101\n",
      "     Non-Political       0.69      0.44      0.53        62\n",
      "       Photography       0.62      0.79      0.69        94\n",
      "    Policy/Economy       0.68      0.23      0.34        92\n",
      "          Politics       0.42      0.68      0.52        78\n",
      "Science/Technology       0.48      0.52      0.50        88\n",
      "            Sports       0.91      0.68      0.78        73\n",
      "\n",
      "          accuracy                           0.62       860\n",
      "         macro avg       0.69      0.62      0.63       860\n",
      "      weighted avg       0.66      0.62      0.61       860\n",
      "\n",
      "\n",
      " TESTING THE SVM MODEL \n",
      "confusion matrix\n",
      "[[68 10  0  0 11  0  0  3  4  3  1]\n",
      " [ 4 52  2  1  3  2  2  5  2  6  3]\n",
      " [ 4  0 51  0  0  0  0  0  1  1  0]\n",
      " [ 0  0  0 31  2  0  0  0  0  0  0]\n",
      " [ 3  1  4  4 80  3  2  2  2  0  0]\n",
      " [ 2  3  1  0  5 20 12  0  8  3  8]\n",
      " [ 9  1  0  0  6  5 69  0  2  1  1]\n",
      " [ 4 17  2  2  3  0  1 41 15  5  2]\n",
      " [ 2  3  2  0  5  5  1  8 47  2  3]\n",
      " [ 7 11  0  2  2  2  4  8  1 49  2]\n",
      " [ 5  0  0  0  3  2  0  1  2  0 60]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.63      0.68      0.65       100\n",
      "  Business/Finance       0.53      0.63      0.58        82\n",
      "       CAA-NRC-NPR       0.82      0.89      0.86        57\n",
      "       Coronavirus       0.78      0.94      0.85        33\n",
      "              Food       0.67      0.79      0.72       101\n",
      "     Non-Political       0.51      0.32      0.40        62\n",
      "       Photography       0.76      0.73      0.75        94\n",
      "    Policy/Economy       0.60      0.45      0.51        92\n",
      "          Politics       0.56      0.60      0.58        78\n",
      "Science/Technology       0.70      0.56      0.62        88\n",
      "            Sports       0.75      0.82      0.78        73\n",
      "\n",
      "          accuracy                           0.66       860\n",
      "         macro avg       0.66      0.67      0.66       860\n",
      "      weighted avg       0.66      0.66      0.65       860\n",
      "\n",
      "\n",
      " TESTING THE NAIVE BAYES MODEL\n",
      "confusion matrix\n",
      "[[65  3  0  0  2  0  0  2 26  2  0]\n",
      " [10 46  0  0  2  0  0  0 21  3  0]\n",
      " [ 2  0 33  0  1  0  0  0 19  2  0]\n",
      " [ 2  0  0  2  9  0  0  0 17  3  0]\n",
      " [ 8  0  0  0 64  0  0  0 28  1  0]\n",
      " [ 0  1  0  0  1  8  5  0 46  1  0]\n",
      " [17  2  0  0  6  2 45  0 19  3  0]\n",
      " [ 4 13  1  0  0  0  0 16 56  2  0]\n",
      " [ 0  1  0  0  0  1  1  1 73  1  0]\n",
      " [11  9  0  0  0  0  2  2 19 45  0]\n",
      " [ 7  0  0  0  1  0  0  0 20  2 43]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.52      0.65      0.58       100\n",
      "  Business/Finance       0.61      0.56      0.59        82\n",
      "       CAA-NRC-NPR       0.97      0.58      0.73        57\n",
      "       Coronavirus       1.00      0.06      0.11        33\n",
      "              Food       0.74      0.63      0.68       101\n",
      "     Non-Political       0.73      0.13      0.22        62\n",
      "       Photography       0.85      0.48      0.61        94\n",
      "    Policy/Economy       0.76      0.17      0.28        92\n",
      "          Politics       0.21      0.94      0.35        78\n",
      "Science/Technology       0.69      0.51      0.59        88\n",
      "            Sports       1.00      0.59      0.74        73\n",
      "\n",
      "          accuracy                           0.51       860\n",
      "         macro avg       0.74      0.48      0.50       860\n",
      "      weighted avg       0.71      0.51      0.52       860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=sec_strip['title']+sec_strip['processed_url']+sec_strip['author']+sec_strip['stem_comments']\n",
    "y=sec_strip['flair']\n",
    "test_models(X,y,'title,processed_url,author,stemmed_comments(reduced data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING THE  LOGISTIC REGRESSION MODEL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[73  6  0  0  5  0  1  5  4  6  0]\n",
      " [ 8 52  0  0  1  2  4  4  1 10  0]\n",
      " [ 4  0 46  0  1  0  1  0  2  2  1]\n",
      " [ 0  0  0 28  2  1  0  0  2  0  0]\n",
      " [ 3  1  2  3 70  4  6  4  3  3  2]\n",
      " [ 1  2  0  0  1 35  8  0  9  5  1]\n",
      " [12  1  0  0  4  6 65  0  2  3  1]\n",
      " [ 6 10  1  0  1  1  1 52 13  7  0]\n",
      " [ 2  1  0  0  3  9  1 10 50  1  1]\n",
      " [ 6  6  0  1  0  1  6  5  1 62  0]\n",
      " [ 7  1  0  1  1  3  1  1  2  2 54]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.60      0.73      0.66       100\n",
      "  Business/Finance       0.65      0.63      0.64        82\n",
      "       CAA-NRC-NPR       0.94      0.81      0.87        57\n",
      "       Coronavirus       0.85      0.85      0.85        33\n",
      "              Food       0.79      0.69      0.74       101\n",
      "     Non-Political       0.56      0.56      0.56        62\n",
      "       Photography       0.69      0.69      0.69        94\n",
      "    Policy/Economy       0.64      0.57      0.60        92\n",
      "          Politics       0.56      0.64      0.60        78\n",
      "Science/Technology       0.61      0.70      0.66        88\n",
      "            Sports       0.90      0.74      0.81        73\n",
      "\n",
      "          accuracy                           0.68       860\n",
      "         macro avg       0.71      0.69      0.70       860\n",
      "      weighted avg       0.69      0.68      0.69       860\n",
      "\n",
      "\n",
      " TESTING THE RANDOM FORESTS MODEL \n",
      "\n",
      "confusion matrix\n",
      "[[90  1  0  0  2  0  0  1  5  1  0]\n",
      " [17 39  1  0  2  0  5  2  3 13  0]\n",
      " [ 8  0 45  0  0  0  1  0  1  1  1]\n",
      " [ 0  0  0 23  2  0  0  0  8  0  0]\n",
      " [10  1  0  3 57  2  9  1  9  8  1]\n",
      " [ 1  2  0  0  3 27 12  0 15  1  1]\n",
      " [12  0  0  0  3  2 73  0  2  1  1]\n",
      " [ 8 18  1  0  2  2  2 22 23 14  0]\n",
      " [ 4  1  1  0  1  5  6  4 50  6  0]\n",
      " [17  7  0  0  0  0  9  3  7 45  0]\n",
      " [ 7  2  1  0  3  1  2  0  4  2 51]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.52      0.90      0.66       100\n",
      "  Business/Finance       0.55      0.48      0.51        82\n",
      "       CAA-NRC-NPR       0.92      0.79      0.85        57\n",
      "       Coronavirus       0.88      0.70      0.78        33\n",
      "              Food       0.76      0.56      0.65       101\n",
      "     Non-Political       0.69      0.44      0.53        62\n",
      "       Photography       0.61      0.78      0.69        94\n",
      "    Policy/Economy       0.67      0.24      0.35        92\n",
      "          Politics       0.39      0.64      0.49        78\n",
      "Science/Technology       0.49      0.51      0.50        88\n",
      "            Sports       0.93      0.70      0.80        73\n",
      "\n",
      "          accuracy                           0.61       860\n",
      "         macro avg       0.67      0.61      0.62       860\n",
      "      weighted avg       0.65      0.61      0.60       860\n",
      "\n",
      "\n",
      " TESTING THE SVM MODEL \n",
      "confusion matrix\n",
      "[[54 17  1  1 12  0  0  4  5  5  1]\n",
      " [ 4 50  3  1  3  1  1  4  2  9  4]\n",
      " [ 2  0 49  1  1  0  1  0  2  0  1]\n",
      " [ 0  0  1 30  2  0  0  0  0  0  0]\n",
      " [ 3  1  4  3 77  3  4  2  2  2  0]\n",
      " [ 2  3  1  0  6 16 12  1  9  5  7]\n",
      " [ 6  2  1  0  5  4 69  0  1  3  3]\n",
      " [ 5 16  2  2  3  0  0 44 14  4  2]\n",
      " [ 2  2  3  0  3  3  2  7 51  2  3]\n",
      " [ 6 11  0  3  2  1  4  8  1 52  0]\n",
      " [ 3  0  0  1  3  2  1  1  2  0 60]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.62      0.54      0.58       100\n",
      "  Business/Finance       0.49      0.61      0.54        82\n",
      "       CAA-NRC-NPR       0.75      0.86      0.80        57\n",
      "       Coronavirus       0.71      0.91      0.80        33\n",
      "              Food       0.66      0.76      0.71       101\n",
      "     Non-Political       0.53      0.26      0.35        62\n",
      "       Photography       0.73      0.73      0.73        94\n",
      "    Policy/Economy       0.62      0.48      0.54        92\n",
      "          Politics       0.57      0.65      0.61        78\n",
      "Science/Technology       0.63      0.59      0.61        88\n",
      "            Sports       0.74      0.82      0.78        73\n",
      "\n",
      "          accuracy                           0.64       860\n",
      "         macro avg       0.64      0.66      0.64       860\n",
      "      weighted avg       0.64      0.64      0.63       860\n",
      "\n",
      "\n",
      " TESTING THE NAIVE BAYES MODEL\n",
      "confusion matrix\n",
      "[[59  6  0  0  2  0  0  3 27  3  0]\n",
      " [10 45  0  0  3  0  0  0 20  4  0]\n",
      " [ 2  0 31  0  1  0  0  0 22  1  0]\n",
      " [ 2  0  0  1  9  0  0  0 19  2  0]\n",
      " [ 4  0  0  0 64  0  1  0 30  2  0]\n",
      " [ 0  1  0  0  1  8  6  0 45  1  0]\n",
      " [13  1  0  0  5  1 53  0 20  1  0]\n",
      " [ 2 11  1  0  1  0  0 18 58  1  0]\n",
      " [ 0  0  0  0  0  1  1  2 74  0  0]\n",
      " [ 9  8  0  0  0  0  2  2 19 48  0]\n",
      " [ 4  0  0  0  1  0  1  0 21  2 44]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.56      0.59      0.58       100\n",
      "  Business/Finance       0.62      0.55      0.58        82\n",
      "       CAA-NRC-NPR       0.97      0.54      0.70        57\n",
      "       Coronavirus       1.00      0.03      0.06        33\n",
      "              Food       0.74      0.63      0.68       101\n",
      "     Non-Political       0.80      0.13      0.22        62\n",
      "       Photography       0.83      0.56      0.67        94\n",
      "    Policy/Economy       0.72      0.20      0.31        92\n",
      "          Politics       0.21      0.95      0.34        78\n",
      "Science/Technology       0.74      0.55      0.63        88\n",
      "            Sports       1.00      0.60      0.75        73\n",
      "\n",
      "          accuracy                           0.52       860\n",
      "         macro avg       0.74      0.48      0.50       860\n",
      "      weighted avg       0.72      0.52      0.53       860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=sec_strip['stemmed_titles']+sec_strip['stem_comments']+sec_strip['processed_url']\n",
    "y=sec_strip['flair']\n",
    "test_models(X,y,'stemmed_titles,stemmed_comments,processed_url(reduced data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING THE  LOGISTIC REGRESSION MODEL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[398  14   0   0   7  27   2  18  19   8   1]\n",
      " [ 22 150   0   0   0  10   0  63   2  10   0]\n",
      " [  7   0  48   0   0   0   0   7   4   0   0]\n",
      " [  1   0   0  25   1   2   0   2   3   0   0]\n",
      " [ 18   2   0   2  41  24   0   5   4   1   1]\n",
      " [ 29   4   0   0   3 286   6  12  30   4   4]\n",
      " [ 20   1   0   0   1  32  33   2   0   2   0]\n",
      " [ 18  39   0   0   1  14   0 416  32  11   1]\n",
      " [ 14   3   1   0   2  59   0  36 309   4   1]\n",
      " [ 34  14   0   0   0  23   1  51   8  96   2]\n",
      " [ 17   0   0   0   1  10   1   5   5   2  99]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.69      0.81      0.74       494\n",
      "  Business/Finance       0.66      0.58      0.62       257\n",
      "       CAA-NRC-NPR       0.98      0.73      0.83        66\n",
      "       Coronavirus       0.93      0.74      0.82        34\n",
      "              Food       0.72      0.42      0.53        98\n",
      "     Non-Political       0.59      0.76      0.66       378\n",
      "       Photography       0.77      0.36      0.49        91\n",
      "    Policy/Economy       0.67      0.78      0.72       532\n",
      "          Politics       0.74      0.72      0.73       429\n",
      "Science/Technology       0.70      0.42      0.52       229\n",
      "            Sports       0.91      0.71      0.80       140\n",
      "\n",
      "          accuracy                           0.69      2748\n",
      "         macro avg       0.76      0.64      0.68      2748\n",
      "      weighted avg       0.70      0.69      0.69      2748\n",
      "\n",
      "\n",
      " TESTING THE RANDOM FORESTS MODEL \n",
      "\n",
      "confusion matrix\n",
      "[[450   0   0   0   0  14   0  13  15   1   1]\n",
      " [ 40  47   0   0   0  17   0 145   7   1   0]\n",
      " [ 12   0  38   0   0   0   1   8   7   0   0]\n",
      " [  3   0   0   7   0   5   0  14   5   0   0]\n",
      " [ 31   0   0   0   8  29   0  21   7   0   2]\n",
      " [ 34   0   0   0   0 264   2  42  36   0   0]\n",
      " [ 18   0   0   0   0  31  20  22   0   0   0]\n",
      " [ 34   5   0   0   0   8   0 450  34   1   0]\n",
      " [ 14   0   0   0   0  52   0  63 299   1   0]\n",
      " [ 42   0   0   0   0  22   0 118   9  37   1]\n",
      " [ 23   0   0   0   1  22   1  31   6   0  56]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.64      0.91      0.75       494\n",
      "  Business/Finance       0.90      0.18      0.30       257\n",
      "       CAA-NRC-NPR       1.00      0.58      0.73        66\n",
      "       Coronavirus       1.00      0.21      0.34        34\n",
      "              Food       0.89      0.08      0.15        98\n",
      "     Non-Political       0.57      0.70      0.63       378\n",
      "       Photography       0.83      0.22      0.35        91\n",
      "    Policy/Economy       0.49      0.85      0.62       532\n",
      "          Politics       0.70      0.70      0.70       429\n",
      "Science/Technology       0.90      0.16      0.27       229\n",
      "            Sports       0.93      0.40      0.56       140\n",
      "\n",
      "          accuracy                           0.61      2748\n",
      "         macro avg       0.81      0.45      0.49      2748\n",
      "      weighted avg       0.70      0.61      0.57      2748\n",
      "\n",
      "\n",
      " TESTING THE MLP MODEL\n",
      "confusion matrix\n",
      "[[275  36   1   0  80  26  24  13   7  30   2]\n",
      " [ 20 134   3   0  14   2   0  58   8  18   0]\n",
      " [  2   1  38   1   0   0   0   3   9  12   0]\n",
      " [  1   0   4  17   0   1   0   0   6   3   2]\n",
      " [ 12   4   2   1  47  16   2   4   3   6   1]\n",
      " [ 10   4   3   0  45 234  26  14  31   6   5]\n",
      " [ 13   1   0   0   9  26  32   1   0   9   0]\n",
      " [  9  58   9   3  12  14   0 340  40  46   1]\n",
      " [  1   3   2   3  17  69   8  34 279  11   2]\n",
      " [ 16  17   5   2  19  10   8  33  10 106   3]\n",
      " [  9   0   1   7   4   6   7   2   3  10  91]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.75      0.56      0.64       494\n",
      "  Business/Finance       0.52      0.52      0.52       257\n",
      "       CAA-NRC-NPR       0.56      0.58      0.57        66\n",
      "       Coronavirus       0.50      0.50      0.50        34\n",
      "              Food       0.19      0.48      0.27        98\n",
      "     Non-Political       0.58      0.62      0.60       378\n",
      "       Photography       0.30      0.35      0.32        91\n",
      "    Policy/Economy       0.68      0.64      0.66       532\n",
      "          Politics       0.70      0.65      0.68       429\n",
      "Science/Technology       0.41      0.46      0.44       229\n",
      "            Sports       0.85      0.65      0.74       140\n",
      "\n",
      "          accuracy                           0.58      2748\n",
      "         macro avg       0.55      0.55      0.54      2748\n",
      "      weighted avg       0.62      0.58      0.59      2748\n",
      "\n",
      "\n",
      " TESTING THE SVM MODEL \n",
      "confusion matrix\n",
      "[[398   4   0   1   3  12   2  30  37   3   4]\n",
      " [ 54  47   0   0   0   7   1 129  13   6   0]\n",
      " [  8   0  40   0   0   0   0   4  14   0   0]\n",
      " [  1   0   0  25   1   1   0   1   5   0   0]\n",
      " [ 23   2   1   4  29  15   2   9   8   3   2]\n",
      " [ 61   4   2   1   2 179   9  31  67   4  18]\n",
      " [ 15   1   0   0   1  29  36   5   1   1   2]\n",
      " [ 27  13   2   4   1   8   1 421  48   6   1]\n",
      " [ 17   3   4   3   2  28   0  41 324   2   5]\n",
      " [ 41   5   1   2   1  16   1  78  25  55   4]\n",
      " [ 11   0   0   1   0   2   1   2   8   2 113]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.61      0.81      0.69       494\n",
      "  Business/Finance       0.59      0.18      0.28       257\n",
      "       CAA-NRC-NPR       0.80      0.61      0.69        66\n",
      "       Coronavirus       0.61      0.74      0.67        34\n",
      "              Food       0.72      0.30      0.42        98\n",
      "     Non-Political       0.60      0.47      0.53       378\n",
      "       Photography       0.68      0.40      0.50        91\n",
      "    Policy/Economy       0.56      0.79      0.66       532\n",
      "          Politics       0.59      0.76      0.66       429\n",
      "Science/Technology       0.67      0.24      0.35       229\n",
      "            Sports       0.76      0.81      0.78       140\n",
      "\n",
      "          accuracy                           0.61      2748\n",
      "         macro avg       0.65      0.55      0.57      2748\n",
      "      weighted avg       0.62      0.61      0.58      2748\n",
      "\n",
      "\n",
      " TESTING THE NAIVE BAYES MODEL\n",
      "confusion matrix\n",
      "[[345   0   0   0   0  20   0  61  68   0   0]\n",
      " [ 32   4   0   0   0   3   0 202  16   0   0]\n",
      " [  2   0   0   0   0   0   0  32  32   0   0]\n",
      " [  3   0   0   0   0   0   0  12  19   0   0]\n",
      " [ 32   0   0   0   0  32   0  17  17   0   0]\n",
      " [ 47   0   0   0   0 198   0  32 101   0   0]\n",
      " [ 28   0   0   0   0  43   7  10   3   0   0]\n",
      " [ 11   0   0   0   0   1   0 471  49   0   0]\n",
      " [  5   0   0   0   0  12   0  48 364   0   0]\n",
      " [ 49   0   0   0   0  10   0 136  30   4   0]\n",
      " [ 34   0   0   0   0  20   0  35  38   0  13]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.59      0.70      0.64       494\n",
      "  Business/Finance       1.00      0.02      0.03       257\n",
      "       CAA-NRC-NPR       0.00      0.00      0.00        66\n",
      "       Coronavirus       0.00      0.00      0.00        34\n",
      "              Food       0.00      0.00      0.00        98\n",
      "     Non-Political       0.58      0.52      0.55       378\n",
      "       Photography       1.00      0.08      0.14        91\n",
      "    Policy/Economy       0.45      0.89      0.59       532\n",
      "          Politics       0.49      0.85      0.62       429\n",
      "Science/Technology       1.00      0.02      0.03       229\n",
      "            Sports       1.00      0.09      0.17       140\n",
      "\n",
      "          accuracy                           0.51      2748\n",
      "         macro avg       0.56      0.29      0.25      2748\n",
      "      weighted avg       0.61      0.51      0.42      2748\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X=df['author']+df['stemmed_titles']+df['processed_url']+df['stem_comments']\n",
    "y=df['flair']\n",
    "test_models(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING THE  LOGISTIC REGRESSION MODEL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[74  5  0  0  5  0  1  5  4  6  0]\n",
      " [ 8 52  0  0  1  2  2  5  1 11  0]\n",
      " [ 6  0 45  0  0  0  1  0  3  1  1]\n",
      " [ 0  0  0 27  3  0  0  0  2  0  1]\n",
      " [ 4  0  1  3 71  4  4  5  4  3  2]\n",
      " [ 1  2  0  0  1 34  8  1  9  5  1]\n",
      " [12  1  0  0  4  9 60  1  2  4  1]\n",
      " [ 6  9  0  0  1  1  1 55 13  6  0]\n",
      " [ 1  1  0  0  3  9  1  9 52  1  1]\n",
      " [ 7  6  0  0  1  2  2  5  1 64  0]\n",
      " [ 7  1  0  1  1  3  1  1  2  1 55]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.59      0.74      0.65       100\n",
      "  Business/Finance       0.68      0.63      0.65        82\n",
      "       CAA-NRC-NPR       0.98      0.79      0.87        57\n",
      "       Coronavirus       0.87      0.82      0.84        33\n",
      "              Food       0.78      0.70      0.74       101\n",
      "     Non-Political       0.53      0.55      0.54        62\n",
      "       Photography       0.74      0.64      0.69        94\n",
      "    Policy/Economy       0.63      0.60      0.61        92\n",
      "          Politics       0.56      0.67      0.61        78\n",
      "Science/Technology       0.63      0.73      0.67        88\n",
      "            Sports       0.89      0.75      0.81        73\n",
      "\n",
      "          accuracy                           0.68       860\n",
      "         macro avg       0.72      0.69      0.70       860\n",
      "      weighted avg       0.70      0.68      0.69       860\n",
      "\n",
      "\n",
      " TESTING THE RANDOM FORESTS MODEL \n",
      "\n",
      "confusion matrix\n",
      "[[89  2  0  0  0  1  0  1  6  1  0]\n",
      " [17 41  1  0  2  1  2  2  2 14  0]\n",
      " [ 7  0 46  1  0  0  1  0  2  0  0]\n",
      " [ 1  0  0 22  2  1  0  0  6  0  1]\n",
      " [10  0  0  1 60  0 13  1 11  4  1]\n",
      " [ 1  1  0  0  2 33 11  0 11  2  1]\n",
      " [11  0  0  0  4  2 71  0  3  2  1]\n",
      " [11 17  1  0  2  2  2 19 25 13  0]\n",
      " [ 5  1  0  0  1  6  6  4 50  5  0]\n",
      " [16  7  0  0  2  1  9  2  8 43  0]\n",
      " [ 8  2  0  0  3  2  2  0  2  2 52]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.51      0.89      0.64       100\n",
      "  Business/Finance       0.58      0.50      0.54        82\n",
      "       CAA-NRC-NPR       0.96      0.81      0.88        57\n",
      "       Coronavirus       0.92      0.67      0.77        33\n",
      "              Food       0.77      0.59      0.67       101\n",
      "     Non-Political       0.67      0.53      0.59        62\n",
      "       Photography       0.61      0.76      0.67        94\n",
      "    Policy/Economy       0.66      0.21      0.31        92\n",
      "          Politics       0.40      0.64      0.49        78\n",
      "Science/Technology       0.50      0.49      0.49        88\n",
      "            Sports       0.93      0.71      0.81        73\n",
      "\n",
      "          accuracy                           0.61       860\n",
      "         macro avg       0.68      0.62      0.62       860\n",
      "      weighted avg       0.65      0.61      0.61       860\n",
      "\n",
      "\n",
      " TESTING THE SVM MODEL \n",
      "confusion matrix\n",
      "[[52 17  0  0 13  1  2  5  4  4  2]\n",
      " [ 6 49  2  1  3  1  0  6  0  9  5]\n",
      " [ 4  0 48  1  0  0  1  0  2  0  1]\n",
      " [ 0  0  1 28  4  0  0  0  0  0  0]\n",
      " [ 5  1  3  2 80  2  4  2  2  0  0]\n",
      " [ 2  2  1  0  8 12 13  1  9  5  9]\n",
      " [10  1  1  0  6  4 63  0  1  5  3]\n",
      " [ 6 15  2  2  3  0  1 43 14  4  2]\n",
      " [ 2  2  2  0  3  4  2  8 51  2  2]\n",
      " [ 5 11  0  1  2  2  5  7  1 51  3]\n",
      " [ 3  0  0  0  3  1  1  1  2  0 62]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.55      0.52      0.53       100\n",
      "  Business/Finance       0.50      0.60      0.54        82\n",
      "       CAA-NRC-NPR       0.80      0.84      0.82        57\n",
      "       Coronavirus       0.80      0.85      0.82        33\n",
      "              Food       0.64      0.79      0.71       101\n",
      "     Non-Political       0.44      0.19      0.27        62\n",
      "       Photography       0.68      0.67      0.68        94\n",
      "    Policy/Economy       0.59      0.47      0.52        92\n",
      "          Politics       0.59      0.65      0.62        78\n",
      "Science/Technology       0.64      0.58      0.61        88\n",
      "            Sports       0.70      0.85      0.77        73\n",
      "\n",
      "          accuracy                           0.63       860\n",
      "         macro avg       0.63      0.64      0.63       860\n",
      "      weighted avg       0.62      0.63      0.62       860\n",
      "\n",
      "\n",
      " TESTING THE NAIVE BAYES MODEL\n",
      "confusion matrix\n",
      "[[57  4  0  0  3  0  0  3 31  2  0]\n",
      " [ 9 47  0  0  3  0  0  0 20  3  0]\n",
      " [ 4  0 27  0  0  0  0  0 25  1  0]\n",
      " [ 2  0  0  1 10  0  0  0 19  1  0]\n",
      " [ 5  1  0  0 63  0  1  0 29  2  0]\n",
      " [ 0  1  0  0  1  8  5  0 46  1  0]\n",
      " [19  1  0  0  7  3 43  0 20  1  0]\n",
      " [ 5 10  1  0  1  0  0 17 58  0  0]\n",
      " [ 1  0  0  0  0  1  0  2 74  0  0]\n",
      " [10  8  0  0  1  0  2  2 19 46  0]\n",
      " [ 4  0  0  0  1  0  0  0 23  1 44]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.49      0.57      0.53       100\n",
      "  Business/Finance       0.65      0.57      0.61        82\n",
      "       CAA-NRC-NPR       0.96      0.47      0.64        57\n",
      "       Coronavirus       1.00      0.03      0.06        33\n",
      "              Food       0.70      0.62      0.66       101\n",
      "     Non-Political       0.67      0.13      0.22        62\n",
      "       Photography       0.84      0.46      0.59        94\n",
      "    Policy/Economy       0.71      0.18      0.29        92\n",
      "          Politics       0.20      0.95      0.33        78\n",
      "Science/Technology       0.79      0.52      0.63        88\n",
      "            Sports       1.00      0.60      0.75        73\n",
      "\n",
      "          accuracy                           0.50       860\n",
      "         macro avg       0.73      0.47      0.48       860\n",
      "      weighted avg       0.70      0.50      0.51       860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=sec_strip['author']+sec_strip['stemmed_titles']+sec_strip['processed_url']+sec_strip['stem_comments']\n",
    "y=sec_strip['flair']\n",
    "test_models(X,y,'author,stemmed_titles,processed_url,stem_comments(reduced data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING THE  LOGISTIC REGRESSION MODEL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[450  11   0   0   3  16   0   6   5   2   2]\n",
      " [ 25 142   0   0   0  13   0  61   4   9   0]\n",
      " [ 11   0  47   0   0   2   0   2   3   1   0]\n",
      " [  1   0   0  25   1   2   0   2   3   0   0]\n",
      " [ 22   2   0   4  38  14   1  10   1   4   2]\n",
      " [ 29   3   0   0   4 258  11  27  34   1   7]\n",
      " [ 14   2   0   0   1  38  35   1   3   1   0]\n",
      " [ 30  33   0   0   1  26   0 384  42  12   1]\n",
      " [ 23   8   0   0   0  77   0  53 262   7   0]\n",
      " [ 27  16   0   0   0  25   0  45   9 114   1]\n",
      " [ 19   3   0   0   0  12   1   5   4   5  86]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.69      0.91      0.79       495\n",
      "  Business/Finance       0.65      0.56      0.60       254\n",
      "       CAA-NRC-NPR       1.00      0.71      0.83        66\n",
      "       Coronavirus       0.86      0.74      0.79        34\n",
      "              Food       0.79      0.39      0.52        98\n",
      "     Non-Political       0.53      0.69      0.60       374\n",
      "       Photography       0.73      0.37      0.49        95\n",
      "    Policy/Economy       0.64      0.73      0.68       529\n",
      "          Politics       0.71      0.61      0.65       430\n",
      "Science/Technology       0.73      0.48      0.58       237\n",
      "            Sports       0.87      0.64      0.74       135\n",
      "\n",
      "          accuracy                           0.67      2747\n",
      "         macro avg       0.75      0.62      0.66      2747\n",
      "      weighted avg       0.69      0.67      0.66      2747\n",
      "\n",
      "\n",
      " TESTING THE RANDOM FORESTS MODEL \n",
      "\n",
      "confusion matrix\n",
      "[[467   0   0   0   1  18   0   7   1   1   0]\n",
      " [ 56  65   0   0   0  18   0 113   1   1   0]\n",
      " [ 13   0  44   0   0   4   0   2   3   0   0]\n",
      " [  4   0   0  22   1   3   0   3   1   0   0]\n",
      " [ 29   2   0   4  27  24   0  11   0   1   0]\n",
      " [ 32   0   0   0   2 277   0  47  10   0   6]\n",
      " [ 18   0   0   0   1  49  24   3   0   0   0]\n",
      " [ 66  11   0   0   0  24   0 402  22   4   0]\n",
      " [ 41   2   1   0   0  91   0  98 196   1   0]\n",
      " [ 48   3   0   0   0  43   0  82   5  56   0]\n",
      " [ 35   0   0   0   0  23   0  15   2   0  60]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.58      0.94      0.72       495\n",
      "  Business/Finance       0.78      0.26      0.39       254\n",
      "       CAA-NRC-NPR       0.98      0.67      0.79        66\n",
      "       Coronavirus       0.85      0.65      0.73        34\n",
      "              Food       0.84      0.28      0.42        98\n",
      "     Non-Political       0.48      0.74      0.58       374\n",
      "       Photography       1.00      0.25      0.40        95\n",
      "    Policy/Economy       0.51      0.76      0.61       529\n",
      "          Politics       0.81      0.46      0.58       430\n",
      "Science/Technology       0.88      0.24      0.37       237\n",
      "            Sports       0.91      0.44      0.60       135\n",
      "\n",
      "          accuracy                           0.60      2747\n",
      "         macro avg       0.78      0.52      0.56      2747\n",
      "      weighted avg       0.69      0.60      0.57      2747\n",
      "\n",
      "\n",
      " TESTING THE SVM MODEL \n",
      "confusion matrix\n",
      "[[447   2   0   0   8   6   2  17  12   1   0]\n",
      " [ 70  70   0   0   2  10   1  83  10   2   6]\n",
      " [ 14   0  38   0   0   3   0   4   7   0   0]\n",
      " [  3   0   0  27   1   0   0   1   2   0   0]\n",
      " [ 24   0   0   0  46   3   3  10  12   0   0]\n",
      " [ 53   5   1   1   3 106  32  42 114   1  16]\n",
      " [ 19   0   0   0   1   9  38   1  26   0   1]\n",
      " [ 65  24   1   0   1  13   4 371  42   4   4]\n",
      " [ 34   8   2   2   1  30  18  82 248   3   2]\n",
      " [ 50  12   0   2   0  20   4  52  24  63  10]\n",
      " [ 27   0   0   0   0   4   2   5   7   1  89]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.55      0.90      0.69       495\n",
      "  Business/Finance       0.58      0.28      0.37       254\n",
      "       CAA-NRC-NPR       0.90      0.58      0.70        66\n",
      "       Coronavirus       0.84      0.79      0.82        34\n",
      "              Food       0.73      0.47      0.57        98\n",
      "     Non-Political       0.52      0.28      0.37       374\n",
      "       Photography       0.37      0.40      0.38        95\n",
      "    Policy/Economy       0.56      0.70      0.62       529\n",
      "          Politics       0.49      0.58      0.53       430\n",
      "Science/Technology       0.84      0.27      0.40       237\n",
      "            Sports       0.70      0.66      0.68       135\n",
      "\n",
      "          accuracy                           0.56      2747\n",
      "         macro avg       0.64      0.54      0.56      2747\n",
      "      weighted avg       0.59      0.56      0.54      2747\n",
      "\n",
      "\n",
      " TESTING THE NAIVE BAYES MODEL\n",
      "confusion matrix\n",
      "[[417   2   0   0   0   4   0  67   5   0   0]\n",
      " [ 40  34   0   0   0   5   0 175   0   0   0]\n",
      " [ 14   0   3   0   0   2   0  36  11   0   0]\n",
      " [  2   0   0   0   0   1   0  25   6   0   0]\n",
      " [ 26   0   0   0   0  10   0  51  11   0   0]\n",
      " [ 56   1   0   0   0 176   0  96  45   0   0]\n",
      " [ 20   1   0   0   0  44  15  11   4   0   0]\n",
      " [ 14   4   0   0   0   7   0 494  10   0   0]\n",
      " [ 20   1   0   0   0  38   0 150 221   0   0]\n",
      " [ 42   2   0   0   0   8   0 153   9  23   0]\n",
      " [ 27   0   0   0   0  10   0  55   8   0  35]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.62      0.84      0.71       495\n",
      "  Business/Finance       0.76      0.13      0.23       254\n",
      "       CAA-NRC-NPR       1.00      0.05      0.09        66\n",
      "       Coronavirus       0.00      0.00      0.00        34\n",
      "              Food       0.00      0.00      0.00        98\n",
      "     Non-Political       0.58      0.47      0.52       374\n",
      "       Photography       1.00      0.16      0.27        95\n",
      "    Policy/Economy       0.38      0.93      0.54       529\n",
      "          Politics       0.67      0.51      0.58       430\n",
      "Science/Technology       1.00      0.10      0.18       237\n",
      "            Sports       1.00      0.26      0.41       135\n",
      "\n",
      "          accuracy                           0.52      2747\n",
      "         macro avg       0.64      0.31      0.32      2747\n",
      "      weighted avg       0.63      0.52      0.46      2747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X=df['author']+df['stemmed_titles']+df['processed_url']\n",
    "y=df['flair']\n",
    "test_models(X,y,'author,stemmed_titles,processed_url')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing after removing common occurring words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING THE  LOGISTIC REGRESSION MODEL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[110  15   0   0   3   4   1  10   6  11   1]\n",
      " [ 14 129   0   0   4   8   0  21   8  20   1]\n",
      " [  2   0  57   0   0   1   1   1   4   1   1]\n",
      " [  1   0   1  23   2   0   0   0   1   0   0]\n",
      " [  7   0   1   1  51  11   1   2   6   4   1]\n",
      " [  3   6   0   0   3 113   5   7  23   4   5]\n",
      " [  7   0   0   0   1  26  55   0   1   1   1]\n",
      " [  8  35   0   0   2   8   0 107  19  19   0]\n",
      " [  1   3   0   2   3  26   2  19 128   3   3]\n",
      " [ 19  13   0   0   2   8   2  13   7 143   2]\n",
      " [  9   0   0   0   3   8   2   0   3   3 111]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.61      0.68      0.64       161\n",
      "  Business/Finance       0.64      0.63      0.64       205\n",
      "       CAA-NRC-NPR       0.97      0.84      0.90        68\n",
      "       Coronavirus       0.88      0.82      0.85        28\n",
      "              Food       0.69      0.60      0.64        85\n",
      "     Non-Political       0.53      0.67      0.59       169\n",
      "       Photography       0.80      0.60      0.68        92\n",
      "    Policy/Economy       0.59      0.54      0.57       198\n",
      "          Politics       0.62      0.67      0.65       190\n",
      "Science/Technology       0.68      0.68      0.68       209\n",
      "            Sports       0.88      0.80      0.84       139\n",
      "\n",
      "          accuracy                           0.67      1544\n",
      "         macro avg       0.72      0.69      0.70      1544\n",
      "      weighted avg       0.68      0.67      0.67      1544\n",
      "\n",
      "\n",
      " TESTING THE RANDOM FORESTS MODEL \n",
      "\n",
      "confusion matrix\n",
      "[[141   1   0   0   0   3   0   3   8   5   0]\n",
      " [ 26 114   0   0   1  15   0   8   3  38   0]\n",
      " [  4   0  54   0   0   1   1   1   3   3   1]\n",
      " [  1   0   1  18   1   2   0   0   3   2   0]\n",
      " [ 15   0   0   2  32  19   3   0   5   7   2]\n",
      " [  5   1   0   0   2 131   2   4  15   6   3]\n",
      " [ 12   0   0   0   0  13  62   0   0   5   0]\n",
      " [ 12  35   0   0   1   9   0  88  27  26   0]\n",
      " [  3   3   0   2   1  35   3   5 128   8   2]\n",
      " [ 26  14   0   0   0  12   5   7   6 135   4]\n",
      " [ 12   6   0   0   3   7   2   0   8   8  93]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.55      0.88      0.67       161\n",
      "  Business/Finance       0.66      0.56      0.60       205\n",
      "       CAA-NRC-NPR       0.98      0.79      0.88        68\n",
      "       Coronavirus       0.82      0.64      0.72        28\n",
      "              Food       0.78      0.38      0.51        85\n",
      "     Non-Political       0.53      0.78      0.63       169\n",
      "       Photography       0.79      0.67      0.73        92\n",
      "    Policy/Economy       0.76      0.44      0.56       198\n",
      "          Politics       0.62      0.67      0.65       190\n",
      "Science/Technology       0.56      0.65      0.60       209\n",
      "            Sports       0.89      0.67      0.76       139\n",
      "\n",
      "          accuracy                           0.65      1544\n",
      "         macro avg       0.72      0.65      0.66      1544\n",
      "      weighted avg       0.68      0.65      0.64      1544\n",
      "\n",
      "\n",
      " TESTING THE SVM MODEL \n",
      "confusion matrix\n",
      "[[ 86  22   1   0   9   3   3  10  10  14   3]\n",
      " [ 13 132   0   0   5   3   1  22   9  17   3]\n",
      " [  3   0  55   0   1   1   0   1   4   2   1]\n",
      " [  1   0   0  23   3   0   0   0   1   0   0]\n",
      " [  3   0   1   1  66   2   1   1   6   4   0]\n",
      " [  3   6   0   0  14  96   4   5  23   4  14]\n",
      " [  3   0   0   0   4  27  50   1   2   1   4]\n",
      " [  7  28   2   0   3   7   1 107  23  14   6]\n",
      " [  2   5   5   3   6  12   6  14 125   5   7]\n",
      " [ 19  12   1   4   4   9   3  20   7 123   7]\n",
      " [  5   0   0   0   1   3   2   1   6   1 120]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.59      0.53      0.56       161\n",
      "  Business/Finance       0.64      0.64      0.64       205\n",
      "       CAA-NRC-NPR       0.85      0.81      0.83        68\n",
      "       Coronavirus       0.74      0.82      0.78        28\n",
      "              Food       0.57      0.78      0.66        85\n",
      "     Non-Political       0.59      0.57      0.58       169\n",
      "       Photography       0.70      0.54      0.61        92\n",
      "    Policy/Economy       0.59      0.54      0.56       198\n",
      "          Politics       0.58      0.66      0.62       190\n",
      "Science/Technology       0.66      0.59      0.62       209\n",
      "            Sports       0.73      0.86      0.79       139\n",
      "\n",
      "          accuracy                           0.64      1544\n",
      "         macro avg       0.66      0.67      0.66      1544\n",
      "      weighted avg       0.64      0.64      0.63      1544\n",
      "\n",
      "\n",
      " TESTING THE NAIVE BAYES MODEL\n",
      "confusion matrix\n",
      "[[ 47  19   0   0   0  52   0   6  31   6   0]\n",
      " [  5 117   0   0   0  14   0  22  28  19   0]\n",
      " [  2   0  12   0   0   1   0   6  45   2   0]\n",
      " [  2   0   0   0   0   5   0   2  12   7   0]\n",
      " [  3   0   0   0   7  50   0   1  18   6   0]\n",
      " [  0   1   0   0   1 133   0   2  31   0   1]\n",
      " [  2   0   0   0   0  71  11   0   3   5   0]\n",
      " [  0  20   0   0   0  18   0 103  51   6   0]\n",
      " [  0   2   0   0   0  20   0   9 154   4   1]\n",
      " [ 10   9   0   0   0  31   0  19  26 114   0]\n",
      " [  4   2   0   0   0  38   0   3  22   7  63]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.63      0.29      0.40       161\n",
      "  Business/Finance       0.69      0.57      0.62       205\n",
      "       CAA-NRC-NPR       1.00      0.18      0.30        68\n",
      "       Coronavirus       0.00      0.00      0.00        28\n",
      "              Food       0.88      0.08      0.15        85\n",
      "     Non-Political       0.31      0.79      0.44       169\n",
      "       Photography       1.00      0.12      0.21        92\n",
      "    Policy/Economy       0.60      0.52      0.56       198\n",
      "          Politics       0.37      0.81      0.50       190\n",
      "Science/Technology       0.65      0.55      0.59       209\n",
      "            Sports       0.97      0.45      0.62       139\n",
      "\n",
      "          accuracy                           0.49      1544\n",
      "         macro avg       0.64      0.40      0.40      1544\n",
      "      weighted avg       0.64      0.49      0.48      1544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X=strip_df['title_comments_stem']+strip_df['processed_url']\n",
    "y=strip_df['flair']\n",
    "test_models(X,y,'title-comments-combined,processed_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING THE  LOGISTIC REGRESSION MODEL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[403  18   0   0   7  22   1  18  14   9   3]\n",
      " [ 28 150   0   0   0  11   0  55   5   5   0]\n",
      " [  6   0  48   0   0   0   1   7   4   0   0]\n",
      " [  1   0   0  25   1   2   0   1   4   0   0]\n",
      " [ 19   2   0   2  46  12   0   7   7   2   1]\n",
      " [ 19   2   0   0   5 275   9  13  43   3   5]\n",
      " [ 16   0   0   0   2  29  46   1   0   1   0]\n",
      " [ 18  50   0   0   2  18   2 395  33  11   0]\n",
      " [ 11   5   1   0   1  47   3  24 331   5   2]\n",
      " [ 30  17   0   0   0  27   2  42   8 108   3]\n",
      " [ 14   2   0   0   1   7   2   6   2   3  98]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.71      0.81      0.76       495\n",
      "  Business/Finance       0.61      0.59      0.60       254\n",
      "       CAA-NRC-NPR       0.98      0.73      0.83        66\n",
      "       Coronavirus       0.93      0.74      0.82        34\n",
      "              Food       0.71      0.47      0.56        98\n",
      "     Non-Political       0.61      0.74      0.67       374\n",
      "       Photography       0.70      0.48      0.57        95\n",
      "    Policy/Economy       0.69      0.75      0.72       529\n",
      "          Politics       0.73      0.77      0.75       430\n",
      "Science/Technology       0.73      0.46      0.56       237\n",
      "            Sports       0.88      0.73      0.79       135\n",
      "\n",
      "          accuracy                           0.70      2747\n",
      "         macro avg       0.75      0.66      0.70      2747\n",
      "      weighted avg       0.71      0.70      0.70      2747\n",
      "\n",
      "\n",
      " TESTING THE RANDOM FORESTS MODEL \n",
      "\n",
      "confusion matrix\n",
      "[[453   0   0   0   0  10   0  16  15   0   1]\n",
      " [ 38  55   0   0   0  13   1 140   6   1   0]\n",
      " [ 11   0  42   0   0   0   1   5   7   0   0]\n",
      " [  3   0   0  13   0   4   0  10   4   0   0]\n",
      " [ 27   0   0   1   9  28   0  25   6   0   2]\n",
      " [ 32   0   0   0   0 258   6  39  39   0   0]\n",
      " [ 18   0   0   0   0  31  34  12   0   0   0]\n",
      " [ 31   7   0   0   0  14   0 439  37   1   0]\n",
      " [ 17   0   1   0   0  46   1  58 306   1   0]\n",
      " [ 49   0   0   0   0  20   1 109  12  45   1]\n",
      " [ 21   0   0   0   1  20   1  28   5   0  59]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.65      0.92      0.76       495\n",
      "  Business/Finance       0.89      0.22      0.35       254\n",
      "       CAA-NRC-NPR       0.98      0.64      0.77        66\n",
      "       Coronavirus       0.93      0.38      0.54        34\n",
      "              Food       0.90      0.09      0.17        98\n",
      "     Non-Political       0.58      0.69      0.63       374\n",
      "       Photography       0.76      0.36      0.49        95\n",
      "    Policy/Economy       0.50      0.83      0.62       529\n",
      "          Politics       0.70      0.71      0.71       430\n",
      "Science/Technology       0.94      0.19      0.32       237\n",
      "            Sports       0.94      0.44      0.60       135\n",
      "\n",
      "          accuracy                           0.62      2747\n",
      "         macro avg       0.80      0.50      0.54      2747\n",
      "      weighted avg       0.70      0.62      0.59      2747\n",
      "\n",
      "\n",
      " TESTING THE SVM MODEL \n",
      "confusion matrix\n",
      "[[406   1   0   4   1   8   1  33  34   2   5]\n",
      " [ 54  66   0   2   1   7   0 102  16   3   3]\n",
      " [  8   0  38   1   0   0   1   4  14   0   0]\n",
      " [  1   0   0  27   0   1   0   1   4   0   0]\n",
      " [ 27   2   0   5  23  11   2  15   8   1   4]\n",
      " [ 49   4   0   3   2 154  10  31  93   4  24]\n",
      " [ 16   0   0   0   0  32  44   0   0   0   3]\n",
      " [ 32  15   2   7   2   6   2 408  49   3   3]\n",
      " [  9   4   3   3   1  21   1  35 345   3   5]\n",
      " [ 48  11   0   5   0  16   3  65  26  54   9]\n",
      " [ 10   0   0   0   0   1   2   5   6   1 110]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.62      0.82      0.70       495\n",
      "  Business/Finance       0.64      0.26      0.37       254\n",
      "       CAA-NRC-NPR       0.88      0.58      0.70        66\n",
      "       Coronavirus       0.47      0.79      0.59        34\n",
      "              Food       0.77      0.23      0.36        98\n",
      "     Non-Political       0.60      0.41      0.49       374\n",
      "       Photography       0.67      0.46      0.55        95\n",
      "    Policy/Economy       0.58      0.77      0.66       529\n",
      "          Politics       0.58      0.80      0.67       430\n",
      "Science/Technology       0.76      0.23      0.35       237\n",
      "            Sports       0.66      0.81      0.73       135\n",
      "\n",
      "          accuracy                           0.61      2747\n",
      "         macro avg       0.66      0.56      0.56      2747\n",
      "      weighted avg       0.63      0.61      0.58      2747\n",
      "\n",
      "\n",
      " TESTING THE NAIVE BAYES MODEL\n",
      "confusion matrix\n",
      "[[347   0   0   0   0  22   0  66  60   0   0]\n",
      " [ 36   5   0   0   0   5   0 194  14   0   0]\n",
      " [  3   0   0   0   0   0   0  30  33   0   0]\n",
      " [  3   0   0   0   0   0   0  13  18   0   0]\n",
      " [ 33   0   0   0   0  23   0  23  19   0   0]\n",
      " [ 39   0   0   0   0 185   0  37 113   0   0]\n",
      " [ 22   0   0   0   0  50   7   8   8   0   0]\n",
      " [ 10   0   0   0   0   7   0 467  45   0   0]\n",
      " [  4   0   0   0   0  12   0  49 365   0   0]\n",
      " [ 49   0   0   0   0  11   0 132  39   6   0]\n",
      " [ 27   0   0   0   0  18   0  37  43   0  10]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.61      0.70      0.65       495\n",
      "  Business/Finance       1.00      0.02      0.04       254\n",
      "       CAA-NRC-NPR       0.00      0.00      0.00        66\n",
      "       Coronavirus       0.00      0.00      0.00        34\n",
      "              Food       0.00      0.00      0.00        98\n",
      "     Non-Political       0.56      0.49      0.52       374\n",
      "       Photography       1.00      0.07      0.14        95\n",
      "    Policy/Economy       0.44      0.88      0.59       529\n",
      "          Politics       0.48      0.85      0.61       430\n",
      "Science/Technology       1.00      0.03      0.05       237\n",
      "            Sports       1.00      0.07      0.14       135\n",
      "\n",
      "          accuracy                           0.51      2747\n",
      "         macro avg       0.55      0.28      0.25      2747\n",
      "      weighted avg       0.61      0.51      0.42      2747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X=df['author']+df['title_comments_stem']+df['processed_url']\n",
    "y=df['flair']\n",
    "test_models(X,y,'author,title-comments-combined,processed_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING THE  LOGISTIC REGRESSION MODEL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[123  14   0   0   4   5   1   9   8  11   0]\n",
      " [ 13 125   0   0   3  12   0  20   6  24   0]\n",
      " [  2   0  59   0   0   2   0   1   3   0   1]\n",
      " [  1   0   1  22   1   0   0   1   2   0   0]\n",
      " [ 14   2   1   1  52   5   1   1   4   9   1]\n",
      " [  4   4   0   0   9 121   5   4  16   4   1]\n",
      " [  7   0   0   0   1  22  52   0   0   3   0]\n",
      " [  6  26   1   0   1   6   0 110  23  17   1]\n",
      " [  2   3   0   2   2  21   0  16 129   6   1]\n",
      " [ 19  13   0   0   1  13   0  12   5 140   4]\n",
      " [  9   0   0   0   3   9   1   0   3   5 117]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.61      0.70      0.66       175\n",
      "  Business/Finance       0.67      0.62      0.64       203\n",
      "       CAA-NRC-NPR       0.95      0.87      0.91        68\n",
      "       Coronavirus       0.88      0.79      0.83        28\n",
      "              Food       0.68      0.57      0.62        91\n",
      "     Non-Political       0.56      0.72      0.63       168\n",
      "       Photography       0.87      0.61      0.72        85\n",
      "    Policy/Economy       0.63      0.58      0.60       191\n",
      "          Politics       0.65      0.71      0.68       182\n",
      "Science/Technology       0.64      0.68      0.66       207\n",
      "            Sports       0.93      0.80      0.86       147\n",
      "\n",
      "          accuracy                           0.68      1545\n",
      "         macro avg       0.73      0.69      0.71      1545\n",
      "      weighted avg       0.69      0.68      0.68      1545\n",
      "\n",
      "\n",
      " TESTING THE RANDOM FORESTS MODEL \n",
      "\n",
      "confusion matrix\n",
      "[[151   2   0   0   0   4   1   2   9   6   0]\n",
      " [ 19 105   0   0   0  18   1  10   7  43   0]\n",
      " [  3   0  55   0   0   1   1   0   5   3   0]\n",
      " [  1   0   1  14   1   1   0   0   7   3   0]\n",
      " [ 17   0   0   2  24  24   0   0   5  17   2]\n",
      " [  5   1   0   0   2 123   2   0  22  13   0]\n",
      " [  8   0   0   0   1  13  42   0   0  21   0]\n",
      " [ 13  23   0   0   0  10   0  81  30  34   0]\n",
      " [  4   3   0   0   0  29   0   5 122  17   2]\n",
      " [ 25   7   0   0   0  12   0   6   9 147   1]\n",
      " [ 12   2   0   0   3  11   0   2   8  11  98]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.59      0.86      0.70       175\n",
      "  Business/Finance       0.73      0.52      0.61       203\n",
      "       CAA-NRC-NPR       0.98      0.81      0.89        68\n",
      "       Coronavirus       0.88      0.50      0.64        28\n",
      "              Food       0.77      0.26      0.39        91\n",
      "     Non-Political       0.50      0.73      0.59       168\n",
      "       Photography       0.89      0.49      0.64        85\n",
      "    Policy/Economy       0.76      0.42      0.55       191\n",
      "          Politics       0.54      0.67      0.60       182\n",
      "Science/Technology       0.47      0.71      0.56       207\n",
      "            Sports       0.95      0.67      0.78       147\n",
      "\n",
      "          accuracy                           0.62      1545\n",
      "         macro avg       0.73      0.60      0.63      1545\n",
      "      weighted avg       0.68      0.62      0.62      1545\n",
      "\n",
      "\n",
      " TESTING THE MLP MODEL\n",
      "confusion matrix\n",
      "[[ 87  20   0   0   1  12   6  19   2  15  13]\n",
      " [ 13 115   0   0   2   3   2  36   5  25   2]\n",
      " [  2   0  52   1   0   1   3   1   8   0   0]\n",
      " [  1   1   2  17   1   0   2   0   3   0   1]\n",
      " [  4   7   1   2  44  12   9   0   4   0   8]\n",
      " [  7   5   0   0   8 104   7   5  15  13   4]\n",
      " [  6   5   0   0   3  15  53   2   0   1   0]\n",
      " [  9  28   0   0   0   5   1 114  21  12   1]\n",
      " [  0   8   0   0   2  19   0  20 121  11   1]\n",
      " [ 21  33   0   0   0  13  10  24   6 100   0]\n",
      " [ 12   7   0   2   9   9   3   3   1   0 101]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.54      0.50      0.52       175\n",
      "  Business/Finance       0.50      0.57      0.53       203\n",
      "       CAA-NRC-NPR       0.95      0.76      0.85        68\n",
      "       Coronavirus       0.77      0.61      0.68        28\n",
      "              Food       0.63      0.48      0.55        91\n",
      "     Non-Political       0.54      0.62      0.58       168\n",
      "       Photography       0.55      0.62      0.59        85\n",
      "    Policy/Economy       0.51      0.60      0.55       191\n",
      "          Politics       0.65      0.66      0.66       182\n",
      "Science/Technology       0.56      0.48      0.52       207\n",
      "            Sports       0.77      0.69      0.73       147\n",
      "\n",
      "          accuracy                           0.59      1545\n",
      "         macro avg       0.63      0.60      0.61      1545\n",
      "      weighted avg       0.60      0.59      0.59      1545\n",
      "\n",
      "\n",
      " TESTING THE SVM MODEL \n",
      "confusion matrix\n",
      "[[ 90  30   0   0  10   6   4   9  11  12   3]\n",
      " [ 12 128   0   0   3   6   1  18  10  22   3]\n",
      " [  2   0  56   0   1   0   1   1   4   1   2]\n",
      " [  1   0   0  24   2   0   0   0   1   0   0]\n",
      " [  5   2   1   2  59   4   1   0   5   9   3]\n",
      " [  5   5   1   0  16  95   6   4  21   5  10]\n",
      " [  3   0   0   0   4  22  46   1   2   5   2]\n",
      " [  8  32   2   1   4   3   0  95  24  17   5]\n",
      " [  2   6   3   2   4   9   1  12 132   7   4]\n",
      " [ 21  16   2   5   4   9   3  14  10 119   4]\n",
      " [  5   0   0   0   0   5   1   1   5   2 128]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.58      0.51      0.55       175\n",
      "  Business/Finance       0.58      0.63      0.61       203\n",
      "       CAA-NRC-NPR       0.86      0.82      0.84        68\n",
      "       Coronavirus       0.71      0.86      0.77        28\n",
      "              Food       0.55      0.65      0.60        91\n",
      "     Non-Political       0.60      0.57      0.58       168\n",
      "       Photography       0.72      0.54      0.62        85\n",
      "    Policy/Economy       0.61      0.50      0.55       191\n",
      "          Politics       0.59      0.73      0.65       182\n",
      "Science/Technology       0.60      0.57      0.59       207\n",
      "            Sports       0.78      0.87      0.82       147\n",
      "\n",
      "          accuracy                           0.63      1545\n",
      "         macro avg       0.65      0.66      0.65      1545\n",
      "      weighted avg       0.63      0.63      0.63      1545\n",
      "\n",
      "\n",
      " TESTING THE NAIVE BAYES MODEL\n",
      "confusion matrix\n",
      "[[ 40  18   0   0   0  55   0   6  46  10   0]\n",
      " [  4  99   0   0   0  16   0  35  29  20   0]\n",
      " [  1   0  13   0   0   1   0   4  46   3   0]\n",
      " [  2   0   0   0   0   1   0   2  20   3   0]\n",
      " [  3   0   0   0   5  48   0   1  25   9   0]\n",
      " [  0   1   0   0   0 126   0   0  41   0   0]\n",
      " [  2   0   0   0   0  68  11   0   1   3   0]\n",
      " [  0  20   0   0   0  11   0  92  61   7   0]\n",
      " [  0   1   0   0   0  11   0   4 163   3   0]\n",
      " [  7   9   0   0   0  31   0  14  35 111   0]\n",
      " [  3   1   0   0   0  32   0   3  34   4  70]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.65      0.23      0.34       175\n",
      "  Business/Finance       0.66      0.49      0.56       203\n",
      "       CAA-NRC-NPR       1.00      0.19      0.32        68\n",
      "       Coronavirus       0.00      0.00      0.00        28\n",
      "              Food       1.00      0.05      0.10        91\n",
      "     Non-Political       0.32      0.75      0.44       168\n",
      "       Photography       1.00      0.13      0.23        85\n",
      "    Policy/Economy       0.57      0.48      0.52       191\n",
      "          Politics       0.33      0.90      0.48       182\n",
      "Science/Technology       0.64      0.54      0.58       207\n",
      "            Sports       1.00      0.48      0.65       147\n",
      "\n",
      "          accuracy                           0.47      1545\n",
      "         macro avg       0.65      0.38      0.38      1545\n",
      "      weighted avg       0.64      0.47      0.45      1545\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X=strip_df['title_comments_stem']+strip_df['processed_url']+strip_df['author']\n",
    "y=strip_df['flair']\n",
    "test_models(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(df[df['stemmed_titles'].isna()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING THE  LOGISTIC REGRESSION MODEL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[437  15   0   0   3  15   1  11   8   4   1]\n",
      " [ 21 149   0   0   0  13   0  59   5   7   0]\n",
      " [  8   0  49   0   0   2   0   4   3   0   0]\n",
      " [  1   0   0  26   1   1   0   2   2   0   1]\n",
      " [ 19   2   0   1  47  12   1  10   1   4   1]\n",
      " [ 20   3   0   0   3 255  12  24  46   4   7]\n",
      " [ 14   5   0   0   1  35  36   1   3   0   0]\n",
      " [ 24  33   0   0   1  23   0 393  43  12   0]\n",
      " [ 20   8   0   0   0  68   4  52 272   5   1]\n",
      " [ 26  17   0   0   0  22   0  42  14 116   0]\n",
      " [ 16   1   0   0   0  13   2   4   2   6  91]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.72      0.88      0.79       495\n",
      "  Business/Finance       0.64      0.59      0.61       254\n",
      "       CAA-NRC-NPR       1.00      0.74      0.85        66\n",
      "       Coronavirus       0.96      0.76      0.85        34\n",
      "              Food       0.84      0.48      0.61        98\n",
      "     Non-Political       0.56      0.68      0.61       374\n",
      "       Photography       0.64      0.38      0.48        95\n",
      "    Policy/Economy       0.65      0.74      0.69       529\n",
      "          Politics       0.68      0.63      0.66       430\n",
      "Science/Technology       0.73      0.49      0.59       237\n",
      "            Sports       0.89      0.67      0.77       135\n",
      "\n",
      "          accuracy                           0.68      2747\n",
      "         macro avg       0.76      0.64      0.68      2747\n",
      "      weighted avg       0.69      0.68      0.68      2747\n",
      "\n",
      "\n",
      " TESTING THE RANDOM FORESTS MODEL \n",
      "\n",
      "confusion matrix\n",
      "[[465   0   0   0   3  17   0   7   1   1   1]\n",
      " [ 53  67   0   0   0  20   0 111   1   2   0]\n",
      " [ 12   0  46   0   0   4   0   2   2   0   0]\n",
      " [  4   0   0  26   1   2   0   1   0   0   0]\n",
      " [ 24   2   0   5  35  21   0  11   0   0   0]\n",
      " [ 30   0   0   0   1 276   1  43  18   0   5]\n",
      " [ 18   0   0   0   1  48  25   3   0   0   0]\n",
      " [ 62   9   0   0   0  20   0 412  24   2   0]\n",
      " [ 36   2   1   0   0  87   0  90 213   1   0]\n",
      " [ 48   4   0   0   0  38   0  80   5  62   0]\n",
      " [ 32   1   0   0   0  22   0  14   2   0  64]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.59      0.94      0.73       495\n",
      "  Business/Finance       0.79      0.26      0.40       254\n",
      "       CAA-NRC-NPR       0.98      0.70      0.81        66\n",
      "       Coronavirus       0.84      0.76      0.80        34\n",
      "              Food       0.85      0.36      0.50        98\n",
      "     Non-Political       0.50      0.74      0.59       374\n",
      "       Photography       0.96      0.26      0.41        95\n",
      "    Policy/Economy       0.53      0.78      0.63       529\n",
      "          Politics       0.80      0.50      0.61       430\n",
      "Science/Technology       0.91      0.26      0.41       237\n",
      "            Sports       0.91      0.47      0.62       135\n",
      "\n",
      "          accuracy                           0.62      2747\n",
      "         macro avg       0.79      0.55      0.59      2747\n",
      "      weighted avg       0.70      0.62      0.59      2747\n",
      "\n",
      "\n",
      " TESTING THE SVM MODEL \n",
      "confusion matrix\n",
      "[[444   4   1   0   8   8   2  17   9   1   1]\n",
      " [ 63  73   3   0   2  12   1  84  11   2   3]\n",
      " [ 13   0  36   0   0   3   0   6   8   0   0]\n",
      " [  2   0   1  29   1   0   0   0   1   0   0]\n",
      " [ 24   0   2   0  50  13   0   7   2   0   0]\n",
      " [ 58   6   5   0   2 213   7  37  37   1   8]\n",
      " [ 16   1   0   0   1  38  35   2   2   0   0]\n",
      " [ 65  20   5   0   1  15   2 376  40   3   2]\n",
      " [ 30   8   4   3   1  61   2  73 243   3   2]\n",
      " [ 51   8   8   2   0  18   4  55  21  68   2]\n",
      " [ 27   0   1   0   0   8   0   4   3   0  92]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.56      0.90      0.69       495\n",
      "  Business/Finance       0.61      0.29      0.39       254\n",
      "       CAA-NRC-NPR       0.55      0.55      0.55        66\n",
      "       Coronavirus       0.85      0.85      0.85        34\n",
      "              Food       0.76      0.51      0.61        98\n",
      "     Non-Political       0.55      0.57      0.56       374\n",
      "       Photography       0.66      0.37      0.47        95\n",
      "    Policy/Economy       0.57      0.71      0.63       529\n",
      "          Politics       0.64      0.57      0.60       430\n",
      "Science/Technology       0.87      0.29      0.43       237\n",
      "            Sports       0.84      0.68      0.75       135\n",
      "\n",
      "          accuracy                           0.60      2747\n",
      "         macro avg       0.68      0.57      0.59      2747\n",
      "      weighted avg       0.63      0.60      0.59      2747\n",
      "\n",
      "\n",
      " TESTING THE NAIVE BAYES MODEL\n",
      "confusion matrix\n",
      "[[424   2   0   0   0   6   0  58   5   0   0]\n",
      " [ 40  35   0   0   0   3   0 174   2   0   0]\n",
      " [ 14   0   4   0   0   2   0  35  11   0   0]\n",
      " [  1   0   0   0   0   1   0  25   7   0   0]\n",
      " [ 29   2   0   0   0  11   0  47   9   0   0]\n",
      " [ 55   2   0   0   0 187   0  83  44   0   3]\n",
      " [ 19   1   0   0   0  43  15  11   6   0   0]\n",
      " [ 18   4   0   0   0   5   0 493   9   0   0]\n",
      " [ 22   1   0   0   0  34   0 145 227   1   0]\n",
      " [ 45   4   0   0   0   7   0 146   7  28   0]\n",
      " [ 26   0   0   0   0  13   0  51   8   0  37]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.61      0.86      0.71       495\n",
      "  Business/Finance       0.69      0.14      0.23       254\n",
      "       CAA-NRC-NPR       1.00      0.06      0.11        66\n",
      "       Coronavirus       0.00      0.00      0.00        34\n",
      "              Food       0.00      0.00      0.00        98\n",
      "     Non-Political       0.60      0.50      0.55       374\n",
      "       Photography       1.00      0.16      0.27        95\n",
      "    Policy/Economy       0.39      0.93      0.55       529\n",
      "          Politics       0.68      0.53      0.59       430\n",
      "Science/Technology       0.97      0.12      0.21       237\n",
      "            Sports       0.93      0.27      0.42       135\n",
      "\n",
      "          accuracy                           0.53      2747\n",
      "         macro avg       0.62      0.32      0.33      2747\n",
      "      weighted avg       0.62      0.53      0.47      2747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X=df['stemmed_titles']+df['processed_url']\n",
    "y=df['flair']\n",
    "test_models(X,y,'stemmed_titles,processed_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=strip_df[strip_df['stemmed_titles'].isna()].index\n",
    "strip_df=strip_df.drop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING THE  LOGISTIC REGRESSION MODEL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[ 79  24   0   0   4  16   4   8   9  15   2]\n",
      " [ 19 131   0   0   3   5   0  16   4  25   2]\n",
      " [  0   0  59   0   0   0   0   4   4   1   0]\n",
      " [  0   0   0  24   0   0   1   1   1   1   0]\n",
      " [  4   3   0   2  50  12   0   5   2   5   2]\n",
      " [ 17   5   0   0   7  73   9   9  21  19   9]\n",
      " [  5   0   0   0   1  24  48   4   5   5   0]\n",
      " [  6  23   0   0   1  14   0 112  20  20   2]\n",
      " [  8  11   0   0   3  19   5  19 103  15   7]\n",
      " [ 23  18   0   0   3  15   1  13  17 115   4]\n",
      " [  8   3   0   1   2  13   0   5   8   3  96]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.47      0.49      0.48       161\n",
      "  Business/Finance       0.60      0.64      0.62       205\n",
      "       CAA-NRC-NPR       1.00      0.87      0.93        68\n",
      "       Coronavirus       0.89      0.86      0.87        28\n",
      "              Food       0.68      0.59      0.63        85\n",
      "     Non-Political       0.38      0.43      0.41       169\n",
      "       Photography       0.71      0.52      0.60        92\n",
      "    Policy/Economy       0.57      0.57      0.57       198\n",
      "          Politics       0.53      0.54      0.54       190\n",
      "Science/Technology       0.51      0.55      0.53       209\n",
      "            Sports       0.77      0.69      0.73       139\n",
      "\n",
      "          accuracy                           0.58      1544\n",
      "         macro avg       0.65      0.61      0.63      1544\n",
      "      weighted avg       0.59      0.58      0.58      1544\n",
      "\n",
      "\n",
      " TESTING THE RANDOM FORESTS MODEL \n",
      "\n",
      "confusion matrix\n",
      "[[ 67  17   0   0   1  53   2   7   1  12   1]\n",
      " [  9 112   0   0   2  43   0   6   7  24   2]\n",
      " [  1   0  55   0   0   3   0   3   5   1   0]\n",
      " [  0   0   0  25   0   2   0   0   1   0   0]\n",
      " [  7   0   1   2  43  29   0   0   2   0   1]\n",
      " [  9   4   0   0   3 118   7   6   8  11   3]\n",
      " [  3   0   0   0   1  49  34   2   1   2   0]\n",
      " [  5  26   1   0   0  42   0 102  10  12   0]\n",
      " [  3   5   3   0   0  68   0  14  80  12   5]\n",
      " [ 10   9   0   1   2  58   1  21  10  96   1]\n",
      " [  4   1   0   1   0  36   0   2   1   1  93]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.57      0.42      0.48       161\n",
      "  Business/Finance       0.64      0.55      0.59       205\n",
      "       CAA-NRC-NPR       0.92      0.81      0.86        68\n",
      "       Coronavirus       0.86      0.89      0.88        28\n",
      "              Food       0.83      0.51      0.63        85\n",
      "     Non-Political       0.24      0.70      0.35       169\n",
      "       Photography       0.77      0.37      0.50        92\n",
      "    Policy/Economy       0.63      0.52      0.57       198\n",
      "          Politics       0.63      0.42      0.51       190\n",
      "Science/Technology       0.56      0.46      0.51       209\n",
      "            Sports       0.88      0.67      0.76       139\n",
      "\n",
      "          accuracy                           0.53      1544\n",
      "         macro avg       0.68      0.57      0.60      1544\n",
      "      weighted avg       0.63      0.53      0.56      1544\n",
      "\n",
      "\n",
      " TESTING THE SVM MODEL \n",
      "confusion matrix\n",
      "[[ 82  21   1   0  11   8   3  11   4  12   8]\n",
      " [ 19 129   0   0  11   7   2  11   7  13   6]\n",
      " [  2   0  54   0   1   0   0   3   7   0   1]\n",
      " [  0   0   0  24   2   0   1   0   1   0   0]\n",
      " [  7   3   2   0  60   5   2   3   1   2   0]\n",
      " [ 17  10   0   1  28  45  15  12  16  13  12]\n",
      " [  7   2   0   0   8  14  49   4   3   5   0]\n",
      " [  8  30   2   0   9  10   3 113  12   9   2]\n",
      " [ 11  13   5   3  13  12   3  28  84   7  11]\n",
      " [ 19  18   2   2  18  10   2  24  10  94  10]\n",
      " [  7   3   0   1  10   5   0   4   2   2 105]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.46      0.51      0.48       161\n",
      "  Business/Finance       0.56      0.63      0.59       205\n",
      "       CAA-NRC-NPR       0.82      0.79      0.81        68\n",
      "       Coronavirus       0.77      0.86      0.81        28\n",
      "              Food       0.35      0.71      0.47        85\n",
      "     Non-Political       0.39      0.27      0.32       169\n",
      "       Photography       0.61      0.53      0.57        92\n",
      "    Policy/Economy       0.53      0.57      0.55       198\n",
      "          Politics       0.57      0.44      0.50       190\n",
      "Science/Technology       0.60      0.45      0.51       209\n",
      "            Sports       0.68      0.76      0.71       139\n",
      "\n",
      "          accuracy                           0.54      1544\n",
      "         macro avg       0.58      0.59      0.58      1544\n",
      "      weighted avg       0.55      0.54      0.54      1544\n",
      "\n",
      "\n",
      " TESTING THE NAIVE BAYES MODEL\n",
      "confusion matrix\n",
      "[[ 81  23   0   0   0  11   0   9   8  29   0]\n",
      " [ 11 132   0   0   0   5   0  14   6  36   1]\n",
      " [  2   0  29   0   0   4   0   3  18  11   1]\n",
      " [  1   0   0   1   3   2   0   4   7  10   0]\n",
      " [ 14   2   0   0  31  13   0   9   3  13   0]\n",
      " [ 14   7   0   0   0  73   2  12  25  31   5]\n",
      " [  8   0   0   0   1  30  22   7   8  16   0]\n",
      " [  7  24   1   0   0  10   0 113  15  28   0]\n",
      " [  8   8   0   0   0  21   0  23  99  26   5]\n",
      " [ 17  11   0   0   2   7   0  15  15 141   1]\n",
      " [ 11   4   0   1   0  10   0   7   9  12  85]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.47      0.50      0.48       161\n",
      "  Business/Finance       0.63      0.64      0.63       205\n",
      "       CAA-NRC-NPR       0.97      0.43      0.59        68\n",
      "       Coronavirus       0.50      0.04      0.07        28\n",
      "              Food       0.84      0.36      0.51        85\n",
      "     Non-Political       0.39      0.43      0.41       169\n",
      "       Photography       0.92      0.24      0.38        92\n",
      "    Policy/Economy       0.52      0.57      0.55       198\n",
      "          Politics       0.46      0.52      0.49       190\n",
      "Science/Technology       0.40      0.67      0.50       209\n",
      "            Sports       0.87      0.61      0.72       139\n",
      "\n",
      "          accuracy                           0.52      1544\n",
      "         macro avg       0.63      0.46      0.48      1544\n",
      "      weighted avg       0.58      0.52      0.52      1544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=strip_df['stemmed_titles']\n",
    "y=strip_df['flair']\n",
    "test_models(X,y,'stemmed_titles(reduced data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_csv('combined_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING THE  LOGISTIC REGRESSION MODEL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[393  18   1   0   6  28   3  18  16  10   1]\n",
      " [ 21 155   0   0   0  10   0  55   5  11   0]\n",
      " [  3   0  48   0   0   0   1  10   4   0   0]\n",
      " [  1   0   0  29   1   2   0   0   1   0   0]\n",
      " [ 14   2   0   1  43  25   3   5   3   0   2]\n",
      " [ 25   4   0   0   2 283   9  11  36   4   4]\n",
      " [ 14   1   0   0   1  28  45   0   0   2   0]\n",
      " [ 13  43   0   0   0  14   3 412  33  13   1]\n",
      " [ 10   4   1   0   2  56   0  38 313   4   1]\n",
      " [ 26  19   0   0   0  22   3  47  10 100   2]\n",
      " [ 15   0   0   0   1   9   2   7   4   4  98]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.73      0.80      0.76       494\n",
      "  Business/Finance       0.63      0.60      0.62       257\n",
      "       CAA-NRC-NPR       0.96      0.73      0.83        66\n",
      "       Coronavirus       0.97      0.85      0.91        34\n",
      "              Food       0.77      0.44      0.56        98\n",
      "     Non-Political       0.59      0.75      0.66       378\n",
      "       Photography       0.65      0.49      0.56        91\n",
      "    Policy/Economy       0.68      0.77      0.73       532\n",
      "          Politics       0.74      0.73      0.73       429\n",
      "Science/Technology       0.68      0.44      0.53       229\n",
      "            Sports       0.90      0.70      0.79       140\n",
      "\n",
      "          accuracy                           0.70      2748\n",
      "         macro avg       0.75      0.66      0.70      2748\n",
      "      weighted avg       0.71      0.70      0.69      2748\n",
      "\n",
      "\n",
      " TESTING THE RANDOM FORESTS MODEL \n",
      "\n",
      "confusion matrix\n",
      "[[455   0   0   0   0  11   1  10  15   1   1]\n",
      " [ 39  57   0   0   0  15   0 140   4   2   0]\n",
      " [ 12   0  41   0   0   0   1   5   7   0   0]\n",
      " [  2   0   0  18   0   4   0   5   5   0   0]\n",
      " [ 27   0   0   1   9  36   1  17   5   0   2]\n",
      " [ 23   0   0   0   0 289   4  28  34   0   0]\n",
      " [ 18   0   0   0   0  24  39  10   0   0   0]\n",
      " [ 30   8   0   0   0  11   0 455  27   1   0]\n",
      " [ 11   1   1   0   0  60   0  59 296   1   0]\n",
      " [ 37   2   0   0   0  20   2 104   9  54   1]\n",
      " [ 23   0   0   0   1  18   2  27   6   0  63]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.67      0.92      0.78       494\n",
      "  Business/Finance       0.84      0.22      0.35       257\n",
      "       CAA-NRC-NPR       0.98      0.62      0.76        66\n",
      "       Coronavirus       0.95      0.53      0.68        34\n",
      "              Food       0.90      0.09      0.17        98\n",
      "     Non-Political       0.59      0.76      0.67       378\n",
      "       Photography       0.78      0.43      0.55        91\n",
      "    Policy/Economy       0.53      0.86      0.65       532\n",
      "          Politics       0.73      0.69      0.71       429\n",
      "Science/Technology       0.92      0.24      0.37       229\n",
      "            Sports       0.94      0.45      0.61       140\n",
      "\n",
      "          accuracy                           0.65      2748\n",
      "         macro avg       0.80      0.53      0.57      2748\n",
      "      weighted avg       0.71      0.65      0.61      2748\n",
      "\n",
      "\n",
      " TESTING THE SVM MODEL \n",
      "confusion matrix\n",
      "[[412   4   0   0   1   9   1  27  34   1   5]\n",
      " [ 54  62   0   0   0   5   0 120  10   5   1]\n",
      " [  7   0  39   0   0   0   1   5  14   0   0]\n",
      " [  1   0   0  29   0   2   0   0   2   0   0]\n",
      " [ 24   0   0   4  30  15   2   9  10   3   1]\n",
      " [ 51   6   0   0   3 192   7  33  62   6  18]\n",
      " [ 15   1   0   0   1  29  41   1   0   0   3]\n",
      " [ 31  18   2   1   1   8   3 412  50   5   1]\n",
      " [ 13   3   4   3   2  27   0  42 327   2   6]\n",
      " [ 38  12   0   4   0  17   0  74  21  59   4]\n",
      " [ 12   0   0   0   0   2   1   6   7   0 112]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.63      0.83      0.72       494\n",
      "  Business/Finance       0.58      0.24      0.34       257\n",
      "       CAA-NRC-NPR       0.87      0.59      0.70        66\n",
      "       Coronavirus       0.71      0.85      0.77        34\n",
      "              Food       0.79      0.31      0.44        98\n",
      "     Non-Political       0.63      0.51      0.56       378\n",
      "       Photography       0.73      0.45      0.56        91\n",
      "    Policy/Economy       0.57      0.77      0.65       532\n",
      "          Politics       0.61      0.76      0.68       429\n",
      "Science/Technology       0.73      0.26      0.38       229\n",
      "            Sports       0.74      0.80      0.77       140\n",
      "\n",
      "          accuracy                           0.62      2748\n",
      "         macro avg       0.69      0.58      0.60      2748\n",
      "      weighted avg       0.64      0.62      0.60      2748\n",
      "\n",
      "\n",
      " TESTING THE NAIVE BAYES MODEL\n",
      "confusion matrix\n",
      "[[349   0   0   0   0  22   0  65  58   0   0]\n",
      " [ 32   6   0   0   0   2   0 205  12   0   0]\n",
      " [  3   0   0   0   0   0   0  32  31   0   0]\n",
      " [  3   0   0   0   0   0   0  14  17   0   0]\n",
      " [ 29   0   0   0   0  34   0  19  16   0   0]\n",
      " [ 42   0   0   0   0 205   0  36  95   0   0]\n",
      " [ 26   0   0   0   0  46   5  10   4   0   0]\n",
      " [  7   0   0   0   0   2   0 479  44   0   0]\n",
      " [  5   0   0   0   0  15   0  56 353   0   0]\n",
      " [ 45   0   0   0   0  11   0 140  25   8   0]\n",
      " [ 32   0   0   0   0  23   0  34  37   0  14]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.61      0.71      0.65       494\n",
      "  Business/Finance       1.00      0.02      0.05       257\n",
      "       CAA-NRC-NPR       0.00      0.00      0.00        66\n",
      "       Coronavirus       0.00      0.00      0.00        34\n",
      "              Food       0.00      0.00      0.00        98\n",
      "     Non-Political       0.57      0.54      0.56       378\n",
      "       Photography       1.00      0.05      0.10        91\n",
      "    Policy/Economy       0.44      0.90      0.59       532\n",
      "          Politics       0.51      0.82      0.63       429\n",
      "Science/Technology       1.00      0.03      0.07       229\n",
      "            Sports       1.00      0.10      0.18       140\n",
      "\n",
      "          accuracy                           0.52      2748\n",
      "         macro avg       0.56      0.29      0.26      2748\n",
      "      weighted avg       0.61      0.52      0.43      2748\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X=df2['title_comments_stem']+df2['processed_url']\n",
    "y=df2['flair']\n",
    "test_models(X,y,'title-comments-combined,processed_url(reduced data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip2=pd.read_csv('stripped_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes=strip2[strip2['title_comments_stem'].isna()].index\n",
    "strip2=strip2.drop(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING THE  LOGISTIC REGRESSION MODEL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[110  15   0   0   3   4   1  10   6  11   1]\n",
      " [ 14 129   0   0   4   8   0  21   8  20   1]\n",
      " [  2   0  57   0   0   1   1   1   4   1   1]\n",
      " [  1   0   1  23   2   0   0   0   1   0   0]\n",
      " [  7   0   1   1  51  11   1   2   6   4   1]\n",
      " [  3   6   0   0   3 113   5   7  23   4   5]\n",
      " [  7   0   0   0   1  26  55   0   1   1   1]\n",
      " [  8  35   0   0   2   8   0 107  19  19   0]\n",
      " [  1   3   0   2   3  26   2  19 128   3   3]\n",
      " [ 19  13   0   0   2   8   2  13   7 143   2]\n",
      " [  9   0   0   0   3   8   2   0   3   3 111]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.61      0.68      0.64       161\n",
      "  Business/Finance       0.64      0.63      0.64       205\n",
      "       CAA-NRC-NPR       0.97      0.84      0.90        68\n",
      "       Coronavirus       0.88      0.82      0.85        28\n",
      "              Food       0.69      0.60      0.64        85\n",
      "     Non-Political       0.53      0.67      0.59       169\n",
      "       Photography       0.80      0.60      0.68        92\n",
      "    Policy/Economy       0.59      0.54      0.57       198\n",
      "          Politics       0.62      0.67      0.65       190\n",
      "Science/Technology       0.68      0.68      0.68       209\n",
      "            Sports       0.88      0.80      0.84       139\n",
      "\n",
      "          accuracy                           0.67      1544\n",
      "         macro avg       0.72      0.69      0.70      1544\n",
      "      weighted avg       0.68      0.67      0.67      1544\n",
      "\n",
      "\n",
      " TESTING THE RANDOM FORESTS MODEL \n",
      "\n",
      "confusion matrix\n",
      "[[145   2   0   0   0   1   0   2   7   4   0]\n",
      " [ 27 114   0   0   1  14   2   3   7  37   0]\n",
      " [  4   0  53   0   0   1   1   1   4   4   0]\n",
      " [  1   0   1  17   1   2   0   0   4   2   0]\n",
      " [ 17   0   0   1  34  16   3   0   7   6   1]\n",
      " [  5   0   0   0   2 134   2   3  15   3   5]\n",
      " [ 10   0   0   0   0  14  62   0   0   6   0]\n",
      " [ 11  31   0   0   2  13   0  86  29  25   1]\n",
      " [  3   2   0   2   0  36   4   6 125   8   4]\n",
      " [ 23  16   0   0   0  14   3   7   6 137   3]\n",
      " [ 11   4   0   0   3   8   2   1   5   8  97]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.56      0.90      0.69       161\n",
      "  Business/Finance       0.67      0.56      0.61       205\n",
      "       CAA-NRC-NPR       0.98      0.78      0.87        68\n",
      "       Coronavirus       0.85      0.61      0.71        28\n",
      "              Food       0.79      0.40      0.53        85\n",
      "     Non-Political       0.53      0.79      0.64       169\n",
      "       Photography       0.78      0.67      0.73        92\n",
      "    Policy/Economy       0.79      0.43      0.56       198\n",
      "          Politics       0.60      0.66      0.63       190\n",
      "Science/Technology       0.57      0.66      0.61       209\n",
      "            Sports       0.87      0.70      0.78       139\n",
      "\n",
      "          accuracy                           0.65      1544\n",
      "         macro avg       0.73      0.65      0.67      1544\n",
      "      weighted avg       0.69      0.65      0.65      1544\n",
      "\n",
      "\n",
      " TESTING THE SVM MODEL \n",
      "confusion matrix\n",
      "[[ 83  23   2   0   9   2   4  10  10  14   4]\n",
      " [  9 132   0   0   5   2   2  23  10  20   2]\n",
      " [  3   0  56   0   1   0   0   1   4   2   1]\n",
      " [  1   0   0  23   3   0   0   0   1   0   0]\n",
      " [  3   1   1   1  66   1   1   1   6   4   0]\n",
      " [  2   6   0   0  13  92   7   5  25   5  14]\n",
      " [  3   0   0   0   4  27  50   1   2   1   4]\n",
      " [  7  29   3   0   3   7   0 106  25  13   5]\n",
      " [  2   6   5   2   6  11   5  13 129   5   6]\n",
      " [ 17  13   0   3   4   8   3  22   8 123   8]\n",
      " [  5   0   0   0   1   3   2   1   6   1 120]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.61      0.52      0.56       161\n",
      "  Business/Finance       0.63      0.64      0.64       205\n",
      "       CAA-NRC-NPR       0.84      0.82      0.83        68\n",
      "       Coronavirus       0.79      0.82      0.81        28\n",
      "              Food       0.57      0.78      0.66        85\n",
      "     Non-Political       0.60      0.54      0.57       169\n",
      "       Photography       0.68      0.54      0.60        92\n",
      "    Policy/Economy       0.58      0.54      0.56       198\n",
      "          Politics       0.57      0.68      0.62       190\n",
      "Science/Technology       0.65      0.59      0.62       209\n",
      "            Sports       0.73      0.86      0.79       139\n",
      "\n",
      "          accuracy                           0.63      1544\n",
      "         macro avg       0.66      0.67      0.66      1544\n",
      "      weighted avg       0.64      0.63      0.63      1544\n",
      "\n",
      "\n",
      " TESTING THE NAIVE BAYES MODEL\n",
      "confusion matrix\n",
      "[[ 47  19   0   0   0  52   0   6  31   6   0]\n",
      " [  5 117   0   0   0  14   0  22  28  19   0]\n",
      " [  2   0  12   0   0   1   0   6  45   2   0]\n",
      " [  2   0   0   0   0   5   0   2  12   7   0]\n",
      " [  3   0   0   0   7  50   0   1  18   6   0]\n",
      " [  0   1   0   0   1 133   0   2  31   0   1]\n",
      " [  2   0   0   0   0  71  11   0   3   5   0]\n",
      " [  0  20   0   0   0  18   0 103  51   6   0]\n",
      " [  0   2   0   0   0  20   0   9 154   4   1]\n",
      " [ 10   9   0   0   0  31   0  19  26 114   0]\n",
      " [  4   2   0   0   0  38   0   3  22   7  63]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.63      0.29      0.40       161\n",
      "  Business/Finance       0.69      0.57      0.62       205\n",
      "       CAA-NRC-NPR       1.00      0.18      0.30        68\n",
      "       Coronavirus       0.00      0.00      0.00        28\n",
      "              Food       0.88      0.08      0.15        85\n",
      "     Non-Political       0.31      0.79      0.44       169\n",
      "       Photography       1.00      0.12      0.21        92\n",
      "    Policy/Economy       0.60      0.52      0.56       198\n",
      "          Politics       0.37      0.81      0.50       190\n",
      "Science/Technology       0.65      0.55      0.59       209\n",
      "            Sports       0.97      0.45      0.62       139\n",
      "\n",
      "          accuracy                           0.49      1544\n",
      "         macro avg       0.64      0.40      0.40      1544\n",
      "      weighted avg       0.64      0.49      0.48      1544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X=strip2['title_comments_stem']+strip2['processed_url']\n",
    "y=strip2['flair']\n",
    "test_models(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(df[df['stemmed_titles'].isna()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING THE  LOGISTIC REGRESSION MODEL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[391  21   0   0   7  24   1  20  18  10   3]\n",
      " [ 26 148   0   0   0  11   0  59   5   5   0]\n",
      " [  6   0  48   0   0   0   1   7   4   0   0]\n",
      " [  1   0   0  28   2   1   0   0   2   0   0]\n",
      " [ 19   2   0   1  47  11   0   7   7   2   2]\n",
      " [ 18   3   0   0   4 277   9  12  43   4   4]\n",
      " [ 14   0   0   0   2  30  45   1   1   1   1]\n",
      " [ 14  51   0   0   2  19   1 395  34  13   0]\n",
      " [ 13   5   1   0   1  49   3  23 329   5   1]\n",
      " [ 32  18   0   0   0  27   1  41  10 105   3]\n",
      " [ 13   1   0   0   1   8   2   5   2   3 100]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.71      0.79      0.75       495\n",
      "  Business/Finance       0.59      0.58      0.59       254\n",
      "       CAA-NRC-NPR       0.98      0.73      0.83        66\n",
      "       Coronavirus       0.97      0.82      0.89        34\n",
      "              Food       0.71      0.48      0.57        98\n",
      "     Non-Political       0.61      0.74      0.67       374\n",
      "       Photography       0.71      0.47      0.57        95\n",
      "    Policy/Economy       0.69      0.75      0.72       529\n",
      "          Politics       0.72      0.77      0.74       430\n",
      "Science/Technology       0.71      0.44      0.55       237\n",
      "            Sports       0.88      0.74      0.80       135\n",
      "\n",
      "          accuracy                           0.70      2747\n",
      "         macro avg       0.75      0.66      0.70      2747\n",
      "      weighted avg       0.70      0.70      0.69      2747\n",
      "\n",
      "\n",
      " TESTING THE RANDOM FORESTS MODEL \n",
      "\n",
      "confusion matrix\n",
      "[[447   0   0   0   0  10   0  18  17   1   2]\n",
      " [ 43  67   0   0   0   7   1 128   5   3   0]\n",
      " [ 11   0  42   0   0   0   1   5   7   0   0]\n",
      " [  2   0   0  20   0   4   0   3   5   0   0]\n",
      " [ 33   0   0   1   8  26   0  22   6   0   2]\n",
      " [ 21   0   0   0   0 265   7  37  44   0   0]\n",
      " [ 18   0   0   0   0  27  35  14   1   0   0]\n",
      " [ 29   9   0   0   0   8   0 445  37   1   0]\n",
      " [ 22   0   1   0   1  39   1  54 311   1   0]\n",
      " [ 51   1   0   0   0  18   1  99   8  58   1]\n",
      " [ 17   0   0   0   1  18   1  23   7   0  68]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.64      0.90      0.75       495\n",
      "  Business/Finance       0.87      0.26      0.40       254\n",
      "       CAA-NRC-NPR       0.98      0.64      0.77        66\n",
      "       Coronavirus       0.95      0.59      0.73        34\n",
      "              Food       0.80      0.08      0.15        98\n",
      "     Non-Political       0.63      0.71      0.67       374\n",
      "       Photography       0.74      0.37      0.49        95\n",
      "    Policy/Economy       0.52      0.84      0.65       529\n",
      "          Politics       0.69      0.72      0.71       430\n",
      "Science/Technology       0.91      0.24      0.39       237\n",
      "            Sports       0.93      0.50      0.65       135\n",
      "\n",
      "          accuracy                           0.64      2747\n",
      "         macro avg       0.79      0.53      0.58      2747\n",
      "      weighted avg       0.71      0.64      0.61      2747\n",
      "\n",
      "\n",
      " TESTING THE SVM MODEL \n",
      "confusion matrix\n",
      "[[394   3   0   1   1   9   4  36  37   3   7]\n",
      " [ 49  74   0   1   1   8   0 101  13   3   4]\n",
      " [  5   0  40   1   0   0   0   6  14   0   0]\n",
      " [  1   0   0  29   0   2   0   0   2   0   0]\n",
      " [ 24   2   0   7  28  10   1  14   9   0   3]\n",
      " [ 32   3   0   1   1 176  10  34  90   5  22]\n",
      " [ 13   0   0   0   0  39  39   0   2   0   2]\n",
      " [ 26  15   2   3   1   8   1 414  53   1   5]\n",
      " [  3   4   3   2   0  24   1  40 347   1   5]\n",
      " [ 48   9   0   7   0  17   2  62  25  58   9]\n",
      " [ 10   0   0   0   0   1   2   4   5   0 113]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.65      0.80      0.72       495\n",
      "  Business/Finance       0.67      0.29      0.41       254\n",
      "       CAA-NRC-NPR       0.89      0.61      0.72        66\n",
      "       Coronavirus       0.56      0.85      0.67        34\n",
      "              Food       0.88      0.29      0.43        98\n",
      "     Non-Political       0.60      0.47      0.53       374\n",
      "       Photography       0.65      0.41      0.50        95\n",
      "    Policy/Economy       0.58      0.78      0.67       529\n",
      "          Politics       0.58      0.81      0.68       430\n",
      "Science/Technology       0.82      0.24      0.38       237\n",
      "            Sports       0.66      0.84      0.74       135\n",
      "\n",
      "          accuracy                           0.62      2747\n",
      "         macro avg       0.69      0.58      0.59      2747\n",
      "      weighted avg       0.65      0.62      0.60      2747\n",
      "\n",
      "\n",
      " TESTING THE NAIVE BAYES MODEL\n",
      "confusion matrix\n",
      "[[332   0   0   0   0  27   0  75  61   0   0]\n",
      " [ 36   5   0   0   0   5   0 193  15   0   0]\n",
      " [  4   0   1   0   0   1   0  25  35   0   0]\n",
      " [  1   0   0   0   0   1   0  11  21   0   0]\n",
      " [ 32   0   0   0   0  24   0  24  18   0   0]\n",
      " [ 37   0   0   0   0 191   0  34 112   0   0]\n",
      " [ 20   0   0   0   0  51   7   9   8   0   0]\n",
      " [ 14   0   0   0   0   4   0 462  49   0   0]\n",
      " [  3   0   0   0   0  11   0  50 366   0   0]\n",
      " [ 53   1   0   0   0  16   0 120  41   6   0]\n",
      " [ 23   0   0   0   0  21   0  31  43   0  17]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.60      0.67      0.63       495\n",
      "  Business/Finance       0.83      0.02      0.04       254\n",
      "       CAA-NRC-NPR       1.00      0.02      0.03        66\n",
      "       Coronavirus       0.00      0.00      0.00        34\n",
      "              Food       0.00      0.00      0.00        98\n",
      "     Non-Political       0.54      0.51      0.53       374\n",
      "       Photography       1.00      0.07      0.14        95\n",
      "    Policy/Economy       0.45      0.87      0.59       529\n",
      "          Politics       0.48      0.85      0.61       430\n",
      "Science/Technology       1.00      0.03      0.05       237\n",
      "            Sports       1.00      0.13      0.22       135\n",
      "\n",
      "          accuracy                           0.50      2747\n",
      "         macro avg       0.63      0.29      0.26      2747\n",
      "      weighted avg       0.61      0.50      0.42      2747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X=df['title_comments_stem']+df['stemmed_url']\n",
    "y=df['flair']\n",
    "test_models(X,y,'title-comments-combined,stemmed_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING THE  LOGISTIC REGRESSION MODEL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[395  21   0   0   7  21   1  21  16  10   3]\n",
      " [ 26 150   0   0   0  11   0  58   6   3   0]\n",
      " [  5   0  48   0   0   0   1   8   4   0   0]\n",
      " [  1   0   0  29   1   2   0   0   1   0   0]\n",
      " [ 19   2   0   1  47  11   0   8   7   1   2]\n",
      " [ 19   2   0   0   4 277   9  11  44   4   4]\n",
      " [ 15   0   0   0   2  30  46   1   0   1   0]\n",
      " [ 16  49   0   0   2  18   1 400  33  10   0]\n",
      " [ 13   5   1   0   1  48   3  22 331   5   1]\n",
      " [ 32  17   0   0   0  24   1  42   9 109   3]\n",
      " [ 13   2   0   0   1   6   2   5   2   4 100]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.71      0.80      0.75       495\n",
      "  Business/Finance       0.60      0.59      0.60       254\n",
      "       CAA-NRC-NPR       0.98      0.73      0.83        66\n",
      "       Coronavirus       0.97      0.85      0.91        34\n",
      "              Food       0.72      0.48      0.58        98\n",
      "     Non-Political       0.62      0.74      0.67       374\n",
      "       Photography       0.72      0.48      0.58        95\n",
      "    Policy/Economy       0.69      0.76      0.72       529\n",
      "          Politics       0.73      0.77      0.75       430\n",
      "Science/Technology       0.74      0.46      0.57       237\n",
      "            Sports       0.88      0.74      0.81       135\n",
      "\n",
      "          accuracy                           0.70      2747\n",
      "         macro avg       0.76      0.67      0.71      2747\n",
      "      weighted avg       0.71      0.70      0.70      2747\n",
      "\n",
      "\n",
      " TESTING THE RANDOM FORESTS MODEL \n",
      "\n",
      "confusion matrix\n",
      "[[452   0   0   0   0  12   0  16  14   0   1]\n",
      " [ 36  57   0   0   0  15   1 139   6   0   0]\n",
      " [ 12   0  41   0   0   0   1   5   7   0   0]\n",
      " [  3   0   0  20   0   4   0   3   4   0   0]\n",
      " [ 27   0   0   1   9  28   0  25   6   0   2]\n",
      " [ 26   0   0   0   0 269   6  36  37   0   0]\n",
      " [ 18   0   0   0   0  30  34  11   2   0   0]\n",
      " [ 32   7   0   0   0   9   0 441  39   1   0]\n",
      " [ 16   0   1   0   0  44   1  57 310   1   0]\n",
      " [ 50   2   0   0   0  20   1 104   9  49   2]\n",
      " [ 22   0   0   0   1  16   1  25   6   0  64]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.65      0.91      0.76       495\n",
      "  Business/Finance       0.86      0.22      0.36       254\n",
      "       CAA-NRC-NPR       0.98      0.62      0.76        66\n",
      "       Coronavirus       0.95      0.59      0.73        34\n",
      "              Food       0.90      0.09      0.17        98\n",
      "     Non-Political       0.60      0.72      0.66       374\n",
      "       Photography       0.76      0.36      0.49        95\n",
      "    Policy/Economy       0.51      0.83      0.63       529\n",
      "          Politics       0.70      0.72      0.71       430\n",
      "Science/Technology       0.96      0.21      0.34       237\n",
      "            Sports       0.93      0.47      0.63       135\n",
      "\n",
      "          accuracy                           0.64      2747\n",
      "         macro avg       0.80      0.52      0.57      2747\n",
      "      weighted avg       0.71      0.64      0.60      2747\n",
      "\n",
      "\n",
      " TESTING THE SVM MODEL \n",
      "confusion matrix\n",
      "[[411   0   0   1   1   7   2  32  33   2   6]\n",
      " [ 55  63   0   2   1   7   0 106  15   2   3]\n",
      " [  6   0  40   0   0   0   1   5  14   0   0]\n",
      " [  1   0   0  30   0   1   0   0   2   0   0]\n",
      " [ 28   0   0   6  28   9   1  14   9   0   3]\n",
      " [ 44   3   0   1   1 166  11  32  88   6  22]\n",
      " [ 15   0   0   0   0  37  41   0   0   0   2]\n",
      " [ 34  12   2   2   2   8   1 412  49   3   4]\n",
      " [ 10   3   3   3   0  18   1  37 348   3   4]\n",
      " [ 55   9   0   3   0  10   3  65  25  57  10]\n",
      " [ 10   0   0   0   0   1   2   5   6   0 111]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.61      0.83      0.71       495\n",
      "  Business/Finance       0.70      0.25      0.37       254\n",
      "       CAA-NRC-NPR       0.89      0.61      0.72        66\n",
      "       Coronavirus       0.62      0.88      0.73        34\n",
      "              Food       0.85      0.29      0.43        98\n",
      "     Non-Political       0.63      0.44      0.52       374\n",
      "       Photography       0.65      0.43      0.52        95\n",
      "    Policy/Economy       0.58      0.78      0.67       529\n",
      "          Politics       0.59      0.81      0.68       430\n",
      "Science/Technology       0.78      0.24      0.37       237\n",
      "            Sports       0.67      0.82      0.74       135\n",
      "\n",
      "          accuracy                           0.62      2747\n",
      "         macro avg       0.69      0.58      0.59      2747\n",
      "      weighted avg       0.65      0.62      0.59      2747\n",
      "\n",
      "\n",
      " TESTING THE NAIVE BAYES MODEL\n",
      "confusion matrix\n",
      "[[355   0   0   0   0  18   0  67  55   0   0]\n",
      " [ 35   5   0   0   0   4   0 196  14   0   0]\n",
      " [  3   0   0   0   0   1   0  30  32   0   0]\n",
      " [  3   0   0   0   0   0   0  13  18   0   0]\n",
      " [ 32   0   0   0   0  24   0  24  18   0   0]\n",
      " [ 40   0   0   0   0 187   0  36 111   0   0]\n",
      " [ 28   0   0   0   0  49   4   8   6   0   0]\n",
      " [ 13   0   0   0   0   5   0 468  43   0   0]\n",
      " [  4   0   0   0   0  11   0  51 364   0   0]\n",
      " [ 48   0   0   0   0  12   0 131  39   7   0]\n",
      " [ 27   0   0   0   0  22   0  38  37   0  11]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.60      0.72      0.66       495\n",
      "  Business/Finance       1.00      0.02      0.04       254\n",
      "       CAA-NRC-NPR       0.00      0.00      0.00        66\n",
      "       Coronavirus       0.00      0.00      0.00        34\n",
      "              Food       0.00      0.00      0.00        98\n",
      "     Non-Political       0.56      0.50      0.53       374\n",
      "       Photography       1.00      0.04      0.08        95\n",
      "    Policy/Economy       0.44      0.88      0.59       529\n",
      "          Politics       0.49      0.85      0.62       430\n",
      "Science/Technology       1.00      0.03      0.06       237\n",
      "            Sports       1.00      0.08      0.15       135\n",
      "\n",
      "          accuracy                           0.51      2747\n",
      "         macro avg       0.55      0.28      0.25      2747\n",
      "      weighted avg       0.61      0.51      0.42      2747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\mihee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X=df['title_comments_stem']+df['processed_url']\n",
    "y=df['flair']\n",
    "test_models(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[395  21   0   0   7  21   1  21  16  10   3]\n",
      " [ 26 150   0   0   0  11   0  58   6   3   0]\n",
      " [  5   0  48   0   0   0   1   8   4   0   0]\n",
      " [  1   0   0  29   1   2   0   0   1   0   0]\n",
      " [ 19   2   0   1  47  11   0   8   7   1   2]\n",
      " [ 19   2   0   0   4 277   9  11  44   4   4]\n",
      " [ 15   0   0   0   2  30  46   1   0   1   0]\n",
      " [ 16  49   0   0   2  18   1 400  33  10   0]\n",
      " [ 13   5   1   0   1  48   3  22 331   5   1]\n",
      " [ 32  17   0   0   0  24   1  42   9 109   3]\n",
      " [ 13   2   0   0   1   6   2   5   2   4 100]]\n",
      "\n",
      "\n",
      "Classification report \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.71      0.80      0.75       495\n",
      "  Business/Finance       0.60      0.59      0.60       254\n",
      "       CAA-NRC-NPR       0.98      0.73      0.83        66\n",
      "       Coronavirus       0.97      0.85      0.91        34\n",
      "              Food       0.72      0.48      0.58        98\n",
      "     Non-Political       0.62      0.74      0.67       374\n",
      "       Photography       0.72      0.48      0.58        95\n",
      "    Policy/Economy       0.69      0.76      0.72       529\n",
      "          Politics       0.73      0.77      0.75       430\n",
      "Science/Technology       0.74      0.46      0.57       237\n",
      "            Sports       0.88      0.74      0.81       135\n",
      "\n",
      "          accuracy                           0.70      2747\n",
      "         macro avg       0.76      0.67      0.71      2747\n",
      "      weighted avg       0.71      0.70      0.70      2747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=df['title_comments_stem']+df['processed_url']\n",
    "y=df['flair']\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=101)\n",
    "logreg=Pipeline([('vect',CountVectorizer()),\n",
    "                 ('tfidf',TfidfTransformer()),\n",
    "                  ('clf',LogisticRegression(C=50,penalty='l2')) # l1 performed comparatively worse \n",
    "                 ])\n",
    "logreg.fit(X_train,y_train)\n",
    "predictions=logreg.predict(X_test)\n",
    "print(\"confusion matrix\")\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(\"Classification report \")\n",
    "c_report=classification_report(y_test,predictions,output_dict=True)\n",
    "print(classification_report(y_test,predictions))\n",
    "model_eval['Classifier'].append('Logistic Regression')\n",
    "model_eval['Features'].append('title-comments-combined,processed_url')\n",
    "model_eval['macro_precision'].append(c_report['macro avg']['precision'])\n",
    "model_eval['weighted_precision'].append(c_report['weighted avg']['precision'])\n",
    "model_eval['macro_recall'].append(c_report['macro avg']['recall'])\n",
    "model_eval['weighted_recall'].append(c_report['weighted avg']['recall'])\n",
    "model_eval['macro_F1'].append(c_report['macro avg']['f1-score'])\n",
    "model_eval['weighted_F1'].append(c_report['weighted avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_eval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-75a6cd47e154>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_scores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model_eval' is not defined"
     ]
    }
   ],
   "source": [
    "model_scores=pd.DataFrame(model_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Features</th>\n",
       "      <th>macro_precision</th>\n",
       "      <th>weighted_precision</th>\n",
       "      <th>macro_recall</th>\n",
       "      <th>weighted_recall</th>\n",
       "      <th>macro_F1</th>\n",
       "      <th>weighted_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>stemmed titles,stemmed comments,author,process...</td>\n",
       "      <td>0.716193</td>\n",
       "      <td>0.673877</td>\n",
       "      <td>0.682564</td>\n",
       "      <td>0.663212</td>\n",
       "      <td>0.695358</td>\n",
       "      <td>0.665187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Random Forests</td>\n",
       "      <td>stemmed titles,stemmed comments,author,process...</td>\n",
       "      <td>0.726807</td>\n",
       "      <td>0.678591</td>\n",
       "      <td>0.629294</td>\n",
       "      <td>0.636658</td>\n",
       "      <td>0.650195</td>\n",
       "      <td>0.634279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SVM</td>\n",
       "      <td>stemmed titles,stemmed comments,author,process...</td>\n",
       "      <td>0.657419</td>\n",
       "      <td>0.631799</td>\n",
       "      <td>0.666914</td>\n",
       "      <td>0.630829</td>\n",
       "      <td>0.657376</td>\n",
       "      <td>0.627530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>stemmed titles,stemmed comments,author,process...</td>\n",
       "      <td>0.652677</td>\n",
       "      <td>0.643724</td>\n",
       "      <td>0.381748</td>\n",
       "      <td>0.475389</td>\n",
       "      <td>0.384859</td>\n",
       "      <td>0.459289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>stemmed_titles,processed_url</td>\n",
       "      <td>0.756557</td>\n",
       "      <td>0.692444</td>\n",
       "      <td>0.641448</td>\n",
       "      <td>0.681107</td>\n",
       "      <td>0.683297</td>\n",
       "      <td>0.677236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>title-comments-combined,stemmed_url</td>\n",
       "      <td>0.753595</td>\n",
       "      <td>0.702837</td>\n",
       "      <td>0.664808</td>\n",
       "      <td>0.696396</td>\n",
       "      <td>0.698462</td>\n",
       "      <td>0.692964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>Random Forests</td>\n",
       "      <td>title-comments-combined,stemmed_url</td>\n",
       "      <td>0.788428</td>\n",
       "      <td>0.705252</td>\n",
       "      <td>0.532992</td>\n",
       "      <td>0.642883</td>\n",
       "      <td>0.577779</td>\n",
       "      <td>0.614166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>SVM</td>\n",
       "      <td>title-comments-combined,stemmed_url</td>\n",
       "      <td>0.685392</td>\n",
       "      <td>0.649274</td>\n",
       "      <td>0.580407</td>\n",
       "      <td>0.623225</td>\n",
       "      <td>0.585467</td>\n",
       "      <td>0.600136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>title-comments-combined,stemmed_url</td>\n",
       "      <td>0.626991</td>\n",
       "      <td>0.613298</td>\n",
       "      <td>0.287789</td>\n",
       "      <td>0.504914</td>\n",
       "      <td>0.258079</td>\n",
       "      <td>0.419273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>title-comments-combined,processed_url</td>\n",
       "      <td>0.761437</td>\n",
       "      <td>0.710313</td>\n",
       "      <td>0.672705</td>\n",
       "      <td>0.703313</td>\n",
       "      <td>0.706261</td>\n",
       "      <td>0.699969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Classifier                                           Features  \\\n",
       "0   Logistic Regression  stemmed titles,stemmed comments,author,process...   \n",
       "1        Random Forests  stemmed titles,stemmed comments,author,process...   \n",
       "2                   SVM  stemmed titles,stemmed comments,author,process...   \n",
       "3           Naive Bayes  stemmed titles,stemmed comments,author,process...   \n",
       "4   Logistic Regression                       stemmed_titles,processed_url   \n",
       "..                  ...                                                ...   \n",
       "56  Logistic Regression                title-comments-combined,stemmed_url   \n",
       "57       Random Forests                title-comments-combined,stemmed_url   \n",
       "58                  SVM                title-comments-combined,stemmed_url   \n",
       "59          Naive Bayes                title-comments-combined,stemmed_url   \n",
       "60  Logistic Regression              title-comments-combined,processed_url   \n",
       "\n",
       "    macro_precision  weighted_precision  macro_recall  weighted_recall  \\\n",
       "0          0.716193            0.673877      0.682564         0.663212   \n",
       "1          0.726807            0.678591      0.629294         0.636658   \n",
       "2          0.657419            0.631799      0.666914         0.630829   \n",
       "3          0.652677            0.643724      0.381748         0.475389   \n",
       "4          0.756557            0.692444      0.641448         0.681107   \n",
       "..              ...                 ...           ...              ...   \n",
       "56         0.753595            0.702837      0.664808         0.696396   \n",
       "57         0.788428            0.705252      0.532992         0.642883   \n",
       "58         0.685392            0.649274      0.580407         0.623225   \n",
       "59         0.626991            0.613298      0.287789         0.504914   \n",
       "60         0.761437            0.710313      0.672705         0.703313   \n",
       "\n",
       "    macro_F1  weighted_F1  \n",
       "0   0.695358     0.665187  \n",
       "1   0.650195     0.634279  \n",
       "2   0.657376     0.627530  \n",
       "3   0.384859     0.459289  \n",
       "4   0.683297     0.677236  \n",
       "..       ...          ...  \n",
       "56  0.698462     0.692964  \n",
       "57  0.577779     0.614166  \n",
       "58  0.585467     0.600136  \n",
       "59  0.258079     0.419273  \n",
       "60  0.706261     0.699969  \n",
       "\n",
       "[61 rows x 8 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Features</th>\n",
       "      <th>macro_precision</th>\n",
       "      <th>weighted_precision</th>\n",
       "      <th>macro_recall</th>\n",
       "      <th>weighted_recall</th>\n",
       "      <th>macro_F1</th>\n",
       "      <th>weighted_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>stemmed titles,stemmed comments,author,process...</td>\n",
       "      <td>0.716193</td>\n",
       "      <td>0.673877</td>\n",
       "      <td>0.682564</td>\n",
       "      <td>0.663212</td>\n",
       "      <td>0.695358</td>\n",
       "      <td>0.665187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>stemmed_titles,processed_url</td>\n",
       "      <td>0.756557</td>\n",
       "      <td>0.692444</td>\n",
       "      <td>0.641448</td>\n",
       "      <td>0.681107</td>\n",
       "      <td>0.683297</td>\n",
       "      <td>0.677236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>title,processed_url</td>\n",
       "      <td>0.759476</td>\n",
       "      <td>0.703984</td>\n",
       "      <td>0.653407</td>\n",
       "      <td>0.693848</td>\n",
       "      <td>0.691811</td>\n",
       "      <td>0.689511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>title,processed_url(reduced_data)</td>\n",
       "      <td>0.710380</td>\n",
       "      <td>0.661636</td>\n",
       "      <td>0.664778</td>\n",
       "      <td>0.641192</td>\n",
       "      <td>0.678758</td>\n",
       "      <td>0.643907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>title,processed_url,author,stemmed_comments(re...</td>\n",
       "      <td>0.730383</td>\n",
       "      <td>0.680959</td>\n",
       "      <td>0.684016</td>\n",
       "      <td>0.670337</td>\n",
       "      <td>0.701703</td>\n",
       "      <td>0.671860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>title,processed_url,author,stemmed_comments(re...</td>\n",
       "      <td>0.716776</td>\n",
       "      <td>0.703106</td>\n",
       "      <td>0.699816</td>\n",
       "      <td>0.690698</td>\n",
       "      <td>0.704599</td>\n",
       "      <td>0.692756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>stemmed_titles,stemmed_comments,processed_url(...</td>\n",
       "      <td>0.708707</td>\n",
       "      <td>0.693821</td>\n",
       "      <td>0.692658</td>\n",
       "      <td>0.682558</td>\n",
       "      <td>0.697906</td>\n",
       "      <td>0.685264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>author,stemmed_titles,processed_url,stem_comme...</td>\n",
       "      <td>0.715449</td>\n",
       "      <td>0.699682</td>\n",
       "      <td>0.692422</td>\n",
       "      <td>0.684884</td>\n",
       "      <td>0.700244</td>\n",
       "      <td>0.688520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>author,stemmed_titles,processed_url</td>\n",
       "      <td>0.745966</td>\n",
       "      <td>0.685779</td>\n",
       "      <td>0.619530</td>\n",
       "      <td>0.670186</td>\n",
       "      <td>0.661366</td>\n",
       "      <td>0.664371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>title-comments-combined,processed_url</td>\n",
       "      <td>0.718002</td>\n",
       "      <td>0.675297</td>\n",
       "      <td>0.685044</td>\n",
       "      <td>0.665155</td>\n",
       "      <td>0.698104</td>\n",
       "      <td>0.667402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>author,title-comments-combined,processed_url</td>\n",
       "      <td>0.752922</td>\n",
       "      <td>0.707416</td>\n",
       "      <td>0.659476</td>\n",
       "      <td>0.700764</td>\n",
       "      <td>0.695008</td>\n",
       "      <td>0.697177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>stemmed_titles,processed_url</td>\n",
       "      <td>0.756557</td>\n",
       "      <td>0.692444</td>\n",
       "      <td>0.641448</td>\n",
       "      <td>0.681107</td>\n",
       "      <td>0.683297</td>\n",
       "      <td>0.677236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>stemmed_titles(reduced data)</td>\n",
       "      <td>0.646451</td>\n",
       "      <td>0.587587</td>\n",
       "      <td>0.613188</td>\n",
       "      <td>0.576425</td>\n",
       "      <td>0.627338</td>\n",
       "      <td>0.580221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>title-comments-combined,processed_url(reduced ...</td>\n",
       "      <td>0.754466</td>\n",
       "      <td>0.705945</td>\n",
       "      <td>0.663778</td>\n",
       "      <td>0.698326</td>\n",
       "      <td>0.697598</td>\n",
       "      <td>0.694938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>title-comments-combined,stemmed_url</td>\n",
       "      <td>0.753595</td>\n",
       "      <td>0.702837</td>\n",
       "      <td>0.664808</td>\n",
       "      <td>0.696396</td>\n",
       "      <td>0.698462</td>\n",
       "      <td>0.692964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Classifier                                           Features  \\\n",
       "0   Logistic Regression  stemmed titles,stemmed comments,author,process...   \n",
       "4   Logistic Regression                       stemmed_titles,processed_url   \n",
       "8   Logistic Regression                                title,processed_url   \n",
       "12  Logistic Regression                  title,processed_url(reduced_data)   \n",
       "16  Logistic Regression  title,processed_url,author,stemmed_comments(re...   \n",
       "20  Logistic Regression  title,processed_url,author,stemmed_comments(re...   \n",
       "24  Logistic Regression  stemmed_titles,stemmed_comments,processed_url(...   \n",
       "28  Logistic Regression  author,stemmed_titles,processed_url,stem_comme...   \n",
       "32  Logistic Regression                author,stemmed_titles,processed_url   \n",
       "36  Logistic Regression              title-comments-combined,processed_url   \n",
       "40  Logistic Regression       author,title-comments-combined,processed_url   \n",
       "44  Logistic Regression                       stemmed_titles,processed_url   \n",
       "48  Logistic Regression                       stemmed_titles(reduced data)   \n",
       "52  Logistic Regression  title-comments-combined,processed_url(reduced ...   \n",
       "56  Logistic Regression                title-comments-combined,stemmed_url   \n",
       "\n",
       "    macro_precision  weighted_precision  macro_recall  weighted_recall  \\\n",
       "0          0.716193            0.673877      0.682564         0.663212   \n",
       "4          0.756557            0.692444      0.641448         0.681107   \n",
       "8          0.759476            0.703984      0.653407         0.693848   \n",
       "12         0.710380            0.661636      0.664778         0.641192   \n",
       "16         0.730383            0.680959      0.684016         0.670337   \n",
       "20         0.716776            0.703106      0.699816         0.690698   \n",
       "24         0.708707            0.693821      0.692658         0.682558   \n",
       "28         0.715449            0.699682      0.692422         0.684884   \n",
       "32         0.745966            0.685779      0.619530         0.670186   \n",
       "36         0.718002            0.675297      0.685044         0.665155   \n",
       "40         0.752922            0.707416      0.659476         0.700764   \n",
       "44         0.756557            0.692444      0.641448         0.681107   \n",
       "48         0.646451            0.587587      0.613188         0.576425   \n",
       "52         0.754466            0.705945      0.663778         0.698326   \n",
       "56         0.753595            0.702837      0.664808         0.696396   \n",
       "\n",
       "    macro_F1  weighted_F1  \n",
       "0   0.695358     0.665187  \n",
       "4   0.683297     0.677236  \n",
       "8   0.691811     0.689511  \n",
       "12  0.678758     0.643907  \n",
       "16  0.701703     0.671860  \n",
       "20  0.704599     0.692756  \n",
       "24  0.697906     0.685264  \n",
       "28  0.700244     0.688520  \n",
       "32  0.661366     0.664371  \n",
       "36  0.698104     0.667402  \n",
       "40  0.695008     0.697177  \n",
       "44  0.683297     0.677236  \n",
       "48  0.627338     0.580221  \n",
       "52  0.697598     0.694938  \n",
       "56  0.698462     0.692964  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores[model_scores['Classifier']=='Logistic Regression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores.to_csv('model_scores.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='trained_pipeline.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_pipeline.sav']"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(logreg,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(logreg, open('trained_pipeline_pickle.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_table=pd.read_csv('model_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>macro_precision</th>\n",
       "      <th>weighted_precision</th>\n",
       "      <th>macro_recall</th>\n",
       "      <th>weighted_recall</th>\n",
       "      <th>macro_F1</th>\n",
       "      <th>weighted_F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>title-comments-combined,stemmed_url</td>\n",
       "      <td>0.761437</td>\n",
       "      <td>0.710313</td>\n",
       "      <td>0.699816</td>\n",
       "      <td>0.703313</td>\n",
       "      <td>0.706261</td>\n",
       "      <td>0.699969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>title-comments-combined,stemmed_url</td>\n",
       "      <td>0.744211</td>\n",
       "      <td>0.718472</td>\n",
       "      <td>0.484840</td>\n",
       "      <td>0.566062</td>\n",
       "      <td>0.501684</td>\n",
       "      <td>0.554048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forests</td>\n",
       "      <td>title-comments-combined,stemmed_url</td>\n",
       "      <td>0.812470</td>\n",
       "      <td>0.713627</td>\n",
       "      <td>0.647955</td>\n",
       "      <td>0.646288</td>\n",
       "      <td>0.664368</td>\n",
       "      <td>0.643226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SVM</td>\n",
       "      <td>title-comments-combined,stemmed_url</td>\n",
       "      <td>0.715938</td>\n",
       "      <td>0.656746</td>\n",
       "      <td>0.674903</td>\n",
       "      <td>0.660465</td>\n",
       "      <td>0.663760</td>\n",
       "      <td>0.653127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Features  macro_precision  \\\n",
       "Classifier                                                                  \n",
       "Logistic Regression  title-comments-combined,stemmed_url         0.761437   \n",
       "Naive Bayes          title-comments-combined,stemmed_url         0.744211   \n",
       "Random Forests       title-comments-combined,stemmed_url         0.812470   \n",
       "SVM                  title-comments-combined,stemmed_url         0.715938   \n",
       "\n",
       "                     weighted_precision  macro_recall  weighted_recall  \\\n",
       "Classifier                                                               \n",
       "Logistic Regression            0.710313      0.699816         0.703313   \n",
       "Naive Bayes                    0.718472      0.484840         0.566062   \n",
       "Random Forests                 0.713627      0.647955         0.646288   \n",
       "SVM                            0.656746      0.674903         0.660465   \n",
       "\n",
       "                     macro_F1  weighted_F1  \n",
       "Classifier                                  \n",
       "Logistic Regression  0.706261     0.699969  \n",
       "Naive Bayes          0.501684     0.554048  \n",
       "Random Forests       0.664368     0.643226  \n",
       "SVM                  0.663760     0.653127  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_table.groupby('Classifier').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
